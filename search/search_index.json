{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Martignac: Coarse-grained Martini simulation workflows","text":"<p>Martignac is a Python-based toolkit designed to streamline the preparation and analysis of coarse-grained Martini  molecular dynamics simulations.  It provides a suite of utilities for generating initial configurations---including solutes, solvent boxes, and  phospholipid bilayers---runs the simulations, and performs analysis,  such as alchemical transformations and umbrella sampling .  Martignac directly connects to the NOMAD database to pull existing simulations and push missing ones to the database, thereby constantly enriching the database with new data.</p> <p>The toolkit efficiently sets up and runs simulations, and perform analysis.  By automating routine tasks and offering a structured approach to simulation setup, Martignac aims to enhance  productivity and reproducibility in molecular dynamics studies.</p> <ul> <li> Install <code>martignac</code> to get started</li> <li> Quick start to run your first workflow</li> <li> Workflows explore all workflows</li> <li> Reference check out the docs</li> </ul>"},{"location":"install/","title":"Installation","text":"<p>First, clone (or fork and then clone) the repository:: <pre><code>git clone git@github.com:tbereau/martignac.git\n</code></pre></p> <p>To begin your Martignac project, fork the repository and then create a clone in your local workspace.</p> <p>Setup a virtual environment (Python 3.9 recommended) within the root directory of the local repo:</p> <pre><code>python -m venv .pyenv python==3.9\n. .pyenv/bin/activate\npip install --upgrade pip\n</code></pre> <p>We recommend installing the <code>uv</code> package for efficient installations with pip:</p> <pre><code>pip install uv\n</code></pre> <p>Now, install the package dependencies (<code>test_requirements.txt</code> is only needed for development):</p> <pre><code>uv pip install -r requirements.txt\nuv pip install -r test_requirements.txt\n</code></pre> <p>Finally, run the setup and install the package: <pre><code>python setup.py install\npip install -e .\n</code></pre></p> <p>The <code>-e</code> option installs the package in \"editable\" mode, which allows on the fly changes to the code without re-installing during testing or debugging phases.</p>"},{"location":"install/#gomacs-installation","title":"Gomacs installation","text":"<p>If you don't already have Gromacs installed, you can install with <code>apt-get</code> on linux (tested on Ubuntu 22.04):</p> <pre><code>sudo apt-get update\nsudo apt-get install -y build-essential cmake git libfftw3-dev libgsl0-dev\nsudo apt-get install -y libboost-all-dev libopenmpi-dev\nsudo apt-get install -y gromacs\n</code></pre> <p>Alternatively, you can quickly install with conda via:</p> <pre><code>conda config --add channels bioconda conda-forge\nconda install conda install ocl-icd-system==1.0.0\nconda install gromacs==2023.1\n</code></pre> <p>In either case, you will need to make the gromacs executables available to your environment. If you use conda, make sure not to intertwine your conda and venv (i.e., only work within 1 environment at a time).</p> <p>To install <code>conda</code>: <pre><code>wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n# on MacOS replace with:\n# wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh -O miniconda.sh\nbash ./miniconda.sh -b -f -p /path/to/conda\nexport PATH=\"/path/to/conda/bin:$PATH\"\nsource activate base\n</code></pre></p>"},{"location":"install/#nomad","title":"NOMAD","text":""},{"location":"install/#credentials","title":"Credentials","text":"<p>Martignac will need to connect to NOMAD. Create an account on https://nomad-lab.eu/. Store your credentials in a <code>.env</code> file at the root of the <code>martignac</code> directory, with the following content <pre><code>NOMAD_USERNAME=\"MyLogin\"\nNOMAD_PASSWORD=\"MyPassword\"\n</code></pre> and insert your username and password.</p> <p><code>.env</code> file</p> <p>Never push your <code>.env</code> file to a repository. This would expose your password.</p>"},{"location":"install/#dataset","title":"Dataset","text":"<p>You will need to create your own dataset to push to NOMAD. See the NOMAD datasets page for more information. The function martignac.nomad.datasets.create_dataset will help you create a dataset.</p>"},{"location":"install/#production-vs-test-databases","title":"Production vs. test databases","text":"<p>There are two main databases in NOMAD: production and test. Make sure to run all tests on the test database.</p> <p>Production database</p> <p>Never push test data to the production database.</p>"},{"location":"install/#push-to-nomad","title":"Push to NOMAD","text":"<p>Martignac will push all data to NOMAD. For testing purposes, there are safeguards in place:</p> Method Description <code>upload_to_nomad</code>      upload data to NOMAD <code>use_prod</code>  use the prod/test database <code>publish</code>        publish the NOMAD entries <p><code>publish</code> toggle</p> <p> <code>publish</code> is not yet supported.</p> <p>These safeguards can be changed in the <code>config.yaml</code> file. Note that any simulation that is published on NOMAD canot be deleted.</p>"},{"location":"install/#config-file","title":"Config file","text":"<p>Martignac is controlled through a <code>config.yaml</code> within the <code>martigac/</code> folder of the root directory. There you will find an example file called <code>config_default.yaml</code>. We recommend you copy this default config to <code>config.yaml</code>. You may want to initially delete some options including the dataset id and coauthor nomad ids, and add them back in later. You can add your own name under <code>query_authors</code>:</p> <pre><code>nomad:\n  upload_to_nomad: false\n  publish_uploads: false\n  use_prod: false\n  dataset:\n    id: \"&lt;dataset_id&gt;\"\n  coauthors:\n    - \"&lt;coauthor_nomad_id&gt;\" # coauthor #1\n  query_authors:\n    - \"&lt;Your_Name&gt;\"\n</code></pre> <p>You will need to add the appropriate paths to your workspace:</p> <pre><code>local:\n  workspaces:\n    absolute_path: \"&lt;path_to_martignac_root&gt;/martignac/workspaces\"\n  input_files:\n    absolute_path: \"&lt;path_to_martignac_root&gt;/scripts\"\n    itp_files: \"&lt;path_to_martignac_root&gt;/scripts/martini_v300\"\n  allow_symlinks: true\n</code></pre> <p>The rest of the yaml file consists of a variety of other options which control all aspects of simulation input files and parameters.</p> <p>Martignac workspace path</p> <p>The variable <code>MARTIGNACDIR</code> ensures that your Martignac config file can be found by the code. It should be set automatically, but there have been instances of import errors associated with config variables, which can be easily fixed by explicitly setting this variable with <code>export MARTIGNACDIR=&lt;path_to_martignac_root&gt;/martignac/</code>.</p>"},{"location":"install/#workflow-paths","title":"Workflow paths","text":"<p>You can set the directories for input and output of your workflows in the <code>config.yaml</code>.</p> <ul> <li>Output directory: set the key <code>local &gt; workspaces &gt; absolute_path</code></li> <li>Input directories: set the keys</li> <li><code>local &gt; input_files &gt; absolute_path</code> (default: <code>scripts/</code>), containing python scripts and mdp files</li> <li><code>local &gt; input_files &gt; itp_files</code>, containing force-field itp files</li> </ul> <p>In your workspace directory <code>${WORKSPACE}</code>, create the necessary subdirectories and initialize <code>signac</code>: <pre><code>for dir in alchemical_transformation solute_generation solute_in_solvent bilayer_generation \\\n  solute_in_bilayer solvent_generation; do\n  mkdir -p ${dir}\n  cd ${dir}\n  signac init\n  cd ..\ndone\n</code></pre> you should read <code>Initialized project</code> for each directory.</p>"},{"location":"quickstart/","title":"Quick start","text":"<p>Make sure you first install and set up Martignac as described in the installation guide.</p>"},{"location":"quickstart/#hello-martignac","title":"Hello, Martignac","text":"<p>Safeguards for first-time users</p> <p>The installation guide provides a detailed explanation of the safeguards that are in place to prevent accidental data upload to NOMAD. Please make sure to read it before running Martignac for the first time.</p> <p>You are now ready to run the workflows.  For instance, to generate solutes in bilayers, go to the input absolute path (e.g., <code>scripts/solute_in_bilayer</code>). There should be two files </p> <code>init.py</code> <p>initializes the computational <code>signac-workflow</code>; defines the solutes chemistries to screen (here one single C4 bead, one P6-C3 molecule, and one P6-C3-N1 molecule). This solely tells <code>signac</code> which computational jobs are  to be defined. The actual computation is defined in the <code>project.py</code> script.</p> <pre><code>import signac\n\nfrom martignac.workflows.solute_generation import SoluteGenFlow\n\nproject = signac.init_project(path=SoluteGenFlow.workspace_path)\n\nfor solute_name in [\"C4\", \"P6 C3, 0-1\", \"P6 C3 N1, 0_1 1_2 0-2\"]:\n    sp = {\"type\": \"solute\", \"solute_name\": solute_name}\n    job = project.open_job(sp).init()\n</code></pre> <code>project.py</code> <p>defines the workflow to run by importing the class and setting the desired workspace path. All computations  will occur from this script, and the results will be stored in the <code>workspace/</code> directory.</p> <pre><code>from martignac.workflows.solute_generation import SoluteGenFlow\n\nif __name__ == \"__main__\":\n    SoluteGenFlow(path=SoluteGenFlow.workspace_path).main()\n</code></pre> <p>You can simply run the two scripts by the following commands: <pre><code>python init.py\npython project.py run\n</code></pre></p> <p>The results can be found in your output <code>workspace/</code> directory.  If you've decided to push the data to NOMAD, you can check the content of your uploads on the NOMAD webserver, by logging in and navigating to your Datasets. For instance, the url for the test database would be  https://nomad-lab.eu/prod/v1/test/gui/user/datasets.</p>"},{"location":"running_workflows/","title":"Running workflows","text":"<p>Safeguards for first-time users</p> <p>The installation guide provides a detailed explanation of the safeguards that are in place to prevent accidental data upload to NOMAD. Please make sure to read it before running Martignac for the first time. This assumes you've also made it through the Quick start.</p> <p>Here's a list of workflows currently implemented in Martignac:</p> Workflow Description Class name Solute generation generate a solute in the gas phase martignac.workflows.solute_generation Solvent generation generate a solvent: homogeneous liquid in a box martignac.workflows.solvent_generation Solute-in-solvent generation generate a solute in a box of homogeneous liquid martignac.workflows.solute_in_solvent_generation Solute-in-solvent alchemical alchemical transformation of a solute in a solvent martignac.workflows.solute_in_solvent_alchemical Bilayer generation generate a bilayer martignac.workflows.bilayer_generation Solute-in-bilayer umbrella umbrella sampling of a solute in a bilayer martignac.workflows.solute_in_bilayer_umbrella <p>and a corresponding set of example <code>init.py</code> files to get started with screening each workflow:</p>"},{"location":"running_workflows/#solute-generation","title":"Solute generation","text":"<p>specify the solute chemistry</p> <pre><code>import signac\n\nfrom martignac.workflows.solute_generation import SoluteGenFlow\n\nproject = signac.init_project(path=SoluteGenFlow.workspace_path)\n\nfor solute_name in [\"C4\", \"P6 C3, 0-1\", \"P6 C3 N1, 0_1 1_2 0-2\"]:\n    sp = {\"type\": \"solute\", \"solute_name\": solute_name}\n    job = project.open_job(sp).init()\n</code></pre>"},{"location":"running_workflows/#solvent-generation","title":"Solvent generation","text":"<p>specify the solvent chemistry</p> <pre><code>import signac\n\nfrom martignac.workflows.solvent_generation import SolventGenFlow\n\nproject = signac.init_project(path=SolventGenFlow.workspace_path)\n\nfor solvent_name in [\"HD\"]:\n    sp = {\"type\": \"solvent\", \"solvent_name\": solvent_name}\n    job = project.open_job(sp).init()\n</code></pre>"},{"location":"running_workflows/#solute-in-solvent-generation","title":"Solute-in-solvent generation","text":"<p>specify the solute and solvent chemistry</p> <pre><code>import itertools\nimport signac\n\nfrom martignac.workflows.solute_in_solvent_generation import SoluteInSolventGenFlow\n\nproject = signac.init_project(path=SoluteInSolventGenFlow.workspace_path)\n\nsolvent_names = [\"HD\"]\nsolute_names = [\"P6\"]\n\npairs = list(itertools.product(solute_names, solvent_names))\n\nfor solute_name, solvent_name in pairs:\n    sp = {\"type\": \"solute_solvation\", \"solvent_name\": solvent_name, \"solute_name\": solute_name}\n    job = project.open_job(sp).init()\n</code></pre>"},{"location":"running_workflows/#solute-in-solvent-alchemical","title":"Solute-in-solvent alchemical","text":"<p>specify the solute and solvent chemistry, and the lambda states for the alchemical transformation</p> <pre><code>import itertools\nimport signac\n\nfrom martignac.workflows.solute_in_solvent_alchemical import SoluteInSolventAlchemicalFlow\n\nproject = signac.init_project(path=SoluteInSolventAlchemicalFlow.workspace_path)\n\nsolvent_names = [\"W\", \"OCO\"]\nsolute_names = [\"P6\"]\nlambda_states = range(11)\n\ntriplets = list(itertools.product(solvent_names, solute_names, lambda_states))\n\nfor solvent_name, solute_name, lambda_state in triplets:\n    sp = {\n        \"type\": \"alchemical_transformation\",\n        \"solvent_name\": solvent_name,\n        \"solute_name\": solute_name,\n        \"lambda_state\": lambda_state,\n    }\n    job = project.open_job(sp).init()\n</code></pre>"},{"location":"running_workflows/#bilayer-generation","title":"Bilayer generation","text":"<p>specify the phospholipid chemistry (solvent, e.g., water, is specific in the <code>config.yaml</code> file)</p> <pre><code>import signac\n\nfrom martignac.liquid_models.mixtures import LiquidComponent, LiquidMixture\nfrom martignac.workflows.bilayer_generation import BilayerGenFlow\n\nproject = signac.init_project(path=BilayerGenFlow.workspace_path)\n\nfor lipid_name in [LiquidMixture([LiquidComponent(\"M3.POPC\", 1.0)])]:\n    sp = {\n        \"type\": \"bilayer\",\n        \"lipids\": [{\"name\": c.name, \"fraction\": c.fraction} for c in lipid_name.components],\n    }\n    job = project.open_job(sp).init()\n</code></pre> <p>the \"M3.POPC\" follows the INSANE convention of specifying the Martini force field (version 3, here).</p>"},{"location":"running_workflows/#solute-in-bilayer-umbrella","title":"Solute-in-bilayer umbrella","text":"<p>specify the solute and bilayer chemistry, as well as the set of umbrella restraints</p> <pre><code>import itertools\n\nimport signac\nimport numpy as np\n\nfrom martignac.liquid_models.mixtures import LiquidComponent, LiquidMixture\nfrom martignac.workflows.solute_in_bilayer_umbrella import SoluteInBilayerUmbrellaFlow\n\nproject = signac.init_project(path=SoluteInBilayerUmbrellaFlow.workspace_path)\n\nlipids = [LiquidMixture([LiquidComponent(\"M3.POPC\", 1.0)])]\nlipid_names = []\nfor lipid in lipids:\n    lipid_names.append([{\"name\": c.name, \"fraction\": c.fraction} for c in lipid.components])\nsolute_names = [\"C4\"]\ndepths_from_bilayer_core = np.linspace(0.0, 4.0, 41)  # in nm\n\ntriplets = list(itertools.product(solute_names, lipid_names, depths_from_bilayer_core))\n\nfor solute, lipid, depth in triplets:\n    sp = {\n        \"type\": \"solute_in_bilayer\",\n        \"lipids\": lipid,\n        \"solute_name\": solute,\n        \"depth_from_bilayer_core\": depth,\n    }\n    job = project.open_job(sp).init()\n</code></pre>"},{"location":"liquid_models/mixtures/","title":"Liquids and mixtures","text":""},{"location":"liquid_models/mixtures/#martignac.liquid_models.mixtures.LiquidComponent","title":"<code>LiquidComponent</code>  <code>dataclass</code>","text":"<p>Represents a single component of a liquid mixture.</p> <p>This class models a component within a liquid mixture, including its name, the fraction of the total mixture it represents, and an optional integer component value. It provides methods for initialization validation, creating instances from dictionaries, and formatting component information for specific external systems.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the liquid component.</p> <code>fraction</code> <code>float</code> <p>The fraction of the total mixture this component represents, must be between 0 and 1.</p> <code>integer_component</code> <code>Optional[int]</code> <p>An optional integer value associated with the component, default is None.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Validates the fraction attribute to ensure it is within the expected range (0 to 1).</p> <code>from_dict</code> <p>dict) -&gt; \"LiquidComponent\": Class method to create an instance from a dictionary.</p> <code>to_insane_format</code> <p>Formats the component information for use in an external system, returning a string.</p> Source code in <code>martignac/liquid_models/mixtures.py</code> <pre><code>@dataclass\nclass LiquidComponent:\n    \"\"\"\n    Represents a single component of a liquid mixture.\n\n    This class models a component within a liquid mixture, including its name, the fraction of the total mixture it\n    represents, and an optional integer component value. It provides methods for initialization validation, creating\n    instances from dictionaries, and formatting component information for specific external systems.\n\n    Attributes:\n        name (str): The name of the liquid component.\n        fraction (float): The fraction of the total mixture this component represents, must be between 0 and 1.\n        integer_component (Optional[int]): An optional integer value associated with the component, default is None.\n\n    Methods:\n        __post_init__(self): Validates the fraction attribute to ensure it is within the expected range (0 to 1).\n        from_dict(cls, input_dict: dict) -&gt; \"LiquidComponent\": Class method to create an instance from a dictionary.\n        to_insane_format(self) -&gt; str: Formats the component information for use in an external system, returning a string.\n    \"\"\"\n\n    name: str\n    fraction: float\n    integer_component: Optional[int] = None\n\n    def __post_init__(self):\n        if not 0 &lt;= self.fraction &lt;= 1:\n            raise ValueError(\n                f\"unexpected component fraction {self.fraction} for {self.name}\"\n            )\n\n    @classmethod\n    def from_dict(cls, input_dict: dict) -&gt; \"LiquidComponent\":\n        if \"name\" not in input_dict:\n            raise KeyError(f\"Missing key 'name' in {input_dict}\")\n        if \"fraction\" not in input_dict:\n            raise KeyError(f\"Missing key 'fraction' in {input_dict}\")\n        return LiquidComponent(\n            name=input_dict.get(\"name\"), fraction=input_dict.get(\"fraction\")\n        )\n\n    def to_insane_format(self) -&gt; str:\n        return f\"{self.name}:{self.integer_component}\"\n</code></pre>"},{"location":"liquid_models/mixtures/#martignac.liquid_models.mixtures.LiquidMixture","title":"<code>LiquidMixture</code>  <code>dataclass</code>","text":"<p>Represents a mixture of liquid components.</p> <p>This class models a mixture of various liquid components, allowing for operations such as normalization checks, setting integer contributions based on a scaling factor, and formatting the mixture information for specific external systems. It supports initialization from a list of dictionaries representing individual components, ensuring that the total fraction of components equals 1.0 for a normalized mixture.</p> <p>Attributes:</p> Name Type Description <code>components</code> <code>list[LiquidComponent]</code> <p>A list of <code>LiquidComponent</code> instances representing the components of the mixture.</p> <code>scaling_factor</code> <code>float</code> <p>A scaling factor used to calculate integer contributions of each component, default is 10.0.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Validates the mixture to ensure it is normalized (i.e., the sum of component fractions equals 1.0).</p> <code>from_list_of_dicts</code> <p>list[dict]) -&gt; \"LiquidMixture\": Class method to create an instance from a list of dictionaries.</p> <code>set_integer_contributions</code> <p>Sets the integer contribution for each component based on the scaling factor.</p> <code>to_insane_format</code> <p>Formats the mixture information for use in an external system, returning a string.</p> <code>solvent_names </code> <p>Returns a list of names of the components in the mixture.</p> Source code in <code>martignac/liquid_models/mixtures.py</code> <pre><code>@dataclass\nclass LiquidMixture:\n    \"\"\"\n    Represents a mixture of liquid components.\n\n    This class models a mixture of various liquid components, allowing for operations such as normalization checks,\n    setting integer contributions based on a scaling factor, and formatting the mixture information for specific\n    external systems. It supports initialization from a list of dictionaries representing individual components,\n    ensuring that the total fraction of components equals 1.0 for a normalized mixture.\n\n    Attributes:\n        components (list[LiquidComponent]): A list of `LiquidComponent` instances representing the components of the mixture.\n        scaling_factor (float): A scaling factor used to calculate integer contributions of each component, default is 10.0.\n\n    Methods:\n        __post_init__(self): Validates the mixture to ensure it is normalized (i.e., the sum of component fractions equals 1.0).\n        from_list_of_dicts(cls, list_of_dicts: list[dict]) -&gt; \"LiquidMixture\": Class method to create an instance from a list of dictionaries.\n        set_integer_contributions(self): Sets the integer contribution for each component based on the scaling factor.\n        to_insane_format(self) -&gt; str: Formats the mixture information for use in an external system, returning a string.\n        solvent_names (property): Returns a list of names of the components in the mixture.\n    \"\"\"\n\n    components: list[LiquidComponent]\n    scaling_factor: float = 10.0\n\n    def __post_init__(self):\n        if not np.isclose(sum([c.fraction for c in self.components]), 1.0):\n            raise ValueError(f\"liquid mixture is not normalized: {self.components}\")\n\n    @classmethod\n    def from_list_of_dicts(cls, list_of_dicts: list[dict]) -&gt; \"LiquidMixture\":\n        components = [LiquidComponent.from_dict(d) for d in list_of_dicts]\n        return LiquidMixture(components)\n\n    def set_integer_contributions(self) -&gt; None:\n        for c in self.components:\n            c.integer_component = int(c.fraction * self.scaling_factor)\n\n    def to_insane_format(self, separator: str = \" \") -&gt; str:\n        self.set_integer_contributions()\n        return separator.join([c.to_insane_format() for c in self.components])\n\n    @property\n    def solvent_names(self) -&gt; list[str]:\n        return [c.name for c in self.components]\n</code></pre>"},{"location":"nomad/datasets/","title":"Datasets","text":""},{"location":"nomad/datasets/#martignac.nomad.datasets.NomadDataset","title":"<code>NomadDataset</code>","text":"<p>Represents a dataset within the NOMAD system.</p> <p>This class defines the structure of a dataset object used in the NOMAD application, including its metadata and associated user information. It is designed to be immutable, with all attributes set at the time of instantiation.</p> <p>Attributes:</p> Name Type Description <code>dataset_id</code> <code>str</code> <p>Unique identifier for the dataset.</p> <code>dataset_create_time</code> <code>datetime</code> <p>The creation time of the dataset.</p> <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> <code>dataset_type</code> <code>Optional[str]</code> <p>The type of the dataset, if specified.</p> <code>dataset_modified_time</code> <code>Optional[datetime]</code> <p>The last modification time of the dataset, if any.</p> <code>user</code> <code>Optional[NomadUser]</code> <p>The user associated with the dataset, if any.</p> <code>doi</code> <code>Optional[str]</code> <p>The Digital Object Identifier (DOI) of the dataset, if any.</p> <code>pid</code> <code>Optional[int]</code> <p>The persistent identifier (PID) of the dataset, if any.</p> <code>m_annotations</code> <code>Optional[dict]</code> <p>A dictionary of metadata annotations associated with the dataset, if any.</p> Source code in <code>martignac/nomad/datasets.py</code> <pre><code>@dataclass(frozen=True)\nclass NomadDataset:\n    \"\"\"\n    Represents a dataset within the NOMAD system.\n\n    This class defines the structure of a dataset object used in the NOMAD application, including its metadata and\n    associated user information. It is designed to be immutable, with all attributes set at the time of instantiation.\n\n    Attributes:\n        dataset_id (str): Unique identifier for the dataset.\n        dataset_create_time (dt.datetime): The creation time of the dataset.\n        dataset_name (str): The name of the dataset.\n        dataset_type (Optional[str]): The type of the dataset, if specified.\n        dataset_modified_time (Optional[dt.datetime]): The last modification time of the dataset, if any.\n        user (Optional[NomadUser]): The user associated with the dataset, if any.\n        doi (Optional[str]): The Digital Object Identifier (DOI) of the dataset, if any.\n        pid (Optional[int]): The persistent identifier (PID) of the dataset, if any.\n        m_annotations (Optional[dict]): A dictionary of metadata annotations associated with the dataset, if any.\n    \"\"\"\n\n    dataset_id: str\n    dataset_create_time: dt.datetime\n    dataset_name: str\n    dataset_type: Optional[str] = None\n    dataset_modified_time: Optional[dt.datetime] = None\n    user: Optional[NomadUser] = None\n    doi: Optional[str] = None\n    pid: Optional[int] = None\n    m_annotations: Optional[dict] = None\n    use_prod: Optional[bool] = None\n\n    @property\n    def base_url(self) -&gt; Optional[str]:\n        if self.use_prod is not None:\n            return get_nomad_base_url(self.use_prod)\n        return None\n\n    @property\n    def nomad_gui_url(self) -&gt; str:\n        if self.base_url is None:\n            raise ValueError(f\"missing attribute 'use_prod' for entry {self}\")\n        return f\"{self.base_url}/gui/user/datasets/dataset/id/{self.dataset_id}\"\n</code></pre>"},{"location":"nomad/datasets/#martignac.nomad.datasets.create_dataset","title":"<code>create_dataset(dataset_name, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Creates a new dataset in the NOMAD system with the specified name.</p> <p>This function sends a POST request to the NOMAD system to create a new dataset. The request includes the dataset name and is sent to either the production or test environment based on the <code>use_prod</code> flag. The function waits for a response for a specified timeout period.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset to be created.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment. Defaults to False,                        indicating that the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the server.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The unique identifier of the newly created dataset, as returned by the NOMAD system.</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If the request fails or the NOMAD system returns an error response.</p> Source code in <code>martignac/nomad/datasets.py</code> <pre><code>def create_dataset(\n    dataset_name: str, use_prod: bool = False, timeout_in_sec: int = 10\n) -&gt; str:\n    \"\"\"\n    Creates a new dataset in the NOMAD system with the specified name.\n\n    This function sends a POST request to the NOMAD system to create a new dataset. The request includes the dataset\n    name and is sent to either the production or test environment based on the `use_prod` flag. The function waits for\n    a response for a specified timeout period.\n\n    Args:\n        dataset_name (str): The name of the dataset to be created.\n        use_prod (bool, optional): Flag indicating whether to use the production environment. Defaults to False,\n                                   indicating that the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the server.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        str: The unique identifier of the newly created dataset, as returned by the NOMAD system.\n\n    Raises:\n        HTTPError: If the request fails or the NOMAD system returns an error response.\n    \"\"\"\n    logger.info(\n        f\"creating dataset name {dataset_name} on {'prod' if use_prod else 'test'} server\"\n    )\n    json_dict = {\"dataset_name\": dataset_name}\n    response = post_nomad_request(\n        \"/datasets/\",\n        with_authentication=True,\n        json_dict=json_dict,\n        use_prod=use_prod,\n        timeout_in_sec=timeout_in_sec,\n    )\n    return response.get(\"dataset_id\")\n</code></pre>"},{"location":"nomad/datasets/#martignac.nomad.datasets.delete_dataset","title":"<code>delete_dataset(dataset_id, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Deletes a dataset from the NOMAD system by its dataset ID.</p> <p>This function sends a DELETE request to the NOMAD system to remove a dataset identified by its unique ID. The operation can be directed to either the production or test environment, as specified by the <code>use_prod</code> flag. The function allows specifying a timeout for the request.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>The unique identifier of the dataset to be deleted.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment. Defaults to False,                        indicating that the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the server.                             Defaults to 10 seconds.</p> <code>10</code> Note <p>This function logs the outcome of the deletion operation, reporting success or failure through the logging system.</p> Source code in <code>martignac/nomad/datasets.py</code> <pre><code>def delete_dataset(\n    dataset_id: str, use_prod: bool = False, timeout_in_sec: int = 10\n) -&gt; None:\n    \"\"\"\n    Deletes a dataset from the NOMAD system by its dataset ID.\n\n    This function sends a DELETE request to the NOMAD system to remove a dataset identified by its unique ID. The\n    operation can be directed to either the production or test environment, as specified by the `use_prod` flag. The\n    function allows specifying a timeout for the request.\n\n    Args:\n        dataset_id (str): The unique identifier of the dataset to be deleted.\n        use_prod (bool, optional): Flag indicating whether to use the production environment. Defaults to False,\n                                   indicating that the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the server.\n                                        Defaults to 10 seconds.\n\n    Note:\n        This function logs the outcome of the deletion operation, reporting success or failure through the logging\n        system.\n    \"\"\"\n    logger.info(\n        f\"deleting dataset {dataset_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = delete_nomad_request(\n        f\"/datasets/{dataset_id}\",\n        with_authentication=True,\n        use_prod=use_prod,\n        timeout_in_sec=timeout_in_sec,\n    )\n    if response.get(\"dataset_id\"):\n        logger.info(f\"successfully deleted dataset {dataset_id}\")\n    else:\n        logger.error(\"no dataset deleted\")\n</code></pre>"},{"location":"nomad/datasets/#martignac.nomad.datasets.get_dataset_by_id","title":"<code>get_dataset_by_id(dataset_id, use_prod=True)</code>","text":"<p>Retrieves a single NomadDataset object by its dataset ID.</p> <p>This function queries the NOMAD system for a dataset with the specified ID. It leverages the <code>retrieve_datasets</code> function to perform the query, ensuring that only one dataset is returned. If the query returns more or fewer than one dataset, it raises a ValueError indicating an issue with the retrieval process.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>The unique identifier of the dataset to retrieve.</p> required <code>use_prod</code> <code>bool</code> <p>Flag to use the production environment. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>NomadDataset</code> <code>NomadDataset</code> <p>The dataset object corresponding to the provided ID.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no dataset is found with the provided ID, or if multiple datasets are returned.</p> Source code in <code>martignac/nomad/datasets.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_dataset_by_id(dataset_id: str, use_prod: bool = True) -&gt; NomadDataset:\n    \"\"\"\n    Retrieves a single NomadDataset object by its dataset ID.\n\n    This function queries the NOMAD system for a dataset with the specified ID. It leverages the `retrieve_datasets`\n    function to perform the query, ensuring that only one dataset is returned. If the query returns more or fewer\n    than one dataset, it raises a ValueError indicating an issue with the retrieval process.\n\n    Args:\n        dataset_id (str): The unique identifier of the dataset to retrieve.\n        use_prod (bool, optional): Flag to use the production environment. Defaults to True.\n\n    Returns:\n        NomadDataset: The dataset object corresponding to the provided ID.\n\n    Raises:\n        ValueError: If no dataset is found with the provided ID, or if multiple datasets are returned.\n    \"\"\"\n    datasets = retrieve_datasets(dataset_id=dataset_id, use_prod=use_prod)\n    if len(datasets) != 1:\n        raise ValueError(f\"Problem retrieving dataset {dataset_id}: {datasets}\")\n    return datasets[0]\n</code></pre>"},{"location":"nomad/datasets/#martignac.nomad.datasets.retrieve_datasets","title":"<code>retrieve_datasets(dataset_id=None, dataset_name=None, user_id=None, page_size=10, max_datasets=50, use_prod=True)</code>","text":"<p>Retrieves a list of NomadDataset objects based on the provided filters.</p> <p>This function queries the NOMAD system for datasets, optionally filtering by dataset ID, dataset name, or user ID. It supports pagination through the <code>page_size</code> parameter and allows limiting the total number of datasets returned with <code>max_datasets</code>. The <code>use_prod</code> flag determines whether to query the production or test environment.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>The unique identifier of the dataset to retrieve. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str</code> <p>The name of the dataset to filter by. Defaults to None.</p> <code>None</code> <code>user_id</code> <code>str</code> <p>The user ID to filter datasets by. Defaults to None.</p> <code>None</code> <code>page_size</code> <code>int</code> <p>The number of datasets to return per page. Defaults to 10.</p> <code>10</code> <code>max_datasets</code> <code>int</code> <p>The maximum number of datasets to retrieve. Defaults to 50.</p> <code>50</code> <code>use_prod</code> <code>bool</code> <p>Flag to use the production environment. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[NomadDataset]</code> <p>list[NomadDataset]: A list of NomadDataset objects matching the query.</p> Source code in <code>martignac/nomad/datasets.py</code> <pre><code>def retrieve_datasets(\n    dataset_id: Optional[str] = None,\n    dataset_name: Optional[str] = None,\n    user_id: Optional[str] = None,\n    page_size: int = 10,\n    max_datasets: int = 50,\n    use_prod: bool = True,\n) -&gt; list[NomadDataset]:\n    \"\"\"\n    Retrieves a list of NomadDataset objects based on the provided filters.\n\n    This function queries the NOMAD system for datasets, optionally filtering by dataset ID, dataset name, or user ID.\n    It supports pagination through the `page_size` parameter and allows limiting the total number of datasets returned\n    with `max_datasets`. The `use_prod` flag determines whether to query the production or test environment.\n\n    Args:\n        dataset_id (str, optional): The unique identifier of the dataset to retrieve. Defaults to None.\n        dataset_name (str, optional): The name of the dataset to filter by. Defaults to None.\n        user_id (str, optional): The user ID to filter datasets by. Defaults to None.\n        page_size (int, optional): The number of datasets to return per page. Defaults to 10.\n        max_datasets (int, optional): The maximum number of datasets to retrieve. Defaults to 50.\n        use_prod (bool, optional): Flag to use the production environment. Defaults to True.\n\n    Returns:\n        list[NomadDataset]: A list of NomadDataset objects matching the query.\n    \"\"\"\n    parameters = []\n    if dataset_id:\n        parameters.append(f\"dataset_id={dataset_id}\")\n    if dataset_name:\n        parameters.append(f\"dataset_name={dataset_name}\")\n    if user_id:\n        parameters.append(f\"user_id={user_id}\")\n    parameters.append(f\"page_size={page_size}\")\n    url_suffix = \"/datasets/\"\n    if len(parameters) &gt; 0:\n        url_suffix += f\"?{parameters[0]}\"\n    for i in range(1, len(parameters)):\n        url_suffix += f\"&amp;{parameters[i]}\"\n    headers = {\"Accept\": \"application/json\"}\n    nomad_entry_schema = class_schema(NomadDataset, base_schema=NomadDatasetSchema)\n    datasets = []\n    page_after_value = None\n    while (max_datasets &gt; 0 and len(datasets) &lt;= max_datasets) or (max_datasets &lt; 0):\n        url = (\n            f\"{url_suffix}&amp;page_after_value={page_after_value}\"\n            if page_after_value\n            else url_suffix\n        )\n        response = get_nomad_request(url, headers=headers, use_prod=use_prod)\n        if len(response[\"data\"]) == 0:\n            break\n        datasets.extend(\n            [\n                nomad_entry_schema().load({**d, \"use_prod\": use_prod})\n                for d in response[\"data\"]\n            ]\n        )\n        if response[\"pagination\"][\"page\"] == response[\"pagination\"][\"total\"]:\n            break\n        page_after_value = response[\"pagination\"].get(\"next_page_after_value\", \"\")\n        if not page_after_value:\n            break\n    return datasets\n</code></pre>"},{"location":"nomad/entries/","title":"Entries","text":""},{"location":"nomad/entries/#martignac.nomad.entries.NomadEntry","title":"<code>NomadEntry</code>","text":"<p>Represents an entry in the NOMAD system.</p> <p>This class encapsulates the data and metadata associated with an entry in the NOMAD database, including references, quantities, datasets, and processing information. It provides properties to access computed attributes such as URLs and job-related information derived from comments.</p> <p>Attributes:</p> Name Type Description <code>entry_id</code> <code>str</code> <p>Unique identifier for the entry.</p> <code>upload_id</code> <code>str</code> <p>Identifier of the upload this entry belongs to.</p> <code>references</code> <code>list[str]</code> <p>List of reference identifiers associated with this entry.</p> <code>origin</code> <code>str</code> <p>The origin of the entry data.</p> <code>quantities</code> <code>list[str]</code> <p>List of quantities measured or calculated for this entry.</p> <code>datasets</code> <code>list[NomadDataset]</code> <p>List of datasets associated with this entry.</p> <code>n_quantities</code> <code>int</code> <p>Number of quantities associated with this entry.</p> <code>nomad_version</code> <code>str</code> <p>Version of the NOMAD software used.</p> <code>upload_create_time</code> <code>datetime</code> <p>Creation time of the upload this entry is part of.</p> <code>nomad_commit</code> <code>str</code> <p>Specific commit of the NOMAD software used.</p> <code>section_defs</code> <code>list[NomadSectionDefinition]</code> <p>Definitions of sections used in this entry.</p> <code>processing_errors</code> <code>list[Any]</code> <p>List of errors encountered during processing of this entry.</p> <code>last_processing_time</code> <code>datetime</code> <p>Timestamp of the last processing attempt.</p> <code>parser_name</code> <code>str</code> <p>Name of the parser used to process this entry.</p> <code>calc_id</code> <code>str</code> <p>Calculation identifier associated with this entry.</p> <code>published</code> <code>bool</code> <p>Flag indicating whether this entry is published.</p> <code>writers</code> <code>list[NomadUser]</code> <p>List of users with write access to this entry.</p> <code>sections</code> <code>list[str]</code> <p>List of section identifiers associated with this entry.</p> <code>processed</code> <code>bool</code> <p>Flag indicating whether this entry has been processed.</p> <code>mainfile</code> <code>str</code> <p>Name of the main file for this entry.</p> <code>main_author</code> <code>NomadUser</code> <p>The main author of this entry.</p> <code>viewers</code> <code>list[NomadUser]</code> <p>List of users with view access to this entry.</p> <code>entry_create_time</code> <code>datetime</code> <p>Creation time of this entry.</p> <code>with_embargo</code> <code>bool</code> <p>Flag indicating whether this entry is under embargo.</p> <code>files</code> <code>list[str]</code> <p>List of file names associated with this entry.</p> <code>authors</code> <code>list[NomadUser]</code> <p>List of authors associated with this entry.</p> <code>license</code> <code>str</code> <p>License under which this entry is published.</p> <code>results</code> <code>Optional[dict]</code> <p>Results associated with this entry, if any.</p> <code>entry_name</code> <code>Optional[str]</code> <p>Name of this entry, if any.</p> <code>entry_type</code> <code>Optional[str]</code> <p>Type of this entry, if any.</p> <code>domain</code> <code>Optional[str]</code> <p>Domain of this entry, if any.</p> <code>optimade</code> <code>Optional[dict]</code> <p>OPTIMADE data associated with this entry, if any.</p> <code>comment</code> <code>Optional[str]</code> <p>Additional comments associated with this entry, if any.</p> <code>upload_name</code> <code>Optional[str]</code> <p>Name of the upload this entry belongs to, if any.</p> <code>viewer_groups</code> <code>Optional[list[Any]]</code> <p>Groups of users with view access, if any.</p> <code>writer_groups</code> <code>Optional[list[Any]]</code> <p>Groups of users with write access, if any.</p> <code>text_search_contents</code> <code>Optional[list[str]]</code> <p>Contents available for text search, if any.</p> <code>publish_time</code> <code>Optional[datetime]</code> <p>Time when this entry was published, if any.</p> <code>entry_references</code> <code>Optional[list[dict]]</code> <p>References associated with this entry, if any.</p> <code>use_prod</code> <code>Optional[bool]</code> <p>Flag indicating whether this entry is from the production environment.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@dataclass(frozen=True)\nclass NomadEntry:\n    \"\"\"\n    Represents an entry in the NOMAD system.\n\n    This class encapsulates the data and metadata associated with an entry in the NOMAD database, including references,\n    quantities, datasets, and processing information. It provides properties to access computed attributes such as\n    URLs and job-related information derived from comments.\n\n    Attributes:\n        entry_id (str): Unique identifier for the entry.\n        upload_id (str): Identifier of the upload this entry belongs to.\n        references (list[str]): List of reference identifiers associated with this entry.\n        origin (str): The origin of the entry data.\n        quantities (list[str]): List of quantities measured or calculated for this entry.\n        datasets (list[NomadDataset]): List of datasets associated with this entry.\n        n_quantities (int): Number of quantities associated with this entry.\n        nomad_version (str): Version of the NOMAD software used.\n        upload_create_time (dt.datetime): Creation time of the upload this entry is part of.\n        nomad_commit (str): Specific commit of the NOMAD software used.\n        section_defs (list[NomadSectionDefinition]): Definitions of sections used in this entry.\n        processing_errors (list[Any]): List of errors encountered during processing of this entry.\n        last_processing_time (dt.datetime): Timestamp of the last processing attempt.\n        parser_name (str): Name of the parser used to process this entry.\n        calc_id (str): Calculation identifier associated with this entry.\n        published (bool): Flag indicating whether this entry is published.\n        writers (list[NomadUser]): List of users with write access to this entry.\n        sections (list[str]): List of section identifiers associated with this entry.\n        processed (bool): Flag indicating whether this entry has been processed.\n        mainfile (str): Name of the main file for this entry.\n        main_author (NomadUser): The main author of this entry.\n        viewers (list[NomadUser]): List of users with view access to this entry.\n        entry_create_time (dt.datetime): Creation time of this entry.\n        with_embargo (bool): Flag indicating whether this entry is under embargo.\n        files (list[str]): List of file names associated with this entry.\n        authors (list[NomadUser]): List of authors associated with this entry.\n        license (str): License under which this entry is published.\n        results (Optional[dict]): Results associated with this entry, if any.\n        entry_name (Optional[str]): Name of this entry, if any.\n        entry_type (Optional[str]): Type of this entry, if any.\n        domain (Optional[str]): Domain of this entry, if any.\n        optimade (Optional[dict]): OPTIMADE data associated with this entry, if any.\n        comment (Optional[str]): Additional comments associated with this entry, if any.\n        upload_name (Optional[str]): Name of the upload this entry belongs to, if any.\n        viewer_groups (Optional[list[Any]]): Groups of users with view access, if any.\n        writer_groups (Optional[list[Any]]): Groups of users with write access, if any.\n        text_search_contents (Optional[list[str]]): Contents available for text search, if any.\n        publish_time (Optional[dt.datetime]): Time when this entry was published, if any.\n        entry_references (Optional[list[dict]]): References associated with this entry, if any.\n        use_prod (Optional[bool]): Flag indicating whether this entry is from the production environment.\n    \"\"\"\n\n    entry_id: str\n    upload_id: str\n    references: list[str]\n    origin: str\n    datasets: list[NomadDataset] = field(repr=False)\n    n_quantities: int\n    nomad_version: str\n    upload_create_time: dt.datetime\n    nomad_commit: str\n    parser_name: str\n    calc_id: str\n    published: bool\n    writers: list[NomadUser]\n    processed: bool\n    mainfile: str\n    main_author: NomadUser\n    viewers: list[NomadUser] = field(repr=False)\n    entry_create_time: dt.datetime\n    with_embargo: bool\n    authors: list[NomadUser] = field(repr=False)\n    license: str\n    results: Optional[dict] = field(repr=False, default=None)\n    entry_name: Optional[str] = None\n    entry_type: Optional[str] = None\n    domain: Optional[str] = None\n    optimade: Optional[dict] = field(repr=False, default=None)\n    comment: Optional[str] = None\n    upload_name: Optional[str] = None\n    last_processing_time: Optional[dt.datetime] = None\n    processing_errors: Optional[list[Any]] = field(default=None)\n    quantities: Optional[list[str]] = field(repr=False, default=None)\n    viewer_groups: Optional[list[Any]] = field(repr=False, default=None)\n    writer_groups: Optional[list[Any]] = field(repr=False, default=None)\n    files: Optional[list[str]] = field(repr=False, default=None)\n    sections: Optional[list[str]] = field(repr=False, default=None)\n    section_defs: Optional[list[NomadSectionDefinition]] = field(\n        repr=False, default=None\n    )\n    text_search_contents: Optional[list[str]] = None\n    publish_time: Optional[dt.datetime] = None\n    entry_references: Optional[list[dict]] = None\n    use_prod: Optional[bool] = None\n\n    @property\n    def base_url(self) -&gt; Optional[str]:\n        if self.use_prod is not None:\n            return get_nomad_base_url(self.use_prod)\n        return None\n\n    @property\n    def nomad_gui_url(self) -&gt; str:\n        if self.base_url is None:\n            raise ValueError(f\"missing attribute 'use_prod' for entry {self}\")\n        return f\"{self.base_url}/gui/user/uploads/upload/id/{self.upload_id}/entry/id/{self.entry_id}\"\n\n    @property\n    def job_id(self) -&gt; Optional[str]:\n        return self._comment_dict.get(\"job_id\", None)\n\n    @property\n    def workflow_name(self) -&gt; Optional[str]:\n        return self._comment_dict.get(\"workflow_name\", None)\n\n    @property\n    def state_point(self) -&gt; dict:\n        return self._comment_dict.get(\"state_point\", {})\n\n    @property\n    def mdp_files(self) -&gt; Optional[str]:\n        return self._comment_dict.get(\"mdp_files\", None)\n\n    @property\n    def _comment_dict(self) -&gt; dict:\n        return json.loads(self.comment or \"{}\")\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.download_raw_data_of_job","title":"<code>download_raw_data_of_job(job, timeout_in_sec=10)</code>","text":"<p>Downloads the raw data associated with a given job from the NOMAD system and stores it in the job's directory.</p> <p>This function attempts to find NOMAD entries corresponding to the specified job, downloads the raw data for the first matching entry, and extracts it into the job's directory. It handles the creation of a temporary ZIP file for the raw data, extracts the relevant files, and cleans up the temporary files. Additionally, it updates the job's document with NOMAD dataset and upload IDs, and specific workflow information if available.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The signac job object for which to download the raw data.</p> required <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the server when                             downloading the raw data. Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the raw data was successfully downloaded and processed, False if no corresponding NOMAD entries   were found for the job.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the job's project does not derive from MartiniFlowProject.</p> <code>ValueError</code> <p>If the found entries have inconsistent upload IDs, indicating a data retrieval or processing error.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef download_raw_data_of_job(job: Job, timeout_in_sec: int = 10) -&gt; bool:  # noqa: C901\n    \"\"\"\n    Downloads the raw data associated with a given job from the NOMAD system and stores it in the job's directory.\n\n    This function attempts to find NOMAD entries corresponding to the specified job, downloads the raw data for the\n    first matching entry, and extracts it into the job's directory. It handles the creation of a temporary ZIP file\n    for the raw data, extracts the relevant files, and cleans up the temporary files. Additionally, it updates the\n    job's document with NOMAD dataset and upload IDs, and specific workflow information if available.\n\n    Args:\n        job (Job): The signac job object for which to download the raw data.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the server when\n                                        downloading the raw data. Defaults to 10 seconds.\n\n    Returns:\n        bool: True if the raw data was successfully downloaded and processed, False if no corresponding NOMAD entries\n              were found for the job.\n\n    Raises:\n        TypeError: If the job's project does not derive from MartiniFlowProject.\n        ValueError: If the found entries have inconsistent upload IDs, indicating a data retrieval or processing error.\n    \"\"\"\n    entries = find_mini_queries_corresponding_to_job(job)\n    if len(entries) == 0:\n        return False\n    entry = entries[0]\n    logger.info(\n        f\"found {'un' if not entry.published else ''}published entry {entry.upload_id}\"\n    )\n    if entry.published:\n        zip_content = _get_raw_data_of_upload_by_id(\n            entry.upload_id,\n            use_prod=entry.use_prod,\n            timeout_in_sec=timeout_in_sec,\n            with_authentication=not entry.published,\n        )\n    else:\n        zip_content = _get_raw_data_of_entry_by_id(\n            entry.entry_id,\n            use_prod=entry.use_prod,\n            timeout_in_sec=timeout_in_sec,\n            with_authentication=not entry.published,\n        )\n    zip_file_name = \"nomad_archive.zip\"\n    with open(job.fn(zip_file_name), \"wb\") as f:\n        f.write(bytes(zip_content))\n    with ZipFile(job.fn(zip_file_name), \"r\") as zip_file:\n        archive_path = (\n            job.path + \"/\" + entry.upload_id if not entry.published else job.path\n        )\n        name_list = zip_file.namelist()\n        logger.debug(f\"zip content: {name_list}\")\n        if not entry.published:\n            name_list = [\n                name for name in name_list if name.startswith(f\"{entry.upload_id}/\")\n            ]\n        path_to_extract = job.path\n        if f\"{job.id}/\" in name_list:\n            name_list = [\n                name\n                for name in name_list\n                if name.startswith(f\"{job.id}/\") and name != f\"{job.id}/\"\n            ]\n            path_to_extract = Path(job.path).parent\n        logger.info(f\"to extract: {name_list}\")\n        zip_file.extractall(path=path_to_extract, members=name_list)\n    for file_name in name_list:\n        if Path(file_name).name not in os.listdir(job.path):\n            shutil.move(job.path + \"/\" + file_name, job.path)\n    os.remove(job.fn(zip_file_name))\n    if \"signac_job_document.json\" in os.listdir(archive_path):\n        with open(archive_path + \"/signac_job_document.json\") as fp:\n            json_data = json.load(fp)\n            job.doc = update_nested_dict(job.doc, dict(json_data))\n    if not entry.published:\n        for file_name in os.listdir(archive_path):\n            os.remove(archive_path + \"/\" + file_name)\n        os.removedirs(archive_path)\n    job.document[\"nomad_dataset_id\"] = MartiniFlowProject.nomad_dataset_id\n    if entry.workflow_name not in job.document:\n        job.document[entry.workflow_name] = {}\n    job.document[entry.workflow_name][\"nomad_upload_id\"] = entry.upload_id\n\n    return True\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.find_entries_corresponding_to_job","title":"<code>find_entries_corresponding_to_job(job)</code>","text":"<p>Finds NOMAD entries that correspond to a given job.</p> <p>This function searches for NOMAD entries that are associated with the specified job. It checks if the job's project is a subclass of MartiniFlowProject. If not, it raises a TypeError. The function then proceeds to match entries based on the job's ID and the hash of MDP files associated with the job. It combines entries found through querying the NOMAD dataset with entries associated with uploads owned by the current user. If entries with inconsistent upload IDs are found, a ValueError is raised.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The signac job object to find corresponding NOMAD entries for.</p> required <p>Returns:</p> Type Description <code>list[NomadEntry]</code> <p>list[NomadEntry]: A list of NomadEntry objects that correspond to the given job.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the job's project does not derive from MartiniFlowProject.</p> <code>ValueError</code> <p>If found entries have inconsistent upload IDs, indicating a data retrieval or processing error.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef find_entries_corresponding_to_job(job: Job) -&gt; list[NomadEntry]:\n    \"\"\"\n    Finds NOMAD entries that correspond to a given job.\n\n    This function searches for NOMAD entries that are associated with the specified job. It checks if the job's project\n    is a subclass of MartiniFlowProject. If not, it raises a TypeError. The function then proceeds to match entries\n    based on the job's ID and the hash of MDP files associated with the job. It combines entries found through querying\n    the NOMAD dataset with entries associated with uploads owned by the current user. If entries with inconsistent\n    upload IDs are found, a ValueError is raised.\n\n    Args:\n        job (Job): The signac job object to find corresponding NOMAD entries for.\n\n    Returns:\n        list[NomadEntry]: A list of NomadEntry objects that correspond to the given job.\n\n    Raises:\n        TypeError: If the job's project does not derive from MartiniFlowProject.\n        ValueError: If found entries have inconsistent upload IDs, indicating a data retrieval or processing error.\n    \"\"\"\n    if not issubclass(type(job.project), MartiniFlowProject):\n        raise TypeError(\n            f\"job project {type(job.project)} does not derive from MartiniFlowProject\"\n        )\n    project = cast(\"MartiniFlowProject\", job.project)\n\n    def associate_entry_to_job(entry_: NomadEntry) -&gt; Optional[NomadEntry]:\n        if (\n            entry_.comment is not None\n            and entry_.job_id == job.id\n            and entry_.mdp_files\n            == project.get_hash_for_files(job, list(project.mdp_files.values()))\n        ):\n            return entry_\n\n    match_entries = []\n    nomad_entries = query_entries(\n        dataset_id=project.nomad_dataset_id, use_prod=project.nomad_use_prod_database\n    )\n    for entry in nomad_entries:\n        if found_entry := associate_entry_to_job(entry):\n            match_entries.append(found_entry)\n    my_uploads = get_all_my_uploads(use_prod=project.nomad_use_prod_database)\n    for upload in my_uploads:\n        upload_entries = get_entries_of_upload(\n            upload.upload_id,\n            with_authentication=True,\n            use_prod=project.nomad_use_prod_database,\n        )\n        for entry in upload_entries:\n            if found_entry := associate_entry_to_job(entry):\n                match_entries.append(found_entry)\n    if len(match_entries) &gt; 0 and not all(\n        entry.upload_id == match_entries[0].upload_id for entry in match_entries\n    ):\n        raise ValueError(f\"Inconsistent upload IDs in entries:\\n{match_entries}\")\n    return match_entries\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.get_entries_in_database","title":"<code>get_entries_in_database(database_id=DEFAULT_DATABASE, use_prod=DEFAULT_USE_PROD)</code>","text":"<p>Retrieves a list of NomadEntry objects from a specified database.</p> <p>This function queries the NOMAD system for entries within a specified database, using the provided database ID. It allows specifying whether to use the production or test environment for the query. The function leverages the <code>query_entries</code> function to perform the actual query based on the provided parameters.</p> <p>Parameters:</p> Name Type Description Default <code>database_id</code> <code>str</code> <p>The unique identifier of the database from which to retrieve entries.                          Defaults to the value of <code>DEFAULT_DATABASE</code> from the configuration.</p> <code>DEFAULT_DATABASE</code> <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment. Defaults to the value                        of <code>DEFAULT_USE_PROD</code> from the configuration.</p> <code>DEFAULT_USE_PROD</code> <p>Returns:</p> Type Description <code>list[NomadEntry]</code> <p>list[NomadEntry]: A list of NomadEntry objects corresponding to the entries found in the specified database.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_entries_in_database(\n    database_id: str = DEFAULT_DATABASE, use_prod: bool = DEFAULT_USE_PROD\n) -&gt; list[NomadEntry]:\n    \"\"\"\n    Retrieves a list of NomadEntry objects from a specified database.\n\n    This function queries the NOMAD system for entries within a specified database, using the provided database ID.\n    It allows specifying whether to use the production or test environment for the query. The function leverages\n    the `query_entries` function to perform the actual query based on the provided parameters.\n\n    Args:\n        database_id (str, optional): The unique identifier of the database from which to retrieve entries.\n                                     Defaults to the value of `DEFAULT_DATABASE` from the configuration.\n        use_prod (bool, optional): Flag indicating whether to use the production environment. Defaults to the value\n                                   of `DEFAULT_USE_PROD` from the configuration.\n\n    Returns:\n        list[NomadEntry]: A list of NomadEntry objects corresponding to the entries found in the specified database.\n    \"\"\"\n    return query_entries(dataset_id=database_id, use_prod=use_prod)\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.get_entries_of_my_uploads","title":"<code>get_entries_of_my_uploads(use_prod=False, timeout_in_sec=10)</code>","text":"<p>Retrieves a list of NomadEntry objects associated with the uploads owned by the current user.</p> <p>This function iterates over all uploads owned by the current user, identified through their unique upload IDs, and aggregates all entries associated with these uploads. It allows specifying whether to use the production or test environment for the NOMAD system, and a timeout for the request.</p> <p>Parameters:</p> Name Type Description Default <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment. Defaults to False,                        indicating that the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the server.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[NomadEntry]</code> <p>list[NomadEntry]: A list of NomadEntry objects corresponding to the entries associated with the uploads               owned by the current user.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_entries_of_my_uploads(\n    use_prod: bool = False, timeout_in_sec: int = 10\n) -&gt; list[NomadEntry]:\n    \"\"\"\n    Retrieves a list of NomadEntry objects associated with the uploads owned by the current user.\n\n    This function iterates over all uploads owned by the current user, identified through their unique upload IDs,\n    and aggregates all entries associated with these uploads. It allows specifying whether to use the production\n    or test environment for the NOMAD system, and a timeout for the request.\n\n    Args:\n        use_prod (bool, optional): Flag indicating whether to use the production environment. Defaults to False,\n                                   indicating that the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the server.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        list[NomadEntry]: A list of NomadEntry objects corresponding to the entries associated with the uploads\n                          owned by the current user.\n    \"\"\"\n    return [\n        upload_entry\n        for u in get_all_my_uploads(use_prod=use_prod, timeout_in_sec=timeout_in_sec)\n        for upload_entry in get_entries_of_upload(\n            u.upload_id, with_authentication=True, use_prod=use_prod\n        )\n    ]\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.get_entries_of_upload","title":"<code>get_entries_of_upload(upload_id, use_prod=False, with_authentication=False, timeout_in_sec=10)</code>","text":"<p>Retrieves a list of NomadEntry objects associated with a specific upload ID.</p> <p>This function sends a GET request to the NOMAD system to retrieve all entries associated with a given upload ID. It allows specifying whether to use the production or test environment, whether authentication is required for the request, and a timeout for the request.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload whose entries are to be retrieved.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment. Defaults to False.</p> <code>False</code> <code>with_authentication</code> <code>bool</code> <p>Flag indicating whether the request should include authentication.                                    Defaults to False.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the server.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[NomadEntry]</code> <p>list[NomadEntry]: A list of NomadEntry objects corresponding to the entries of the specified upload ID.</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If the request fails or the NOMAD system returns an error response.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_entries_of_upload(\n    upload_id: str,\n    use_prod: bool = False,\n    with_authentication: bool = False,\n    timeout_in_sec: int = 10,\n) -&gt; list[NomadEntry]:\n    \"\"\"\n    Retrieves a list of NomadEntry objects associated with a specific upload ID.\n\n    This function sends a GET request to the NOMAD system to retrieve all entries associated with a given upload ID.\n    It allows specifying whether to use the production or test environment, whether authentication is required for\n    the request, and a timeout for the request.\n\n    Args:\n        upload_id (str): The unique identifier of the upload whose entries are to be retrieved.\n        use_prod (bool, optional): Flag indicating whether to use the production environment. Defaults to False.\n        with_authentication (bool, optional): Flag indicating whether the request should include authentication.\n                                               Defaults to False.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the server.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        list[NomadEntry]: A list of NomadEntry objects corresponding to the entries of the specified upload ID.\n\n    Raises:\n        HTTPError: If the request fails or the NOMAD system returns an error response.\n    \"\"\"\n    logger.info(\n        f\"retrieving entries for upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = get_nomad_request(\n        f\"/uploads/{upload_id}/entries\",\n        with_authentication=with_authentication,\n        use_prod=use_prod,\n        timeout_in_sec=timeout_in_sec,\n    )\n    nomad_entry_schema = class_schema(NomadEntry, base_schema=NomadEntrySchema)\n    return [\n        nomad_entry_schema().load({**r[\"entry_metadata\"], \"use_prod\": use_prod})\n        for r in response[\"data\"]\n    ]\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.get_entry_by_id","title":"<code>get_entry_by_id(entry_id, use_prod=True, with_authentication=False, timeout_in_sec=10)</code>","text":"<p>Retrieves a NomadEntry object by its unique entry ID.</p> <p>This function sends a GET request to the NOMAD system to retrieve the details of a specific entry identified by its unique ID. It allows specifying whether to use the production or test environment, whether authentication is required for the request, and a timeout for the request.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry to retrieve.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment. Defaults to True.</p> <code>True</code> <code>with_authentication</code> <code>bool</code> <p>Flag indicating whether the request should include authentication.                                    Defaults to False.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the server.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>NomadEntry</code> <code>NomadEntry</code> <p>The NomadEntry object corresponding to the provided entry ID.</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If the request fails or the NOMAD system returns an error response.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_entry_by_id(\n    entry_id: str,\n    use_prod: bool = True,\n    with_authentication: bool = False,\n    timeout_in_sec: int = 10,\n) -&gt; NomadEntry:\n    \"\"\"\n    Retrieves a NomadEntry object by its unique entry ID.\n\n    This function sends a GET request to the NOMAD system to retrieve the details of a specific entry identified by its\n    unique ID. It allows specifying whether to use the production or test environment, whether authentication is\n    required for the request, and a timeout for the request.\n\n    Args:\n        entry_id (str): The unique identifier of the entry to retrieve.\n        use_prod (bool, optional): Flag indicating whether to use the production environment. Defaults to True.\n        with_authentication (bool, optional): Flag indicating whether the request should include authentication.\n                                               Defaults to False.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the server.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        NomadEntry: The NomadEntry object corresponding to the provided entry ID.\n\n    Raises:\n        HTTPError: If the request fails or the NOMAD system returns an error response.\n    \"\"\"\n    logger.info(\n        f\"retrieving entry {entry_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = get_nomad_request(\n        f\"/entries/{entry_id}\",\n        with_authentication=with_authentication,\n        use_prod=use_prod,\n        timeout_in_sec=timeout_in_sec,\n    )\n    nomad_entry_schema = class_schema(NomadEntry, base_schema=NomadEntrySchema)\n    return nomad_entry_schema().load({**response[\"data\"], \"use_prod\": use_prod})\n</code></pre>"},{"location":"nomad/entries/#martignac.nomad.entries.query_entries","title":"<code>query_entries(workflow_name=None, program_name=None, dataset_id=None, origin=None, page_size=10, max_entries=50, use_prod=True)</code>","text":"<p>Queries the NOMAD system for entries based on various filters and returns a list of NomadEntry objects.</p> <p>This function constructs a query to the NOMAD system, allowing for filtering based on workflow name, program name, dataset ID, and origin. It supports pagination through <code>page_size</code> and limits the number of entries returned with <code>max_entries</code>. The environment (production or test) can be specified with <code>use_prod</code>.</p> <p>Parameters:</p> Name Type Description Default <code>workflow_name</code> <code>str</code> <p>Filter entries by the name of the workflow. Defaults to None.</p> <code>None</code> <code>program_name</code> <code>str</code> <p>Filter entries by the program name. Defaults to None.</p> <code>None</code> <code>dataset_id</code> <code>str</code> <p>Filter entries by the dataset ID. Defaults to None.</p> <code>None</code> <code>origin</code> <code>str</code> <p>Filter entries by their origin. Defaults to None.</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of entries to return per page. Defaults to 10.</p> <code>10</code> <code>max_entries</code> <code>int</code> <p>Maximum number of entries to return. Defaults to 50.</p> <code>50</code> <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to query the production environment. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[NomadEntry]</code> <p>list[NomadEntry]: A list of NomadEntry objects that match the query criteria.</p> Source code in <code>martignac/nomad/entries.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef query_entries(\n    workflow_name: Optional[str] = None,\n    program_name: Optional[str] = None,\n    dataset_id: Optional[str] = None,\n    origin: Optional[str] = None,\n    page_size: int = 10,\n    max_entries: int = 50,\n    use_prod: bool = True,\n) -&gt; list[NomadEntry]:\n    \"\"\"\n    Queries the NOMAD system for entries based on various filters and returns a list of NomadEntry objects.\n\n    This function constructs a query to the NOMAD system, allowing for filtering based on workflow name, program name,\n    dataset ID, and origin. It supports pagination through `page_size` and limits the number of entries returned with\n    `max_entries`. The environment (production or test) can be specified with `use_prod`.\n\n    Args:\n        workflow_name (str, optional): Filter entries by the name of the workflow. Defaults to None.\n        program_name (str, optional): Filter entries by the program name. Defaults to None.\n        dataset_id (str, optional): Filter entries by the dataset ID. Defaults to None.\n        origin (str, optional): Filter entries by their origin. Defaults to None.\n        page_size (int, optional): Number of entries to return per page. Defaults to 10.\n        max_entries (int, optional): Maximum number of entries to return. Defaults to 50.\n        use_prod (bool, optional): Flag indicating whether to query the production environment. Defaults to True.\n\n    Returns:\n        list[NomadEntry]: A list of NomadEntry objects that match the query criteria.\n    \"\"\"\n    json_dict = {\n        \"query\": {},\n        \"pagination\": {\"page_size\": page_size},\n        \"required\": {\"include\": [\"entry_id\"]},\n    }\n    entries = []\n    while (max_entries &gt; 0 and len(entries) &lt;= max_entries) or (max_entries &lt; 0):\n        if dataset_id:\n            json_dict[\"query\"][\"datasets\"] = {\"dataset_id\": dataset_id}\n        if workflow_name:\n            json_dict[\"query\"][\"results.method\"] = {\"workflow_name\": workflow_name}\n        if program_name:\n            json_dict[\"query\"][\"results.method\"] = {\n                \"simulation\": {\"program_name\": program_name}\n            }\n        if origin:\n            json_dict[\"query\"][\"origin\"] = origin\n        query = post_nomad_request(\n            \"/entries/query\", json_dict=json_dict, use_prod=use_prod\n        )\n        entries.extend([q[\"entry_id\"] for q in query[\"data\"]])\n        next_page_after_value = query[\"pagination\"].get(\"next_page_after_value\", None)\n        if next_page_after_value:\n            json_dict[\"pagination\"][\"page_after_value\"] = next_page_after_value\n        else:\n            break\n    if max_entries &gt; 0:\n        entries = entries[:max_entries]\n    return [get_entry_by_id(e, use_prod=use_prod) for e in entries]\n</code></pre>"},{"location":"nomad/uploads/","title":"Uploads","text":""},{"location":"nomad/uploads/#martignac.nomad.uploads.NomadUpload","title":"<code>NomadUpload</code>","text":"<p>Represents an upload in the NOMAD system, encapsulating all relevant metadata and state information.</p> <p>Attributes:</p> Name Type Description <code>upload_id</code> <code>str</code> <p>Unique identifier for the upload.</p> <code>upload_create_time</code> <code>datetime</code> <p>The creation time of the upload.</p> <code>main_author</code> <code>NomadUser</code> <p>The main author of the upload.</p> <code>process_running</code> <code>bool</code> <p>Flag indicating if a process is currently running for this upload.</p> <code>current_process</code> <code>str</code> <p>The name of the current process running.</p> <code>process_status</code> <code>str</code> <p>The status of the current process.</p> <code>last_status_message</code> <code>str</code> <p>The last status message received for the current process.</p> <code>errors</code> <code>list[Any]</code> <p>A list of errors associated with the upload.</p> <code>warnings</code> <code>list[Any]</code> <p>A list of warnings associated with the upload.</p> <code>coauthors</code> <code>list[str]</code> <p>List of coauthor identifiers.</p> <code>coauthor_groups</code> <code>list[Any]</code> <p>List of coauthor groups.</p> <code>reviewers</code> <code>list[NomadUser]</code> <p>List of reviewers.</p> <code>reviewer_groups</code> <code>list[Any]</code> <p>List of reviewer groups.</p> <code>writers</code> <code>list[NomadUser]</code> <p>List of writers with access to the upload.</p> <code>writer_groups</code> <code>list[Any]</code> <p>List of writer groups.</p> <code>viewers</code> <code>list[NomadUser]</code> <p>List of viewers with access to the upload.</p> <code>viewer_groups</code> <code>list[Any]</code> <p>List of viewer groups.</p> <code>published</code> <code>bool</code> <p>Flag indicating if the upload is published.</p> <code>published_to</code> <code>list[Any]</code> <p>List of platforms or locations the upload is published to.</p> <code>with_embargo</code> <code>bool</code> <p>Flag indicating if the upload is under embargo.</p> <code>embargo_length</code> <code>float</code> <p>The length of the embargo in days.</p> <code>license</code> <code>str</code> <p>The license associated with the upload.</p> <code>entries</code> <code>int</code> <p>The number of entries in the upload.</p> <code>n_entries</code> <code>Optional[int]</code> <p>The number of entries, if known.</p> <code>upload_files_server_path</code> <code>Optional[str]</code> <p>The server path to the uploaded files.</p> <code>publish_time</code> <code>Optional[datetime]</code> <p>The time the upload was published.</p> <code>references</code> <code>Optional[list[str]]</code> <p>List of references associated with the upload.</p> <code>datasets</code> <code>Optional[list[str]]</code> <p>List of dataset identifiers associated with the upload.</p> <code>external_db</code> <code>Optional[str]</code> <p>External database identifier.</p> <code>upload_name</code> <code>Optional[str]</code> <p>The name of the upload.</p> <code>comment</code> <code>Optional[str]</code> <p>A comment or description of the upload.</p> <code>use_prod</code> <code>Optional[bool]</code> <p>Flag indicating if the production environment is used.</p> <code>complete_time</code> <code>Optional[datetime]</code> <p>The time the upload was completed.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>@dataclass\nclass NomadUpload:\n    \"\"\"\n    Represents an upload in the NOMAD system, encapsulating all relevant metadata and state information.\n\n    Attributes:\n        upload_id (str): Unique identifier for the upload.\n        upload_create_time (datetime.datetime): The creation time of the upload.\n        main_author (NomadUser): The main author of the upload.\n        process_running (bool): Flag indicating if a process is currently running for this upload.\n        current_process (str): The name of the current process running.\n        process_status (str): The status of the current process.\n        last_status_message (str): The last status message received for the current process.\n        errors (list[Any]): A list of errors associated with the upload.\n        warnings (list[Any]): A list of warnings associated with the upload.\n        coauthors (list[str]): List of coauthor identifiers.\n        coauthor_groups (list[Any]): List of coauthor groups.\n        reviewers (list[NomadUser]): List of reviewers.\n        reviewer_groups (list[Any]): List of reviewer groups.\n        writers (list[NomadUser]): List of writers with access to the upload.\n        writer_groups (list[Any]): List of writer groups.\n        viewers (list[NomadUser]): List of viewers with access to the upload.\n        viewer_groups (list[Any]): List of viewer groups.\n        published (bool): Flag indicating if the upload is published.\n        published_to (list[Any]): List of platforms or locations the upload is published to.\n        with_embargo (bool): Flag indicating if the upload is under embargo.\n        embargo_length (float): The length of the embargo in days.\n        license (str): The license associated with the upload.\n        entries (int): The number of entries in the upload.\n        n_entries (Optional[int]): The number of entries, if known.\n        upload_files_server_path (Optional[str]): The server path to the uploaded files.\n        publish_time (Optional[datetime.datetime]): The time the upload was published.\n        references (Optional[list[str]]): List of references associated with the upload.\n        datasets (Optional[list[str]]): List of dataset identifiers associated with the upload.\n        external_db (Optional[str]): External database identifier.\n        upload_name (Optional[str]): The name of the upload.\n        comment (Optional[str]): A comment or description of the upload.\n        use_prod (Optional[bool]): Flag indicating if the production environment is used.\n        complete_time (Optional[datetime.datetime]): The time the upload was completed.\n    \"\"\"\n\n    upload_id: str\n    upload_create_time: dt.datetime\n    main_author: NomadUser\n    process_running: bool\n    current_process: str\n    process_status: str\n    last_status_message: str\n    errors: list[Any]\n    warnings: list[Any]\n    coauthors: list[str]\n    coauthor_groups: list[Any]\n    reviewers: list[NomadUser]\n    reviewer_groups: list[Any]\n    writers: list[NomadUser]\n    writer_groups: list[Any]\n    viewers: list[NomadUser]\n    viewer_groups: list[Any]\n    published: bool\n    published_to: list[Any]\n    with_embargo: bool\n    embargo_length: float\n    license: str\n    entries: int\n    n_entries: Optional[int] = None\n    upload_files_server_path: Optional[str] = None\n    publish_time: Optional[dt.datetime] = None\n    references: Optional[list[str]] = None\n    datasets: Optional[list[str]] = None\n    external_db: Optional[str] = None\n    upload_name: Optional[str] = None\n    comment: Optional[str] = None\n    use_prod: Optional[bool] = None\n    complete_time: Optional[dt.datetime] = None\n\n    @property\n    def base_url(self) -&gt; Optional[str]:\n        if self.use_prod is not None:\n            return get_nomad_base_url(self.use_prod)\n        return None\n\n    @property\n    def nomad_gui_url(self) -&gt; str:\n        if self.base_url is None:\n            raise ValueError(f\"missing attribute 'use_prod' for upload {self}\")\n        return f\"{self.base_url}/gui/user/uploads/upload/id/{self.upload_id}\"\n\n    def fetch(self, with_authentication: bool = True) -&gt; None:\n        updated_upload = get_upload_by_id(\n            self.upload_id,\n            use_prod=self.use_prod,\n            with_authentication=with_authentication,\n        )\n        self.__dict__.update(updated_upload.__dict__)\n\n    def safe_publish(self) -&gt; None:\n        if not self.published:\n            wait_counter = 600  # 10 minutes overall\n            while self.process_running and wait_counter &gt; 0:\n                logger.info(\"upload still processing, waiting before new attempt\")\n                sleep(10)\n                self.fetch()\n                wait_counter -= 1\n            if self.process_running:\n                raise ValueError(f\"upload {self.upload_id} is still processing\")\n            publish_upload(upload_id=self.upload_id, use_prod=self.use_prod)\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.delete_file_to_specified_path","title":"<code>delete_file_to_specified_path(upload_id, remote_path, local_file, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Deletes a file from a specific path within an upload in the NOMAD system.</p> <p>This function deletes a specified file from a specific path within an existing upload in the NOMAD system. It allows the user to choose between the production and test environments. It also supports setting a custom timeout for the deletion process to prevent indefinite waiting periods. The function logs the outcome of the deletion process, including success or failure messages.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload from which the file should be deleted.</p> required <code>path</code> <code>str</code> <p>The path where the file should be deleted within the upload.</p> required <code>file</code> <p>The file to the file to be deleted.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for the deletion to complete.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the response from the NOMAD system regarding the deletion action.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def delete_file_to_specified_path(\n    upload_id: str,\n    remote_path: str,\n    local_file: str,\n    use_prod: bool = False,\n    timeout_in_sec: int = 10,\n) -&gt; dict:\n    \"\"\"\n    Deletes a file from a specific path within an upload in the NOMAD system.\n\n    This function deletes a specified file from a specific path within an existing upload in the NOMAD system. It allows\n    the user to choose between the production and test environments. It also supports setting a custom timeout for the\n    deletion process to prevent indefinite waiting periods. The function logs the outcome of the deletion process,\n    including success or failure messages.\n\n    Args:\n        upload_id (str): The unique identifier of the upload from which the file should be deleted.\n        path (str): The path where the file should be deleted within the upload.\n        file: The file to the file to be deleted.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for the deletion to complete.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        dict: A dictionary containing the response from the NOMAD system regarding the deletion action.\n    \"\"\"\n    logger.info(\n        f\"deleting file {local_file} from upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    remote_file = f\"{remote_path}{basename(local_file)}\"\n    response = delete_nomad_request(\n        f\"/uploads/{upload_id}/raw/{remote_file}\",\n        with_authentication=True,\n        use_prod=use_prod,\n        timeout_in_sec=timeout_in_sec,\n    )\n    upload_class_schema = class_schema(NomadUpload, base_schema=NomadUploadSchema)\n    return upload_class_schema().load({**response[\"data\"], \"use_prod\": use_prod})\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.delete_upload","title":"<code>delete_upload(upload_id, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Deletes a specific upload from the NOMAD system based on its unique ID.</p> <p>This function sends a request to the NOMAD system to delete an upload identified by its unique ID. It allows specifying whether to interact with the production or test environment of the NOMAD system. Additionally, a timeout for the network request can be defined to avoid indefinite waiting periods.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload to be deleted.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>NomadUpload</code> <code>NomadUpload</code> <p>An instance of <code>NomadUpload</code> containing the metadata of the deleted upload. This can be useful          for logging or confirmation purposes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the deletion request fails or the response from the NOMAD system is unexpected.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def delete_upload(\n    upload_id: str, use_prod: bool = False, timeout_in_sec: int = 10\n) -&gt; NomadUpload:\n    \"\"\"\n    Deletes a specific upload from the NOMAD system based on its unique ID.\n\n    This function sends a request to the NOMAD system to delete an upload identified by its unique ID. It allows\n    specifying whether to interact with the production or test environment of the NOMAD system. Additionally, a timeout\n    for the network request can be defined to avoid indefinite waiting periods.\n\n    Args:\n        upload_id (str): The unique identifier of the upload to be deleted.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        NomadUpload: An instance of `NomadUpload` containing the metadata of the deleted upload. This can be useful\n                     for logging or confirmation purposes.\n\n    Raises:\n        ValueError: If the deletion request fails or the response from the NOMAD system is unexpected.\n    \"\"\"\n    logger.info(\n        f\"deleting upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = delete_nomad_request(\n        f\"/uploads/{upload_id}\",\n        with_authentication=True,\n        timeout_in_sec=timeout_in_sec,\n    )\n    upload_class_schema = class_schema(NomadUpload, base_schema=NomadUploadSchema)\n    return upload_class_schema().load({**response[\"data\"], \"use_prod\": use_prod})\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.edit_upload_metadata","title":"<code>edit_upload_metadata(upload_id, upload_name=None, references=None, dataset_id=None, embargo_length=None, coauthors_ids=None, comment=None, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Edits the metadata of a specific upload in the NOMAD system.</p> <p>This function allows for the modification of various metadata fields of an existing upload, identified by its unique ID. It supports updating the upload's name, references, dataset ID, embargo length, coauthors, and additional comments. The function also allows specifying whether to interact with the production or test environment of the NOMAD system, along with a custom timeout for the network request.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload to be edited.</p> required <code>upload_name</code> <code>Optional[str]</code> <p>The new name for the upload.</p> <code>None</code> <code>references</code> <code>Optional[list[str]]</code> <p>A list of new references associated with the upload.</p> <code>None</code> <code>dataset_id</code> <code>Optional[str]</code> <p>The new dataset ID associated with the upload.</p> <code>None</code> <code>embargo_length</code> <code>Optional[float]</code> <p>The new embargo length in days.</p> <code>None</code> <code>coauthors_ids</code> <code>Optional[list[str]]</code> <p>A list of new coauthor identifiers.</p> <code>None</code> <code>comment</code> <code>Optional[str]</code> <p>A new comment or description for the upload.</p> <code>None</code> <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the response from the NOMAD system regarding the edit action.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def edit_upload_metadata(\n    upload_id: str,\n    upload_name: Optional[str] = None,\n    references: Optional[list[str]] = None,\n    dataset_id: Optional[str] = None,\n    embargo_length: Optional[float] = None,\n    coauthors_ids: Optional[list[str]] = None,\n    comment: Optional[str] = None,\n    use_prod: bool = False,\n    timeout_in_sec: int = 10,\n) -&gt; dict:\n    \"\"\"\n    Edits the metadata of a specific upload in the NOMAD system.\n\n    This function allows for the modification of various metadata fields of an existing upload, identified by its unique ID.\n    It supports updating the upload's name, references, dataset ID, embargo length, coauthors, and additional comments.\n    The function also allows specifying whether to interact with the production or test environment of the NOMAD system,\n    along with a custom timeout for the network request.\n\n    Args:\n        upload_id (str): The unique identifier of the upload to be edited.\n        upload_name (Optional[str], optional): The new name for the upload.\n        references (Optional[list[str]], optional): A list of new references associated with the upload.\n        dataset_id (Optional[str], optional): The new dataset ID associated with the upload.\n        embargo_length (Optional[float], optional): The new embargo length in days.\n        coauthors_ids (Optional[list[str]], optional): A list of new coauthor identifiers.\n        comment (Optional[str], optional): A new comment or description for the upload.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        dict: A dictionary containing the response from the NOMAD system regarding the edit action.\n    \"\"\"\n    logger.info(\n        f\"editing the metadata for upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    metadata = {\"metadata\": {}}\n    if upload_name:\n        metadata[\"metadata\"][\"upload_name\"] = upload_name\n    if references:\n        metadata[\"metadata\"][\"references\"] = references\n    if dataset_id:\n        metadata[\"metadata\"][\"datasets\"] = dataset_id\n    if embargo_length:\n        metadata[\"metadata\"][\"embargo_length\"] = embargo_length\n    if coauthors_ids:\n        metadata[\"metadata\"][\"coauthors\"] = coauthors_ids\n    if comment:\n        metadata[\"metadata\"][\"comment\"] = comment\n    response = post_nomad_request(\n        f\"/uploads/{upload_id}/edit\",\n        use_prod=use_prod,\n        with_authentication=True,\n        json_dict=metadata,\n        timeout_in_sec=timeout_in_sec,\n    )\n    return response\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.get_all_my_uploads","title":"<code>get_all_my_uploads(use_prod=False, timeout_in_sec=10)</code>","text":"<p>Retrieves all uploads associated with the authenticated user from the NOMAD system.</p> <p>This function fetches a list of all uploads made by the currently authenticated user. It allows the user to specify whether to interact with the production or test environment of the NOMAD system. The function also supports specifying a timeout for the network request.</p> <p>Parameters:</p> Name Type Description Default <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[NomadUpload]</code> <p>list[NomadUpload]: A list of <code>NomadUpload</code> objects, each representing an upload made by the user.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_all_my_uploads(\n    use_prod: bool = False, timeout_in_sec: int = 10\n) -&gt; list[NomadUpload]:\n    \"\"\"\n    Retrieves all uploads associated with the authenticated user from the NOMAD system.\n\n    This function fetches a list of all uploads made by the currently authenticated user. It allows the user to specify\n    whether to interact with the production or test environment of the NOMAD system. The function also supports specifying\n    a timeout for the network request.\n\n    Args:\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        list[NomadUpload]: A list of `NomadUpload` objects, each representing an upload made by the user.\n    \"\"\"\n    logger.info(f\"retrieving all uploads on {'prod' if use_prod else 'test'} server\")\n    response = get_nomad_request(\n        \"/uploads\",\n        use_prod=use_prod,\n        with_authentication=True,\n        timeout_in_sec=timeout_in_sec,\n    )\n    upload_class_schema = class_schema(NomadUpload, base_schema=NomadUploadSchema)\n    return [\n        upload_class_schema().load({**r, \"use_prod\": use_prod})\n        for r in response[\"data\"]\n    ]\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.get_specific_file_from_upload","title":"<code>get_specific_file_from_upload(upload_id, path_to_file, use_prod=False, with_authentication=False, return_json=True, timeout_in_sec=10)</code>","text":"<p>Downloads a file associated with a specific upload from the NOMAD system.</p> <p>This function retrieves a file associated with a specific upload from the NOMAD system and saves it to the specified path on the local filesystem. It allows specifying whether to interact with the production or test environment of the NOMAD system. Additionally, a timeout for the network request can be defined to manage how long the function waits for the file to be downloaded.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload containing the file to download.</p> required <code>path_to_file</code> <code>str</code> <p>The path where the downloaded file should be saved on the local filesystem.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>with_authentication</code> <code>bool</code> <p>Flag indicating whether to include authentication headers in the request.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for the file to be downloaded.                             Defaults to 10 seconds.</p> <code>10</code> <code>return_json</code> <code>bool</code> <p>Flag indicating whether to return the response as JSON or as a byte string.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file cannot be downloaded or saved to the specified path.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_specific_file_from_upload(\n    upload_id: str,\n    path_to_file: str,\n    use_prod: bool = False,\n    with_authentication: bool = False,\n    return_json: bool = True,\n    timeout_in_sec: int = 10,\n) -&gt; Union[ByteString, dict]:\n    \"\"\"\n    Downloads a file associated with a specific upload from the NOMAD system.\n\n    This function retrieves a file associated with a specific upload from the NOMAD system and saves it to the specified\n    path on the local filesystem. It allows specifying whether to interact with the production or test environment of\n    the NOMAD system. Additionally, a timeout for the network request can be defined to manage how long the function\n    waits for the file to be downloaded.\n\n    Args:\n        upload_id (str): The unique identifier of the upload containing the file to download.\n        path_to_file (str): The path where the downloaded file should be saved on the local filesystem.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        with_authentication: Flag indicating whether to include authentication headers in the request.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for the file to be downloaded.\n                                        Defaults to 10 seconds.\n        return_json: Flag indicating whether to return the response as JSON or as a byte string.\n\n    Raises:\n        ValueError: If the file cannot be downloaded or saved to the specified path.\n    \"\"\"\n    logger.info(\n        f\"downloading file {path_to_file} from upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = get_nomad_request(\n        f\"/uploads/{upload_id}/raw/{path_to_file}\",\n        use_prod=use_prod,\n        with_authentication=with_authentication,\n        timeout_in_sec=timeout_in_sec,\n        return_json=return_json,\n    )\n    if response:\n        return response\n    else:\n        raise ValueError(f\"could not download file from upload {upload_id}\")\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.get_upload_by_id","title":"<code>get_upload_by_id(upload_id, use_prod=False, with_authentication=True, timeout_in_sec=10)</code>","text":"<p>Retrieves a specific upload by its ID from the NOMAD system.</p> <p>This function fetches the details of a single upload identified by its unique ID. It allows specifying whether to access the production or test environment of the NOMAD system. Additionally, a timeout for the network request can be defined.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload to retrieve.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>with_authentication</code> <code>bool</code> <p>Flag indicating whether to include authentication headers in the request.</p> <code>True</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>NomadUpload</code> <code>NomadUpload</code> <p>An instance of <code>NomadUpload</code> containing all the metadata and state information of the upload.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def get_upload_by_id(\n    upload_id: str,\n    use_prod: bool = False,\n    with_authentication: bool = True,\n    timeout_in_sec: int = 10,\n) -&gt; NomadUpload:\n    \"\"\"\n    Retrieves a specific upload by its ID from the NOMAD system.\n\n    This function fetches the details of a single upload identified by its unique ID. It allows specifying whether to\n    access the production or test environment of the NOMAD system. Additionally, a timeout for the network request can\n    be defined.\n\n    Args:\n        upload_id (str): The unique identifier of the upload to retrieve.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        with_authentication: Flag indicating whether to include authentication headers in the request.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        NomadUpload: An instance of `NomadUpload` containing all the metadata and state information of the upload.\n    \"\"\"\n    logger.info(\n        f\"retrieving upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = get_nomad_request(\n        f\"/uploads/{upload_id}\",\n        use_prod=use_prod,\n        with_authentication=with_authentication,\n        timeout_in_sec=timeout_in_sec,\n    )\n    upload_class_schema = class_schema(NomadUpload, base_schema=NomadUploadSchema)\n    return upload_class_schema().load({**response[\"data\"], \"use_prod\": use_prod})\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.publish_upload","title":"<code>publish_upload(upload_id, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Publishes a specified upload in the NOMAD system.</p> <p>This function sends a request to the NOMAD system to publish an upload identified by its unique ID. It allows specifying whether to interact with the production or test environment of the NOMAD system. Additionally, a timeout for the network request can be defined to manage how long the function waits for a response from the NOMAD system.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload to be published.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the response from the NOMAD system regarding the publish action.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def publish_upload(\n    upload_id: str, use_prod: bool = False, timeout_in_sec: int = 10\n) -&gt; dict:\n    \"\"\"\n    Publishes a specified upload in the NOMAD system.\n\n    This function sends a request to the NOMAD system to publish an upload identified by its unique ID. It allows\n    specifying whether to interact with the production or test environment of the NOMAD system. Additionally, a timeout\n    for the network request can be defined to manage how long the function waits for a response from the NOMAD system.\n\n    Args:\n        upload_id (str): The unique identifier of the upload to be published.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        dict: A dictionary containing the response from the NOMAD system regarding the publish action.\n    \"\"\"\n    logger.info(\n        f\"publishing upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = post_nomad_request(\n        f\"/uploads/{upload_id}/action/publish\",\n        with_authentication=True,\n        timeout_in_sec=timeout_in_sec,\n    )\n    logger.info(\n        f\"published upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    return response\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.upload_file_to_specified_path","title":"<code>upload_file_to_specified_path(upload_id, remote_path, local_file, use_prod=False, timeout_in_sec=10)</code>","text":"<p>Uploads a file to a specific path within an upload in the NOMAD system.</p> <p>This function uploads a specified file to a specific path within an existing upload in the NOMAD system. It allows the user to choose between the production and test environments. It also supports setting a custom timeout for the upload process to prevent indefinite waiting periods. The function logs the outcome of the upload process, including success or failure messages.</p> <p>Parameters:</p> Name Type Description Default <code>upload_id</code> <code>str</code> <p>The unique identifier of the upload to which the file should be uploaded.</p> required <code>path</code> <code>str</code> <p>The path where the file should be saved within the upload.</p> required <code>file</code> <p>The file to the file to be uploaded.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for the upload to complete.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the response from the NOMAD system regarding the upload action.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def upload_file_to_specified_path(\n    upload_id: str,\n    remote_path: str,\n    local_file: str,\n    use_prod: bool = False,\n    timeout_in_sec: int = 10,\n) -&gt; dict:\n    \"\"\"\n    Uploads a file to a specific path within an upload in the NOMAD system.\n\n    This function uploads a specified file to a specific path within an existing upload in the NOMAD system. It allows\n    the user to choose between the production and test environments. It also supports setting a custom timeout for the\n    upload process to prevent indefinite waiting periods. The function logs the outcome of the upload process, including\n    success or failure messages.\n\n    Args:\n        upload_id (str): The unique identifier of the upload to which the file should be uploaded.\n        path (str): The path where the file should be saved within the upload.\n        file: The file to the file to be uploaded.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for the upload to complete.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        dict: A dictionary containing the response from the NOMAD system regarding the upload action.\n    \"\"\"\n    logger.info(\n        f\"uploading file {local_file} to upload {upload_id} on {'prod' if use_prod else 'test'} server\"\n    )\n    remote_file = f\"{remote_path}{basename(local_file)}\"\n    response = put_nomad_request(\n        f\"/uploads/{upload_id}/raw/{remote_path}?file_name={remote_file}\",\n        with_authentication=True,\n        file=local_file,\n        remote_path_to_file=remote_file,\n        use_prod=use_prod,\n        timeout_in_sec=timeout_in_sec,\n    )\n    upload_class_schema = class_schema(NomadUpload, base_schema=NomadUploadSchema)\n    return upload_class_schema().load({**response[\"data\"], \"use_prod\": use_prod})\n</code></pre>"},{"location":"nomad/uploads/#martignac.nomad.uploads.upload_files_to_nomad","title":"<code>upload_files_to_nomad(filename, use_prod=False, timeout_in_sec=30)</code>","text":"<p>Uploads a file to the NOMAD system.</p> <p>This function uploads a specified file to the NOMAD system, allowing the user to choose between the production and test environments. It also supports setting a custom timeout for the upload process to prevent indefinite waiting periods. The function logs the outcome of the upload process, including success or failure messages.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the file to be uploaded.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to False, which means the test environment is used by default.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for the upload to complete.                             Defaults to 30 seconds.</p> <code>30</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The unique identifier of the upload if successful, otherwise logs an error.</p> <p>Raises:</p> Type Description <code>IOError</code> <p>If the file cannot be opened or read.</p> <code>ValueError</code> <p>If the response from the NOMAD system does not contain an upload ID.</p> Source code in <code>martignac/nomad/uploads.py</code> <pre><code>def upload_files_to_nomad(\n    filename: str, use_prod: bool = False, timeout_in_sec: int = 30\n) -&gt; str:\n    \"\"\"\n    Uploads a file to the NOMAD system.\n\n    This function uploads a specified file to the NOMAD system, allowing the user to choose between the production\n    and test environments. It also supports setting a custom timeout for the upload process to prevent indefinite\n    waiting periods. The function logs the outcome of the upload process, including success or failure messages.\n\n    Args:\n        filename (str): The path to the file to be uploaded.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to False, which means the test environment is used by default.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for the upload to complete.\n                                        Defaults to 30 seconds.\n\n    Returns:\n        str: The unique identifier of the upload if successful, otherwise logs an error.\n\n    Raises:\n        IOError: If the file cannot be opened or read.\n        ValueError: If the response from the NOMAD system does not contain an upload ID.\n    \"\"\"\n    logger.info(f\"uploading file {filename} on {'prod' if use_prod else 'test'} server\")\n    with open(filename, \"rb\") as f:\n        response = post_nomad_request(\n            \"/uploads\",\n            with_authentication=True,\n            data=f,\n            use_prod=use_prod,\n            timeout_in_sec=timeout_in_sec,\n        )\n    upload_id = response.get(\"upload_id\")\n    if upload_id:\n        logger.info(f\"successful upload to {upload_id}\")\n        return upload_id\n    else:\n        logger.error(f\"could not upload {filename}. Response {response}\")\n</code></pre>"},{"location":"nomad/users/","title":"Users","text":""},{"location":"nomad/users/#martignac.nomad.users.NomadUser","title":"<code>NomadUser</code>","text":"<p>Represents a user in the NOMAD system.</p> <p>This class defines the structure for storing user information as retrieved from the NOMAD system. It includes both mandatory and optional fields, with some fields being hidden from the representation for privacy or security reasons.</p> <p>Attributes:</p> Name Type Description <code>user_id</code> <code>str</code> <p>A unique identifier for the user, not shown in the representation.</p> <code>name</code> <code>str</code> <p>The full name of the user.</p> <code>first_name</code> <code>str</code> <p>The user's first name, not shown in the representation.</p> <code>last_name</code> <code>str</code> <p>The user's last name, not shown in the representation.</p> <code>username</code> <code>str</code> <p>The user's username, not shown in the representation.</p> <code>affiliation</code> <code>str</code> <p>The user's affiliated institution or organization, not shown in the representation.</p> <code>affiliation_address</code> <code>str</code> <p>The address of the affiliated institution or organization, not shown in the representation.</p> <code>email</code> <code>Optional[str]</code> <p>The user's email address, optional and not shown in the representation.</p> <code>is_oasis_admin</code> <code>Optional[bool]</code> <p>Flag indicating if the user is an OASIS admin, optional and not shown in the representation.</p> <code>is_admin</code> <code>Optional[bool]</code> <p>Flag indicating if the user is an admin, optional and not shown in the representation.</p> <code>repo_user_id</code> <code>Optional[str]</code> <p>A repository-specific user identifier, optional and not shown in the representation.</p> <code>created</code> <code>Optional[datetime]</code> <p>The date and time when the user was created, optional and not shown in the representation.</p> Source code in <code>martignac/nomad/users.py</code> <pre><code>@dataclass(frozen=True)\nclass NomadUser:\n    \"\"\"\n    Represents a user in the NOMAD system.\n\n    This class defines the structure for storing user information as retrieved from the NOMAD system. It includes\n    both mandatory and optional fields, with some fields being hidden from the representation for privacy or\n    security reasons.\n\n    Attributes:\n        user_id (str): A unique identifier for the user, not shown in the representation.\n        name (str): The full name of the user.\n        first_name (str): The user's first name, not shown in the representation.\n        last_name (str): The user's last name, not shown in the representation.\n        username (str): The user's username, not shown in the representation.\n        affiliation (str): The user's affiliated institution or organization, not shown in the representation.\n        affiliation_address (str): The address of the affiliated institution or organization, not shown in the representation.\n        email (Optional[str]): The user's email address, optional and not shown in the representation.\n        is_oasis_admin (Optional[bool]): Flag indicating if the user is an OASIS admin, optional and not shown in the representation.\n        is_admin (Optional[bool]): Flag indicating if the user is an admin, optional and not shown in the representation.\n        repo_user_id (Optional[str]): A repository-specific user identifier, optional and not shown in the representation.\n        created (Optional[dt.datetime]): The date and time when the user was created, optional and not shown in the representation.\n    \"\"\"\n\n    user_id: str = field(repr=False)\n    name: str\n    first_name: str = field(repr=False)\n    last_name: str = field(repr=False)\n    username: str = field(repr=False)\n    affiliation: str = field(repr=False)\n    affiliation_address: Optional[str] = field(repr=False)\n    email: Optional[str] = field(repr=False, default=None)\n    is_oasis_admin: Optional[bool] = field(repr=False, default=None)\n    is_admin: Optional[bool] = field(repr=False, default=None)\n    repo_user_id: Optional[str] = field(repr=False, default=None)\n    created: Optional[dt.datetime] = field(repr=False, default=None)\n\n    def as_dict(self) -&gt; dict:\n        return asdict(self)\n</code></pre>"},{"location":"nomad/users/#martignac.nomad.users.get_user_by_id","title":"<code>get_user_by_id(user_id, use_prod=True, timeout_in_sec=10)</code>","text":"<p>Retrieves a user's information from the NOMAD system by their unique user ID.</p> <p>This function makes a request to the NOMAD system to fetch the details of a user specified by their unique identifier. It allows the choice between querying the production or test environment of the NOMAD system. The function also supports specifying a timeout for the request. The results are cached to optimize performance and reduce the load on the NOMAD system.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>The unique identifier of the user to retrieve.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to True.</p> <code>True</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>NomadUser</code> <code>NomadUser</code> <p>An instance of <code>NomadUser</code> containing the retrieved user's information.</p> Note <p>The function is decorated with <code>@ttl_cache</code> to cache the results for 180 seconds and limit the cache size to 128 entries.</p> Source code in <code>martignac/nomad/users.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_user_by_id(\n    user_id: str, use_prod: bool = True, timeout_in_sec: int = 10\n) -&gt; NomadUser:\n    \"\"\"\n    Retrieves a user's information from the NOMAD system by their unique user ID.\n\n    This function makes a request to the NOMAD system to fetch the details of a user specified by their unique identifier.\n    It allows the choice between querying the production or test environment of the NOMAD system. The function also\n    supports specifying a timeout for the request. The results are cached to optimize performance and reduce the load\n    on the NOMAD system.\n\n    Args:\n        user_id (str): The unique identifier of the user to retrieve.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to True.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        NomadUser: An instance of `NomadUser` containing the retrieved user's information.\n\n    Note:\n        The function is decorated with `@ttl_cache` to cache the results for 180 seconds and limit the cache size to 128 entries.\n    \"\"\"\n    logger.info(f\"retrieving user {user_id} on {'prod' if use_prod else 'test'} server\")\n    response = get_nomad_request(f\"/users/{user_id}\", timeout_in_sec=timeout_in_sec)\n    user_schema = class_schema(NomadUser)\n    return user_schema().load(response)\n</code></pre>"},{"location":"nomad/users/#martignac.nomad.users.search_users_by_name","title":"<code>search_users_by_name(user_name, use_prod=True, timeout_in_sec=10)</code>","text":"<p>Searches for users in the NOMAD system by name.</p> <p>This function queries the NOMAD system for users whose names match the provided prefix. It leverages caching to reduce the number of requests made for the same query. The search can be directed to either the production or test environment of the NOMAD system. A timeout can be specified to limit the duration of the request.</p> <p>Parameters:</p> Name Type Description Default <code>user_name</code> <code>str</code> <p>The prefix of the user name to search for.</p> required <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to True.</p> <code>True</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>NomadUser</code> <code>NomadUser</code> <p>An instance or list of <code>NomadUser</code> objects matching the search criteria.</p> Note <p>The function is decorated with <code>@ttl_cache</code> to cache the results for 180 seconds and limit the cache size to 128 entries.</p> Source code in <code>martignac/nomad/users.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef search_users_by_name(\n    user_name: str, use_prod: bool = True, timeout_in_sec: int = 10\n) -&gt; NomadUser:\n    \"\"\"\n    Searches for users in the NOMAD system by name.\n\n    This function queries the NOMAD system for users whose names match the provided prefix. It leverages caching to\n    reduce the number of requests made for the same query. The search can be directed to either the production or\n    test environment of the NOMAD system. A timeout can be specified to limit the duration of the request.\n\n    Args:\n        user_name (str): The prefix of the user name to search for.\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to True.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        NomadUser: An instance or list of `NomadUser` objects matching the search criteria.\n\n    Note:\n        The function is decorated with `@ttl_cache` to cache the results for 180 seconds and limit the cache size to 128 entries.\n    \"\"\"\n    logger.info(\n        f\"retrieving user {user_name} on {'prod' if use_prod else 'test'} server\"\n    )\n    response = get_nomad_request(\n        f\"/users?prefix={user_name}\", timeout_in_sec=timeout_in_sec\n    ).get(\"data\", [])\n    return [class_schema(NomadUser)().load(user) for user in response]\n</code></pre>"},{"location":"nomad/users/#martignac.nomad.users.who_am_i","title":"<code>who_am_i(use_prod=True, timeout_in_sec=10)</code>","text":"<p>Retrieves the information of the currently authenticated user from the NOMAD system.</p> <p>This function makes a request to the NOMAD system to fetch the details of the currently authenticated user. It allows specifying whether to query the production or test environment of the NOMAD system. Additionally, a timeout for the request can be defined to manage how long the function waits for a response from the NOMAD system. The results are cached to improve performance and reduce the load on the NOMAD system.</p> <p>Parameters:</p> Name Type Description Default <code>use_prod</code> <code>bool</code> <p>Flag indicating whether to use the production environment of the NOMAD system.                        Defaults to True.</p> <code>True</code> <code>timeout_in_sec</code> <code>int</code> <p>The maximum time in seconds to wait for a response from the NOMAD system.                             Defaults to 10 seconds.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>NomadUser</code> <code>NomadUser</code> <p>An instance of <code>NomadUser</code> containing the information of the currently authenticated user.</p> Note <p>The function is decorated with <code>@ttl_cache</code> to cache the results for 180 seconds and limit the cache size to 128 entries.</p> Source code in <code>martignac/nomad/users.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef who_am_i(use_prod: bool = True, timeout_in_sec: int = 10) -&gt; NomadUser:\n    \"\"\"\n    Retrieves the information of the currently authenticated user from the NOMAD system.\n\n    This function makes a request to the NOMAD system to fetch the details of the currently authenticated user.\n    It allows specifying whether to query the production or test environment of the NOMAD system. Additionally,\n    a timeout for the request can be defined to manage how long the function waits for a response from the NOMAD system.\n    The results are cached to improve performance and reduce the load on the NOMAD system.\n\n    Args:\n        use_prod (bool, optional): Flag indicating whether to use the production environment of the NOMAD system.\n                                   Defaults to True.\n        timeout_in_sec (int, optional): The maximum time in seconds to wait for a response from the NOMAD system.\n                                        Defaults to 10 seconds.\n\n    Returns:\n        NomadUser: An instance of `NomadUser` containing the information of the currently authenticated user.\n\n    Note:\n        The function is decorated with `@ttl_cache` to cache the results for 180 seconds and limit the cache size to 128 entries.\n    \"\"\"\n    logger.info(f\"retrieving self user info on {'prod' if use_prod else 'test'} server\")\n    response = get_nomad_request(\n        \"/users/me\", with_authentication=True, timeout_in_sec=timeout_in_sec\n    )\n    user_schema = class_schema(NomadUser)\n    return user_schema().load(response)\n</code></pre>"},{"location":"nomad/utils/","title":"Utils","text":""},{"location":"nomad/utils/#martignac.nomad.utils.delete_nomad_request","title":"<code>delete_nomad_request(section, headers=None, use_prod=False, timeout_in_sec=TIMEOUT_IN_SEC, with_authentication=False)</code>","text":"<p>Sends a DELETE request to the NOMAD API for a specified section of the database.</p> <p>This function constructs and sends a DELETE request to either the production or test environment of the NOMAD API, based on the provided parameters. It can optionally include authentication in the request headers. The response is expected to be in JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>section</code> <code>str</code> <p>The specific section of the NOMAD API to target with the DELETE request.</p> required <code>headers</code> <code>dict</code> <p>Additional headers to include in the request. Defaults to None.</p> <code>None</code> <code>use_prod</code> <code>bool</code> <p>Determines whether to use the production or test URL for the NOMAD API. Defaults to False.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.</p> <code>TIMEOUT_IN_SEC</code> <code>with_authentication</code> <code>bool</code> <p>If True, includes an authentication token in the request headers. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>json</code> <code>json</code> <p>The response from the NOMAD API in JSON format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the response from the NOMAD API is not successful (status code 200).</p> Source code in <code>martignac/nomad/utils.py</code> <pre><code>@rate_limiter(min_interval=NOMAD_SLEEP_INTERVAL_IN_SECONDS)\ndef delete_nomad_request(\n    section: str,\n    headers: Optional[dict] = None,\n    use_prod: bool = False,\n    timeout_in_sec: int = TIMEOUT_IN_SEC,\n    with_authentication: bool = False,\n) -&gt; json:\n    \"\"\"\n    Sends a DELETE request to the NOMAD API for a specified section of the database.\n\n    This function constructs and sends a DELETE request to either the production or test environment of the NOMAD API,\n    based on the provided parameters. It can optionally include authentication in the request headers. The response is\n    expected to be in JSON format.\n\n    Parameters:\n        section (str): The specific section of the NOMAD API to target with the DELETE request.\n        headers (dict, optional): Additional headers to include in the request. Defaults to None.\n        use_prod (bool): Determines whether to use the production or test URL for the NOMAD API. Defaults to False.\n        timeout_in_sec (int): The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.\n        with_authentication (bool): If True, includes an authentication token in the request headers. Defaults to False.\n\n    Returns:\n        json: The response from the NOMAD API in JSON format.\n\n    Raises:\n        ValueError: If the response from the NOMAD API is not successful (status code 200).\n    \"\"\"\n    if headers is None:\n        headers = {}\n    if with_authentication:\n        token = get_authentication_token(use_prod=use_prod)\n        headers |= {\n            \"Authorization\": f\"Bearer {token}\",\n            \"Accept\": \"application/json\",\n        }\n    url = NOMAD_PROD_URL if use_prod else NOMAD_TEST_URL\n    url += f\"{'/' if section[0] != '/' else ''}{section}\"\n    logger.info(f\"Sending delete request @ {url}\")\n    response = requests.delete(url, headers=headers, timeout=timeout_in_sec)\n    if not response.status_code == 200:\n        raise ValueError(f\"Unexpected response {response.json()}\")\n    return response.json()\n</code></pre>"},{"location":"nomad/utils/#martignac.nomad.utils.get_authentication_token","title":"<code>get_authentication_token(use_prod=False, username=NOMAD_USERNAME, password=NOMAD_PASSWORD, timeout_in_sec=TIMEOUT_IN_SEC)</code>","text":"<p>Retrieves an authentication token from the NOMAD API.</p> <p>This function requests an authentication token by providing user credentials. It supports both production and test environments of the NOMAD API. The function raises an exception if the request fails or if the response status code is not 200.</p> <p>Parameters:</p> Name Type Description Default <code>use_prod</code> <code>bool</code> <p>Flag to determine whether to use the production URL or the test URL. Defaults to False.</p> <code>False</code> <code>username</code> <code>str</code> <p>The username for authentication. Defaults to NOMAD_USERNAME from environment variables.</p> <code>NOMAD_USERNAME</code> <code>password</code> <code>str</code> <p>The password for authentication. Defaults to NOMAD_PASSWORD from environment variables.</p> <code>NOMAD_PASSWORD</code> <code>timeout_in_sec</code> <code>int</code> <p>The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.</p> <code>TIMEOUT_IN_SEC</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The authentication token as a string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the response from the server is not successful (status code 200).</p> Source code in <code>martignac/nomad/utils.py</code> <pre><code>@ttl_cache(maxsize=128, ttl=180)\ndef get_authentication_token(\n    use_prod: bool = False,\n    username: str = NOMAD_USERNAME,\n    password: str = NOMAD_PASSWORD,\n    timeout_in_sec: int = TIMEOUT_IN_SEC,\n) -&gt; str:\n    \"\"\"\n    Retrieves an authentication token from the NOMAD API.\n\n    This function requests an authentication token by providing user credentials. It supports both production\n    and test environments of the NOMAD API. The function raises an exception if the request fails or if the\n    response status code is not 200.\n\n    Parameters:\n        use_prod (bool): Flag to determine whether to use the production URL or the test URL. Defaults to False.\n        username (str): The username for authentication. Defaults to NOMAD_USERNAME from environment variables.\n        password (str): The password for authentication. Defaults to NOMAD_PASSWORD from environment variables.\n        timeout_in_sec (int): The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.\n\n    Returns:\n        str: The authentication token as a string.\n\n    Raises:\n        ValueError: If the response from the server is not successful (status code 200).\n    \"\"\"\n    url = NOMAD_PROD_URL if use_prod else NOMAD_TEST_URL\n    logger.info(f\"Requesting authentication token @ {url}\")\n    response = requests.get(\n        url + \"/auth/token\",\n        params={\"username\": username, \"password\": password},\n        timeout=timeout_in_sec,\n    )\n    if not response.status_code == 200:\n        raise ValueError(f\"Unexpected response {response.json()}\")\n    return response.json().get(\"access_token\")\n</code></pre>"},{"location":"nomad/utils/#martignac.nomad.utils.get_nomad_base_url","title":"<code>get_nomad_base_url(use_prod)</code>","text":"<p>Returns the base URL for the NOMAD API depending on the environment.</p> <p>This function provides the base URL for either the production or test environment of the NOMAD API. It is useful for constructing full API request URLs based on the desired environment.</p> <p>Parameters:</p> Name Type Description Default <code>use_prod</code> <code>bool</code> <p>A flag indicating whether to return the production URL. If False, the test URL is returned.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The base URL for the NOMAD API.</p> Source code in <code>martignac/nomad/utils.py</code> <pre><code>def get_nomad_base_url(use_prod: bool) -&gt; str:\n    \"\"\"\n    Returns the base URL for the NOMAD API depending on the environment.\n\n    This function provides the base URL for either the production or test environment of the NOMAD API. It is useful\n    for constructing full API request URLs based on the desired environment.\n\n    Parameters:\n        use_prod (bool): A flag indicating whether to return the production URL. If False, the test URL is returned.\n\n    Returns:\n        str: The base URL for the NOMAD API.\n    \"\"\"\n    return (NOMAD_PROD_URL if use_prod else NOMAD_TEST_URL).removesuffix(\"/api/v1\")\n</code></pre>"},{"location":"nomad/utils/#martignac.nomad.utils.get_nomad_request","title":"<code>get_nomad_request(section, use_prod=False, timeout_in_sec=TIMEOUT_IN_SEC, headers=None, with_authentication=False, return_json=True, accept_field='application/json')</code>","text":"<p>Sends a GET request to the NOMAD API for a specified section of the database.</p> <p>This function constructs and sends a GET request to either the production or test environment of the NOMAD API, based on the provided parameters. It can optionally include authentication in the request headers. The response can be returned either as JSON or raw content, based on the <code>return_json</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>section</code> <code>str</code> <p>The specific section of the NOMAD API to query.</p> required <code>use_prod</code> <code>bool</code> <p>Determines whether to use the production or test URL for the NOMAD API. Defaults to False.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.</p> <code>TIMEOUT_IN_SEC</code> <code>headers</code> <code>dict</code> <p>Additional headers to include in the request. Defaults to None.</p> <code>None</code> <code>with_authentication</code> <code>bool</code> <p>If True, includes an authentication token in the request headers. Defaults to False.</p> <code>False</code> <code>return_json</code> <code>bool</code> <p>If True, returns the response in JSON format; otherwise, returns raw content. Defaults to True.</p> <code>True</code> <code>accept_field</code> <code>str</code> <p>The value for the 'Accept' header in the request, indicating the desired response format. Defaults to \"application/json\".</p> <code>'application/json'</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The response from the NOMAD API, formatted as JSON or raw content based on the <code>return_json</code> parameter.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the response from the NOMAD API is not successful (status code 200).</p> Source code in <code>martignac/nomad/utils.py</code> <pre><code>@rate_limiter(min_interval=NOMAD_SLEEP_INTERVAL_IN_SECONDS)\ndef get_nomad_request(\n    section: str,\n    use_prod: bool = False,\n    timeout_in_sec: int = TIMEOUT_IN_SEC,\n    headers: Optional[dict] = None,\n    with_authentication: bool = False,\n    return_json: bool = True,\n    accept_field: str = \"application/json\",\n) -&gt; Any:\n    \"\"\"\n    Sends a GET request to the NOMAD API for a specified section of the database.\n\n    This function constructs and sends a GET request to either the production or test environment of the NOMAD API,\n    based on the provided parameters. It can optionally include authentication in the request headers. The response\n    can be returned either as JSON or raw content, based on the `return_json` parameter.\n\n    Parameters:\n        section (str): The specific section of the NOMAD API to query.\n        use_prod (bool): Determines whether to use the production or test URL for the NOMAD API. Defaults to False.\n        timeout_in_sec (int): The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.\n        headers (dict, optional): Additional headers to include in the request. Defaults to None.\n        with_authentication (bool): If True, includes an authentication token in the request headers. Defaults to False.\n        return_json (bool): If True, returns the response in JSON format; otherwise, returns raw content. Defaults to True.\n        accept_field (str): The value for the 'Accept' header in the request, indicating the desired response format. Defaults to \"application/json\".\n\n    Returns:\n        Any: The response from the NOMAD API, formatted as JSON or raw content based on the `return_json` parameter.\n\n    Raises:\n        ValueError: If the response from the NOMAD API is not successful (status code 200).\n    \"\"\"\n    url = NOMAD_PROD_URL if use_prod else NOMAD_TEST_URL\n    url += f\"{'/' if section[0] != '/' else ''}{section}\"\n    logger.info(f\"Sending get request @ {url}\")\n    if headers is None:\n        headers = {}\n    if with_authentication:\n        token = get_authentication_token(use_prod=use_prod)\n        headers |= {\n            \"Authorization\": f\"Bearer {token}\",\n            \"Accept\": accept_field,\n        }\n    response = requests.get(url, headers=headers, timeout=timeout_in_sec)\n    if not response.status_code == 200:\n        raise ValueError(f\"Unexpected response {response.json()}\")\n    if return_json:\n        return response.json()\n    return response.content\n</code></pre>"},{"location":"nomad/utils/#martignac.nomad.utils.post_nomad_request","title":"<code>post_nomad_request(section, headers=None, data=None, json_dict=None, use_prod=False, timeout_in_sec=TIMEOUT_IN_SEC, with_authentication=False)</code>","text":"<p>Sends a POST request to the NOMAD API for a specified section of the database.</p> <p>This function constructs and sends a POST request to either the production or test environment of the NOMAD API, based on the provided parameters. It can optionally include authentication in the request headers and allows for sending data either as form data or JSON. The response is expected to be in JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>section</code> <code>str</code> <p>The specific section of the NOMAD API to target with the POST request.</p> required <code>headers</code> <code>dict</code> <p>Additional headers to include in the request. Defaults to None.</p> <code>None</code> <code>data</code> <code>Any</code> <p>Form data to send with the request. Defaults to None.</p> <code>None</code> <code>json_dict</code> <code>dict</code> <p>JSON data to send with the request. Defaults to None.</p> <code>None</code> <code>use_prod</code> <code>bool</code> <p>Determines whether to use the production or test URL for the NOMAD API. Defaults to False.</p> <code>False</code> <code>timeout_in_sec</code> <code>int</code> <p>The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.</p> <code>TIMEOUT_IN_SEC</code> <code>with_authentication</code> <code>bool</code> <p>If True, includes an authentication token in the request headers. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>json</code> <code>json</code> <p>The response from the NOMAD API in JSON format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the response from the NOMAD API is not successful (status code 200).</p> Source code in <code>martignac/nomad/utils.py</code> <pre><code>@rate_limiter(min_interval=NOMAD_SLEEP_INTERVAL_IN_SECONDS)\ndef post_nomad_request(\n    section: str,\n    headers: Optional[dict] = None,\n    data: Any = None,\n    json_dict: Optional[dict] = None,\n    use_prod: bool = False,\n    timeout_in_sec: int = TIMEOUT_IN_SEC,\n    with_authentication: bool = False,\n) -&gt; json:\n    \"\"\"\n    Sends a POST request to the NOMAD API for a specified section of the database.\n\n    This function constructs and sends a POST request to either the production or test environment of the NOMAD API,\n    based on the provided parameters. It can optionally include authentication in the request headers and allows for\n    sending data either as form data or JSON. The response is expected to be in JSON format.\n\n    Parameters:\n        section (str): The specific section of the NOMAD API to target with the POST request.\n        headers (dict, optional): Additional headers to include in the request. Defaults to None.\n        data (Any, optional): Form data to send with the request. Defaults to None.\n        json_dict (dict, optional): JSON data to send with the request. Defaults to None.\n        use_prod (bool): Determines whether to use the production or test URL for the NOMAD API. Defaults to False.\n        timeout_in_sec (int): The timeout for the request in seconds. Defaults to TIMEOUT_IN_SEC from environment variables.\n        with_authentication (bool): If True, includes an authentication token in the request headers. Defaults to False.\n\n    Returns:\n        json: The response from the NOMAD API in JSON format.\n\n    Raises:\n        ValueError: If the response from the NOMAD API is not successful (status code 200).\n    \"\"\"\n    if headers is None:\n        headers = {}\n    if with_authentication:\n        token = get_authentication_token(use_prod=use_prod)\n        headers |= {\n            \"Authorization\": f\"Bearer {token}\",\n            \"Accept\": \"application/json\",\n        }\n    if data is None:\n        data = {}\n    if json_dict is None:\n        json_dict = {}\n    url = NOMAD_PROD_URL if use_prod else NOMAD_TEST_URL\n    url += f\"{'/' if section[0] != '/' else ''}{section}\"\n    logger.info(f\"Sending post request @ {url}\")\n    response = requests.post(\n        url, headers=headers, json=json_dict, data=data, timeout=timeout_in_sec\n    )\n    if not response.status_code == 200:\n        raise ValueError(f\"Unexpected response {response.json()}\")\n    return response.json()\n</code></pre>"},{"location":"nomad/utils/#martignac.nomad.utils.rate_limiter","title":"<code>rate_limiter(min_interval)</code>","text":"<p>A decorator to enforce a minimum time interval between calls to the decorated function.</p> <p>Parameters:</p> Name Type Description Default <code>min_interval</code> <code>float</code> <p>Minimum time interval between consecutive calls in seconds.</p> required Source code in <code>martignac/nomad/utils.py</code> <pre><code>def rate_limiter(min_interval):\n    \"\"\"\n    A decorator to enforce a minimum time interval between calls to the decorated function.\n\n    Parameters:\n        min_interval (float): Minimum time interval between consecutive calls in seconds.\n    \"\"\"\n\n    def decorator(func):\n        last_call = [0]  # Use a mutable object to keep track of the last call time\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            elapsed = time.time() - last_call[0]\n            if elapsed &lt; min_interval:\n                time.sleep(min_interval - elapsed)\n            result = func(*args, **kwargs)\n            last_call[0] = time.time()\n            return result\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"nomad/workflows/","title":"Workflows","text":""},{"location":"nomad/workflows/#martignac.nomad.workflows.NomadSection","title":"<code>NomadSection</code>  <code>dataclass</code>","text":"<p>Represents a section within a NOMAD workflow or task.</p> <p>This class is used to define and manage the properties of a section, which can be a task, a workflow, or a default type within the NOMAD system. It includes attributes to specify the section's name, type, label, snapshot number, run number, and an optional upload ID. Additional properties provide convenience methods to determine if the section is a task or workflow, to generate a log file path, to construct the section's URL, and to convert the section information into a dictionary format.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the section.</p> <code>section_type</code> <code>SectionType</code> <p>The type of the section, which can be 'task', 'workflow', or 'default'.</p> <code>label</code> <code>str</code> <p>A label for the section, used in generating paths and URLs.</p> <code>snapshot_number</code> <code>int</code> <p>The snapshot number associated with this section, defaulting to 0.</p> <code>run_number</code> <code>int</code> <p>The run number associated with this section, defaulting to 0.</p> <code>upload_id</code> <code>Optional[str]</code> <p>An optional upload ID for the section, defaulting to None.</p> Properties <p>is_task (bool): Returns True if the section is a task, False otherwise. is_workflow (bool): Returns True if the section is a workflow, False otherwise. log_file (Optional[str]): Returns the log file path if the section is not a task, None otherwise. section (str): Constructs and returns the section's URL based on its properties. upload_prefix (str): Constructs and returns the upload prefix URL for the section.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Converts the section's attributes into a dictionary.</p> <code>add_job_id</code> <p>Job) -&gt; 'NomadSection': Adds a job ID to the section's label if applicable.</p> Source code in <code>martignac/nomad/workflows.py</code> <pre><code>@dataclass\nclass NomadSection:\n    \"\"\"\n    Represents a section within a NOMAD workflow or task.\n\n    This class is used to define and manage the properties of a section, which can be a task, a workflow, or a default\n    type within the NOMAD system. It includes attributes to specify the section's name, type, label, snapshot number,\n    run number, and an optional upload ID. Additional properties provide convenience methods to determine if the\n    section is a task or workflow, to generate a log file path, to construct the section's URL, and to convert the\n    section information into a dictionary format.\n\n    Attributes:\n        name (str): The name of the section.\n        section_type (SectionType): The type of the section, which can be 'task', 'workflow', or 'default'.\n        label (str): A label for the section, used in generating paths and URLs.\n        snapshot_number (int): The snapshot number associated with this section, defaulting to 0.\n        run_number (int): The run number associated with this section, defaulting to 0.\n        upload_id (Optional[str]): An optional upload ID for the section, defaulting to None.\n\n    Properties:\n        is_task (bool): Returns True if the section is a task, False otherwise.\n        is_workflow (bool): Returns True if the section is a workflow, False otherwise.\n        log_file (Optional[str]): Returns the log file path if the section is not a task, None otherwise.\n        section (str): Constructs and returns the section's URL based on its properties.\n        upload_prefix (str): Constructs and returns the upload prefix URL for the section.\n\n    Methods:\n        to_dict() -&gt; dict: Converts the section's attributes into a dictionary.\n        add_job_id(job_: Job) -&gt; 'NomadSection': Adds a job ID to the section's label if applicable.\n    \"\"\"\n\n    name: str\n    section_type: SectionType\n    label: str\n    snapshot_number: int = 0\n    run_number: int = 0\n    upload_id: Optional[str] = None\n\n    @property\n    def is_task(self) -&gt; bool:\n        return self.section_type == \"task\"\n\n    @property\n    def is_workflow(self) -&gt; bool:\n        return self.section_type == \"workflow\"\n\n    @property\n    def log_file(self) -&gt; Optional[str]:\n        return self.label if not self.is_task else None\n\n    @property\n    def section(self) -&gt; str:\n        return f\"{self.upload_prefix}#/run/{self.run_number}/calculation/{self.snapshot_number}\"\n\n    @property\n    def upload_prefix(self) -&gt; str:\n        upload_prefix = f\"/uploads/{self.upload_id}\" if self.upload_id else \"../upload\"\n        return (\n            f\"{upload_prefix}/archive/mainfile/{self.log_file}\" if self.log_file else \"\"\n        )\n\n    def to_dict(self) -&gt; dict:\n        return {\"name\": self.name, \"section\": self.section}\n\n    def add_job_id(self, job_: Job) -&gt; \"NomadSection\":\n        if job_.id not in self.label and self.label != \"run\" and not self.upload_id:\n            self.label = f\"{job_.id}/{self.label}\"\n        return self\n</code></pre>"},{"location":"nomad/workflows/#martignac.nomad.workflows.NomadTask","title":"<code>NomadTask</code>  <code>dataclass</code>","text":"<p>Represents a task within a NOMAD workflow.</p> <p>This class is designed to encapsulate the details of a task in the NOMAD system, including its name, definition, inputs, outputs, and an optional task-specific section. It provides a structured way to manage tasks within workflows, facilitating the creation, manipulation, and serialization of task-related information.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the task, serving as a unique identifier within the workflow.</p> <code>m_def</code> <code>str</code> <p>The metainfo definition for the task, defaulting to a predefined value.</p> <code>inputs</code> <code>list[NomadSection]</code> <p>A list of <code>NomadSection</code> instances representing the inputs to the task.</p> <code>outputs</code> <code>list[NomadSection]</code> <p>A list of <code>NomadSection</code> instances representing the outputs from the task.</p> <code>task_section</code> <code>Optional[NomadSection]</code> <p>An optional <code>NomadSection</code> instance representing a task-specific section.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>A post-initialization method to set default names for inputs and outputs.</p> <code>task</code> <p>A property that returns the task's URL if it is not a task-specific section.</p> <code>to_dict</code> <p>Serializes the task's attributes into a dictionary for easy export and manipulation.</p> Source code in <code>martignac/nomad/workflows.py</code> <pre><code>@dataclass\nclass NomadTask:\n    \"\"\"\n    Represents a task within a NOMAD workflow.\n\n    This class is designed to encapsulate the details of a task in the NOMAD system, including its name, definition,\n    inputs, outputs, and an optional task-specific section. It provides a structured way to manage tasks within\n    workflows, facilitating the creation, manipulation, and serialization of task-related information.\n\n    Attributes:\n        name (str): The name of the task, serving as a unique identifier within the workflow.\n        m_def (str): The metainfo definition for the task, defaulting to a predefined value.\n        inputs (list[NomadSection]): A list of `NomadSection` instances representing the inputs to the task.\n        outputs (list[NomadSection]): A list of `NomadSection` instances representing the outputs from the task.\n        task_section (Optional[NomadSection]): An optional `NomadSection` instance representing a task-specific section.\n\n    Methods:\n        __post_init__(self): A post-initialization method to set default names for inputs and outputs.\n        task(self) -&gt; Optional[str]: A property that returns the task's URL if it is not a task-specific section.\n        to_dict(self) -&gt; dict: Serializes the task's attributes into a dictionary for easy export and manipulation.\n    \"\"\"\n\n    name: str\n    m_def: str = DEFAULT_M_DEF\n    inputs: list[NomadSection] = field(default_factory=list)\n    outputs: list[NomadSection] = field(default_factory=list)\n    task_section: Optional[NomadSection] = None\n\n    def __post_init__(self):\n        for i in range(len(self.inputs)):\n            self.inputs[i].name = \"input\"\n        for i in range(len(self.outputs)):\n            self.outputs[i].name = \"output\"\n\n    @property\n    def task(self) -&gt; Optional[str]:\n        if self.task_section.is_task:\n            return None\n        return self.task_section.upload_prefix + \"#/workflow2\"\n\n    def to_dict(self) -&gt; dict:\n        output_dict = {\n            \"name\": self.name,\n            \"m_def\": self.m_def,\n            \"inputs\": [i.to_dict() for i in self.inputs],\n            \"outputs\": [o.to_dict() for o in self.outputs],\n        }\n        if self.task:\n            output_dict[\"task\"] = self.task\n        return output_dict\n</code></pre>"},{"location":"nomad/workflows/#martignac.nomad.workflows.NomadWorkflow","title":"<code>NomadWorkflow</code>  <code>dataclass</code>","text":"<p>Manages the construction and serialization of a NOMAD workflow.</p> <p>This class is responsible for creating a representation of a workflow within the NOMAD system, which includes tasks, inputs, and outputs as defined by the user's project and job configurations. It utilizes the project's operations and the job's documentation to construct a directed graph representing the workflow, which can then be serialized to a YAML file for use within the NOMAD system.</p> <p>Attributes:</p> Name Type Description <code>project</code> <code>MartiniFlowProject</code> <p>The project instance containing operations and configurations for the workflow.</p> <code>job</code> <code>Job</code> <p>The job instance containing specific execution details and documentation for the workflow.</p> <code>is_top_level</code> <code>bool</code> <p>Flag indicating if the workflow is at the top level of the project hierarchy.</p> <code>add_job_id</code> <code>bool</code> <p>Flag indicating if the job ID should be added to section labels for uniqueness.</p> Properties <p>project_name (str): Returns the name of the project class. gromacs_logs (dict): Retrieves GROMACS log entries from the job's documentation. tasks (dict): Retrieves task entries from the job's documentation. workflows (dict): Retrieves workflow entries from the job's documentation if <code>is_top_level</code> is True. all_tasks (dict): Aggregates all tasks, workflows, and GROMACS logs into a single dictionary. graph (nx.DiGraph): Constructs and returns a directed graph representing the workflow structure.</p> <p>Methods:</p> Name Description <code>register_section</code> <p>str): Registers a section (task, workflow, or default) based on the operation name.</p> <code>build_workflow_yaml</code> <p>str): Serializes the workflow to a YAML file.</p> <code>generate_archive</code> <p>Generates a <code>NomadWorkflowArchive</code> instance representing the workflow.</p> <code>_section_type</code> <p>str) -&gt; SectionType: Determines the section type (task, workflow, default) for a given operation name.</p> Source code in <code>martignac/nomad/workflows.py</code> <pre><code>@dataclass\nclass NomadWorkflow:\n    \"\"\"\n    Manages the construction and serialization of a NOMAD workflow.\n\n    This class is responsible for creating a representation of a workflow within the NOMAD system, which includes\n    tasks, inputs, and outputs as defined by the user's project and job configurations. It utilizes the project's\n    operations and the job's documentation to construct a directed graph representing the workflow, which can then\n    be serialized to a YAML file for use within the NOMAD system.\n\n    Attributes:\n        project (MartiniFlowProject): The project instance containing operations and configurations for the workflow.\n        job (Job): The job instance containing specific execution details and documentation for the workflow.\n        is_top_level (bool): Flag indicating if the workflow is at the top level of the project hierarchy.\n        add_job_id (bool): Flag indicating if the job ID should be added to section labels for uniqueness.\n\n    Properties:\n        project_name (str): Returns the name of the project class.\n        gromacs_logs (dict): Retrieves GROMACS log entries from the job's documentation.\n        tasks (dict): Retrieves task entries from the job's documentation.\n        workflows (dict): Retrieves workflow entries from the job's documentation if `is_top_level` is True.\n        all_tasks (dict): Aggregates all tasks, workflows, and GROMACS logs into a single dictionary.\n        graph (nx.DiGraph): Constructs and returns a directed graph representing the workflow structure.\n\n    Methods:\n        register_section(operation_name: str): Registers a section (task, workflow, or default) based on the operation name.\n        build_workflow_yaml(destination_filename: str): Serializes the workflow to a YAML file.\n        generate_archive() -&gt; NomadWorkflowArchive: Generates a `NomadWorkflowArchive` instance representing the workflow.\n        _section_type(operation_name: str) -&gt; SectionType: Determines the section type (task, workflow, default) for a given operation name.\n    \"\"\"\n\n    project: MartiniFlowProject\n    job: Job\n    is_top_level: bool\n    add_job_id: bool = False\n\n    def __post_init__(self):\n        self.task_elements: Dict[str, NomadSection] = {}\n        self.task_counter: int = 0\n\n    @property\n    def project_name(self) -&gt; str:\n        return self.project.__class__.__name__\n\n    @property\n    def gromacs_logs(self) -&gt; dict:\n        return self.job.doc[self.project_name].get(\"gromacs_logs\", {})\n\n    @property\n    def tasks(self) -&gt; dict:\n        return self.job.doc[self.project_name].get(\"tasks\", {})\n\n    @property\n    def workflows(self) -&gt; dict:\n        return (\n            self.job.doc[self.project_name].get(\"workflows\", {})\n            if self.is_top_level\n            else {}\n        )\n\n    @property\n    def all_tasks(self) -&gt; dict:\n        return dict(self.gromacs_logs) | dict(self.tasks) | dict(self.workflows)\n\n    def register_section(self, operation_name: str) -&gt; None:\n        section_type = self._section_type(operation_name)\n        label = self.all_tasks[operation_name]\n        if section_type == \"workflow\":\n            label = self.job.doc[self.all_tasks[operation_name]].get(\n                \"nomad_workflow\", self.all_tasks[operation_name]\n            )\n        upload_id = (\n            self.job.doc[self.all_tasks[operation_name]].get(\"nomad_upload_id\", None)\n            if section_type == \"workflow\"\n            else None\n        )\n        section = NomadSection(\n            name=operation_name,\n            section_type=section_type,\n            label=label,\n            run_number=self.task_counter if section_type == \"task\" else 0,\n            upload_id=upload_id,\n        )\n        if section.is_task:\n            self.task_counter += 1\n        if self.add_job_id:\n            section.add_job_id(self.job)\n        self.task_elements[operation_name] = section\n\n    @cached_property\n    def graph(self) -&gt; nx.DiGraph:\n        operations = list(self.project.operations.keys())\n        adjacency_matrix = np.asarray(self.project.detect_operation_graph())\n        signac_graph = nx.DiGraph(adjacency_matrix)\n        graph = nx.DiGraph()\n        all_tasks = dict(self.gromacs_logs) | dict(self.tasks) | dict(self.workflows)\n        for node_index in signac_graph.nodes:\n            op_name = operations[node_index]\n            if op_name in all_tasks:\n                graph.add_node(\n                    op_name, label=all_tasks[op_name], is_task=op_name in self.tasks\n                )\n                self.register_section(op_name)\n        for node_1, node_2 in signac_graph.edges:\n            if (op_name_1 := operations[node_1]) in graph.nodes and (\n                op_name_2 := operations[node_2]\n            ) in graph.nodes:\n                graph.add_edge(op_name_1, op_name_2)\n        return graph\n\n    def build_workflow_yaml(self, destination_filename: str) -&gt; None:\n        archive = self.generate_archive()\n        archive.to_yaml(destination_filename)\n        project_name = self.project.class_name()\n        self.job.doc = update_nested_dict(\n            self.job.doc, {project_name: {\"nomad_workflow\": destination_filename}}\n        )\n\n    def generate_archive(self) -&gt; NomadWorkflowArchive:\n        archive = NomadWorkflowArchive()\n        archive.inputs = []\n        for node in [n for n, d in self.graph.in_degree if d == 0]:\n            element = self.task_elements[node]\n            archive.inputs.append(element)\n\n        for node in [n for n, d in self.graph.out_degree if d == 0]:\n            element = self.task_elements[node]\n            element.snapshot_number = -1\n            archive.outputs.append(element)\n        node_names = list(self.graph.nodes)\n        for _i, node_name in enumerate(node_names):\n            in_nodes = [n for n, _ in self.graph.in_edges([node_name])]\n            out_nodes = [n for _, n in self.graph.out_edges([node_name])]\n            if not in_nodes:\n                input_node = copy(self.task_elements[node_name])\n                task_inputs = [input_node]\n            else:\n                if all(self.task_elements[n].is_task for n in in_nodes):\n                    task_inputs = [copy(self.task_elements[node_name])]\n                else:\n                    task_inputs = [copy(self.task_elements[n]) for n in in_nodes]\n                    for _input in task_inputs:\n                        _input.snapshot_number = -1\n            if not out_nodes:\n                output_node = copy(self.task_elements[node_name])\n                task_outputs = [output_node]\n            else:\n                if self.task_elements[node_name].is_task:\n                    task_outputs = [copy(self.task_elements[n]) for n in out_nodes]\n                else:\n                    task_outputs = [copy(self.task_elements[node_name])]\n                    for _output in task_outputs:\n                        _output.snapshot_number = -1\n            archive.tasks.append(\n                NomadTask(\n                    node_name,\n                    inputs=task_inputs,\n                    outputs=task_outputs,\n                    task_section=self.task_elements[node_name],\n                )\n            )\n        return archive\n\n    def _section_type(self, operation_name: str) -&gt; SectionType:\n        if operation_name in self.tasks:\n            return \"task\"\n        elif operation_name in self.workflows:\n            return \"workflow\"\n        return \"default\"\n</code></pre>"},{"location":"nomad/workflows/#martignac.nomad.workflows.NomadWorkflowArchive","title":"<code>NomadWorkflowArchive</code>  <code>dataclass</code>","text":"<p>Represents the archival structure of a NOMAD workflow.</p> <p>This class encapsulates the structure necessary for representing a complete NOMAD workflow, including its inputs, outputs, and the tasks that comprise the workflow. It provides methods for serializing the workflow to a dictionary and saving it as a YAML file, which can be used for workflow reconstruction or analysis. Additionally, it offers a class method for creating a workflow archive from multiple jobs, allowing for the aggregation of tasks and data across different computational jobs within the same project.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the workflow, used as a key in the serialized output.</p> <code>inputs</code> <code>list[NomadSection]</code> <p>A list of sections representing the inputs to the workflow.</p> <code>outputs</code> <code>list[NomadSection]</code> <p>A list of sections representing the outputs from the workflow.</p> <code>tasks</code> <code>list[NomadTask]</code> <p>A list of tasks that are part of the workflow.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Serializes the workflow archive to a dictionary.</p> <code>to_yaml</code> <p>str) -&gt; None: Saves the serialized workflow archive as a YAML file to the specified location.</p> <code>from_multiple_jobs</code> <p>MartiniFlowProject, jobs: list[Job], aggregate_same_task_names: bool = True) -&gt; 'NomadWorkflowArchive': Class method to create a workflow archive from multiple jobs, optionally aggregating tasks with the same name.</p> Source code in <code>martignac/nomad/workflows.py</code> <pre><code>@dataclass\nclass NomadWorkflowArchive:\n    \"\"\"\n    Represents the archival structure of a NOMAD workflow.\n\n    This class encapsulates the structure necessary for representing a complete NOMAD workflow, including its inputs,\n    outputs, and the tasks that comprise the workflow. It provides methods for serializing the workflow to a dictionary\n    and saving it as a YAML file, which can be used for workflow reconstruction or analysis. Additionally, it offers a\n    class method for creating a workflow archive from multiple jobs, allowing for the aggregation of tasks and data\n    across different computational jobs within the same project.\n\n    Attributes:\n        name (str): The name of the workflow, used as a key in the serialized output.\n        inputs (list[NomadSection]): A list of sections representing the inputs to the workflow.\n        outputs (list[NomadSection]): A list of sections representing the outputs from the workflow.\n        tasks (list[NomadTask]): A list of tasks that are part of the workflow.\n\n    Methods:\n        to_dict(self) -&gt; dict: Serializes the workflow archive to a dictionary.\n        to_yaml(self, destination_filename: str) -&gt; None: Saves the serialized workflow archive as a YAML file to the specified location.\n        from_multiple_jobs(cls, project: MartiniFlowProject, jobs: list[Job], aggregate_same_task_names: bool = True) -&gt; 'NomadWorkflowArchive':\n            Class method to create a workflow archive from multiple jobs, optionally aggregating tasks with the same name.\n    \"\"\"\n\n    name: str = \"workflow2\"\n    inputs: list[NomadSection] = field(default_factory=list)\n    outputs: list[NomadSection] = field(default_factory=list)\n    tasks: list[NomadTask] = field(default_factory=list)\n\n    def to_dict(self) -&gt; dict:\n        return {\n            self.name: {\n                \"inputs\": [i.to_dict() for i in self.inputs],\n                \"outputs\": [o.to_dict() for o in self.outputs],\n                \"tasks\": [t.to_dict() for t in self.tasks],\n            },\n        }\n\n    def to_yaml(self, destination_filename: str) -&gt; None:\n        with open(destination_filename, \"w\") as f:\n            yaml.dump(self.to_dict(), f)\n\n    @classmethod\n    def from_multiple_jobs(\n        cls,\n        project: MartiniFlowProject,\n        jobs: list[Job],\n        aggregate_same_task_names: bool = True,\n    ) -&gt; \"NomadWorkflowArchive\":\n        def filter_unique(ele):\n            final_inputs = []\n            for inp in ele:\n                if inp not in final_inputs:\n                    final_inputs.append(inp)\n            return final_inputs\n\n        archive = NomadWorkflowArchive()\n        for job in jobs:\n            workflow = NomadWorkflow(project, job, is_top_level=True)\n            job_inputs = [\n                inp.add_job_id(job) for inp in copy(workflow.generate_archive().inputs)\n            ]\n            archive.inputs.extend(job_inputs)\n            job_outputs = [\n                out.add_job_id(job) for out in copy(workflow.generate_archive().outputs)\n            ]\n            archive.outputs.extend(job_outputs)\n            job_tasks = copy(workflow.generate_archive().tasks)\n\n            for task in job_tasks:\n                task.inputs = [inp.add_job_id(job) for inp in task.inputs]\n                task.outputs = [out.add_job_id(job) for out in task.outputs]\n                task.task_section = task.task_section.add_job_id(job)\n            archive.tasks.extend(job_tasks)\n\n        if aggregate_same_task_names:\n            final_tasks = []\n            for task in archive.tasks:\n                if task.name not in [t.name for t in final_tasks]:\n                    final_tasks.append(task)\n                else:\n                    dest_task = next(t for t in final_tasks if t.name == task.name)\n                    dest_task.inputs = filter_unique(dest_task.inputs)\n                    dest_task.outputs = filter_unique(dest_task.outputs)\n            archive.tasks = final_tasks\n\n        archive.inputs = filter_unique(archive.inputs)\n        archive.outputs = filter_unique(archive.outputs)\n        archive.tasks = filter_unique(archive.tasks)\n        return archive\n</code></pre>"},{"location":"nomad/workflows/#martignac.nomad.workflows.build_nomad_workflow","title":"<code>build_nomad_workflow(job, is_top_level=False, add_job_id=False)</code>","text":"<p>Builds and serializes a NOMAD workflow for a given job.</p> <p>This function initializes a <code>NomadWorkflow</code> instance with the specified job and configuration flags, then serializes the constructed workflow into a YAML file. The YAML file is saved in a location determined by whether the workflow is considered top-level or not. If <code>is_top_level</code> is True, the workflow is saved using the <code>nomad_top_level_workflow</code> path from the project; otherwise, it uses the <code>nomad_workflow</code> path. The <code>add_job_id</code> flag determines whether job IDs should be added to section labels to ensure uniqueness.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job instance for which the workflow is being built.</p> required <code>is_top_level</code> <code>bool</code> <p>Flag indicating if the workflow is at the top level of the project hierarchy.                            Defaults to False.</p> <code>False</code> <code>add_job_id</code> <code>bool</code> <p>Flag indicating if the job ID should be added to section labels for uniqueness.                          Defaults to False.</p> <code>False</code> Source code in <code>martignac/nomad/workflows.py</code> <pre><code>def build_nomad_workflow(job, is_top_level: bool = False, add_job_id: bool = False):\n    \"\"\"\n    Builds and serializes a NOMAD workflow for a given job.\n\n    This function initializes a `NomadWorkflow` instance with the specified job and configuration flags,\n    then serializes the constructed workflow into a YAML file. The YAML file is saved in a location determined\n    by whether the workflow is considered top-level or not. If `is_top_level` is True, the workflow is saved\n    using the `nomad_top_level_workflow` path from the project; otherwise, it uses the `nomad_workflow` path.\n    The `add_job_id` flag determines whether job IDs should be added to section labels to ensure uniqueness.\n\n    Args:\n        job (Job): The job instance for which the workflow is being built.\n        is_top_level (bool, optional): Flag indicating if the workflow is at the top level of the project hierarchy.\n                                       Defaults to False.\n        add_job_id (bool, optional): Flag indicating if the job ID should be added to section labels for uniqueness.\n                                     Defaults to False.\n    \"\"\"\n    project = cast(MartiniFlowProject, job.project)\n    workflow = NomadWorkflow(project, job, is_top_level, add_job_id=add_job_id)\n    destination_filename = (\n        project.nomad_top_level_workflow if is_top_level else project.nomad_workflow\n    )\n    workflow.build_workflow_yaml(destination_filename)\n</code></pre>"},{"location":"nomad/workflows/#martignac.nomad.workflows.build_nomad_workflow_with_multiple_jobs","title":"<code>build_nomad_workflow_with_multiple_jobs(project, jobs)</code>","text":"<p>Builds and serializes a NOMAD workflow archive for multiple jobs within a project.</p> <p>This function aggregates the workflows of multiple jobs into a single NOMAD workflow archive. It utilizes the <code>NomadWorkflowArchive.from_multiple_jobs</code> class method to create an archive that represents the combined workflow of the specified jobs. The resulting workflow archive is then serialized into a YAML file, which is saved using the <code>nomad_top_level_workflow</code> path from the project. This allows for the analysis and reconstruction of complex workflows that span multiple computational jobs within the same project.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>MartiniFlowProject</code> <p>The project instance containing operations and configurations for the workflow.</p> required <code>jobs</code> <code>list[Job]</code> <p>A list of job instances to be included in the workflow archive.</p> required Source code in <code>martignac/nomad/workflows.py</code> <pre><code>def build_nomad_workflow_with_multiple_jobs(\n    project: MartiniFlowProject, jobs: list[Job]\n):\n    \"\"\"\n    Builds and serializes a NOMAD workflow archive for multiple jobs within a project.\n\n    This function aggregates the workflows of multiple jobs into a single NOMAD workflow archive. It utilizes the\n    `NomadWorkflowArchive.from_multiple_jobs` class method to create an archive that represents the combined workflow\n    of the specified jobs. The resulting workflow archive is then serialized into a YAML file, which is saved using\n    the `nomad_top_level_workflow` path from the project. This allows for the analysis and reconstruction of complex\n    workflows that span multiple computational jobs within the same project.\n\n    Args:\n        project (MartiniFlowProject): The project instance containing operations and configurations for the workflow.\n        jobs (list[Job]): A list of job instances to be included in the workflow archive.\n    \"\"\"\n    archive = NomadWorkflowArchive.from_multiple_jobs(project, jobs)\n    destination_filename = project.nomad_top_level_workflow\n    archive.to_yaml(destination_filename)\n</code></pre>"},{"location":"parsers/gromacs_forcefields/","title":"GROMACS forcefields","text":""},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.Angle","title":"<code>Angle</code>  <code>dataclass</code>","text":"<p>Represents an angle formed by three atoms in a molecule.</p> <p>This class models an angle, which is defined by three atoms, typically used to represent the geometric structure of a molecule. Angles are crucial in molecular dynamics simulations for defining the spatial arrangement of atoms and calculating potential energy based on geometric constraints.</p> <p>Attributes:</p> Name Type Description <code>id_i</code> <code>int</code> <p>The identifier of the first atom forming the angle.</p> <code>id_j</code> <code>int</code> <p>The identifier of the second atom (vertex) forming the angle.</p> <code>id_k</code> <code>int</code> <p>The identifier of the third atom forming the angle.</p> <code>funct</code> <code>int</code> <p>The function type of the angle. In GROMACS, this typically refers to the type of angle potential used.</p> <code>angle</code> <code>float</code> <p>The value of the angle, usually in degrees.</p> <code>force_constant</code> <code>float</code> <p>The force constant of the angle, describing its stiffness.</p> Class Methods <p>parse_from_itp_entry(cls, entry: list) -&gt; \"Angle\": Parses angle information from a given entry in a topology file.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>@dataclass\nclass Angle:\n    \"\"\"\n    Represents an angle formed by three atoms in a molecule.\n\n    This class models an angle, which is defined by three atoms, typically used to represent the geometric\n    structure of a molecule. Angles are crucial in molecular dynamics simulations for defining the spatial\n    arrangement of atoms and calculating potential energy based on geometric constraints.\n\n    Attributes:\n        id_i (int): The identifier of the first atom forming the angle.\n        id_j (int): The identifier of the second atom (vertex) forming the angle.\n        id_k (int): The identifier of the third atom forming the angle.\n        funct (int): The function type of the angle. In GROMACS, this typically refers to the type of angle potential used.\n        angle (float): The value of the angle, usually in degrees.\n        force_constant (float): The force constant of the angle, describing its stiffness.\n\n    Class Methods:\n        parse_from_itp_entry(cls, entry: list) -&gt; \"Angle\": Parses angle information from a given entry in a topology file.\n    \"\"\"\n\n    id_i: int\n    id_j: int\n    id_k: int\n    funct: int\n    angle: float\n    force_constant: float\n\n    @classmethod\n    def parse_from_itp_entry(cls, entry: list) -&gt; \"Angle\":\n        return Angle(\n            int(entry[0]),\n            int(entry[1]),\n            int(entry[2]),\n            int(entry[3]),\n            float(entry[4]),\n            float(entry[5]),\n        )\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.Atom","title":"<code>Atom</code>  <code>dataclass</code>","text":"<p>Represents an atom within a molecule.</p> <p>This class models an atom's properties, including its unique identifier, type, residue information, and charge. It also provides a class method to parse atom information from a topology file entry.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>int</code> <p>Unique identifier of the atom within the molecule.</p> <code>type</code> <code>str</code> <p>Type of the atom, defining its chemical characteristics.</p> <code>residue_number</code> <code>int</code> <p>Identifier of the residue the atom belongs to.</p> <code>residue</code> <code>str</code> <p>Name of the residue the atom belongs to.</p> <code>atom</code> <code>str</code> <p>Name of the atom.</p> <code>charge_number</code> <code>int</code> <p>Identifier for the charge group the atom belongs to.</p> <code>charge</code> <code>int</code> <p>The charge of the atom.</p> Class Methods <p>parse_from_itp_entry(cls, entry: list) -&gt; \"Atom\": Parses atom information from a given topology file entry and returns an Atom instance.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>@dataclass\nclass Atom:\n    \"\"\"\n    Represents an atom within a molecule.\n\n    This class models an atom's properties, including its unique identifier, type, residue information, and charge.\n    It also provides a class method to parse atom information from a topology file entry.\n\n    Attributes:\n        id (int): Unique identifier of the atom within the molecule.\n        type (str): Type of the atom, defining its chemical characteristics.\n        residue_number (int): Identifier of the residue the atom belongs to.\n        residue (str): Name of the residue the atom belongs to.\n        atom (str): Name of the atom.\n        charge_number (int): Identifier for the charge group the atom belongs to.\n        charge (int): The charge of the atom.\n\n    Class Methods:\n        parse_from_itp_entry(cls, entry: list) -&gt; \"Atom\": Parses atom information from a given topology file entry and returns an Atom instance.\n    \"\"\"\n\n    id: int\n    type: str\n    residue_number: int\n    residue: str\n    atom: str\n    charge_number: int\n    charge: int\n\n    @classmethod\n    def parse_from_itp_entry(cls, entry: list) -&gt; \"Atom\":\n        return Atom(\n            int(entry[0]),\n            str(entry[1]),\n            int(entry[2]),\n            str(entry[3]),\n            str(entry[4]),\n            int(entry[5]),\n            int(entry[6]),\n        )\n\n    @property\n    def is_charged(self) -&gt; bool:\n        return self.charge != 0\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.Bond","title":"<code>Bond</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Constraint</code></p> <p>Represents a bond between two atoms in a molecule, extending the Constraint class.</p> <p>This class models a bond as a specialized type of constraint with an additional attribute for the force constant. Bonds are used to define the fixed distance between two atoms along with the force constant that describes the strength of the bond. This is particularly useful in molecular dynamics simulations for defining the interactions and energy calculations between atoms.</p> <p>Attributes:</p> Name Type Description <code>id_i</code> <code>int</code> <p>The identifier of the first atom in the bond.</p> <code>id_j</code> <code>int</code> <p>The identifier of the second atom in the bond.</p> <code>funct</code> <code>int</code> <p>The function type of the bond. In GROMACS, this typically refers to the type of bond algorithm used.</p> <code>length</code> <code>float</code> <p>The length of the bond, usually in nanometers.</p> <code>force_constant</code> <code>float</code> <p>The force constant of the bond, describing its strength.</p> Class Methods <p>parse_from_itp_entry(cls, entry: list) -&gt; \"Bond\": Parses a bond from a given entry in a topology file, extending the Constraint class method with an additional parameter for the force constant.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>@dataclass\nclass Bond(Constraint):\n    \"\"\"\n    Represents a bond between two atoms in a molecule, extending the Constraint class.\n\n    This class models a bond as a specialized type of constraint with an additional attribute for the force constant.\n    Bonds are used to define the fixed distance between two atoms along with the force constant that describes the\n    strength of the bond. This is particularly useful in molecular dynamics simulations for defining the interactions\n    and energy calculations between atoms.\n\n    Attributes:\n        id_i (int): The identifier of the first atom in the bond.\n        id_j (int): The identifier of the second atom in the bond.\n        funct (int): The function type of the bond. In GROMACS, this typically refers to the type of bond algorithm used.\n        length (float): The length of the bond, usually in nanometers.\n        force_constant (float): The force constant of the bond, describing its strength.\n\n    Class Methods:\n        parse_from_itp_entry(cls, entry: list) -&gt; \"Bond\": Parses a bond from a given entry in a topology file, extending the Constraint class method with an additional parameter for the force constant.\n    \"\"\"\n\n    force_constant: float\n\n    @classmethod\n    def parse_from_itp_entry(cls, entry: list) -&gt; \"Bond\":\n        return Bond(\n            int(entry[0]),\n            int(entry[1]),\n            int(entry[2]),\n            float(entry[3]),\n            float(entry[4]),\n        )\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.Constraint","title":"<code>Constraint</code>  <code>dataclass</code>","text":"<p>Represents a constraint between two atoms in a molecule.</p> <p>This class models a constraint, which is a fixed distance between two atoms, typically used to maintain a certain structure within the molecule. Constraints are often used in molecular dynamics simulations to simplify the model or enforce certain conditions.</p> <p>Attributes:</p> Name Type Description <code>id_i</code> <code>int</code> <p>The identifier of the first atom in the constraint.</p> <code>id_j</code> <code>int</code> <p>The identifier of the second atom in the constraint.</p> <code>funct</code> <code>int</code> <p>The function type of the constraint. In GROMACS, this typically refers to the type of constraint algorithm used.</p> <code>length</code> <code>float</code> <p>The length of the constraint, usually in nanometers.</p> Class Methods <p>parse_from_itp_entry(cls, entry: list) -&gt; \"Constraint\": Parses a constraint from a given entry in a topology file.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>@dataclass\nclass Constraint:\n    \"\"\"\n    Represents a constraint between two atoms in a molecule.\n\n    This class models a constraint, which is a fixed distance between two atoms, typically used to maintain\n    a certain structure within the molecule. Constraints are often used in molecular dynamics simulations\n    to simplify the model or enforce certain conditions.\n\n    Attributes:\n        id_i (int): The identifier of the first atom in the constraint.\n        id_j (int): The identifier of the second atom in the constraint.\n        funct (int): The function type of the constraint. In GROMACS, this typically refers to the type of constraint algorithm used.\n        length (float): The length of the constraint, usually in nanometers.\n\n    Class Methods:\n        parse_from_itp_entry(cls, entry: list) -&gt; \"Constraint\": Parses a constraint from a given entry in a topology file.\n    \"\"\"\n\n    id_i: int\n    id_j: int\n    funct: int\n    length: float\n\n    @classmethod\n    def parse_from_itp_entry(cls, entry: list) -&gt; \"Constraint\":\n        return Constraint(int(entry[0]), int(entry[1]), int(entry[2]), float(entry[3]))\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.Molecule","title":"<code>Molecule</code>  <code>dataclass</code>","text":"<p>Represents a molecule with its constituent atoms, bonds, angles, and constraints.</p> <p>This class encapsulates a molecule's structure, including its atoms and the relationships between them (bonds, angles, and constraints). It provides methods for generating molecular coordinates, parsing molecule data from topology files, and generating files for molecular dynamics simulations.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the molecule.</p> <code>number_excl</code> <code>int</code> <p>The number of exclusions for the molecule, used in simulations to define non-bonded interactions.</p> <code>atoms</code> <code>list[Atom]</code> <p>A list of <code>Atom</code> instances representing the atoms in the molecule.</p> <code>bonds</code> <code>Optional[list[Bond]]</code> <p>A list of <code>Bond</code> instances representing the bonds in the molecule. Default is None.</p> <code>angles</code> <code>Optional[list[Angle]]</code> <p>A list of <code>Angle</code> instances representing the angles in the molecule. Default is None.</p> <code>constraints</code> <code>Optional[list[Constraint]]</code> <p>A list of <code>Constraint</code> instances representing the constraints in the molecule. Default is None.</p> <p>Methods:</p> Name Description <code>num_atoms </code> <p>Returns the number of atoms in the molecule.</p> <code>generate_coordinates</code> <p>float = 0.1) -&gt; np.ndarray: Generates 3D coordinates for the atoms in the molecule.</p> <code>parse_from_itp_entry</code> <p>dict) -&gt; \"Molecule\": Class method to parse a molecule from a topology file entry.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>@dataclass\nclass Molecule:\n    \"\"\"\n    Represents a molecule with its constituent atoms, bonds, angles, and constraints.\n\n    This class encapsulates a molecule's structure, including its atoms and the relationships between them\n    (bonds, angles, and constraints). It provides methods for generating molecular coordinates, parsing molecule\n    data from topology files, and generating files for molecular dynamics simulations.\n\n    Attributes:\n        name (str): The name of the molecule.\n        number_excl (int): The number of exclusions for the molecule, used in simulations to define non-bonded interactions.\n        atoms (list[Atom]): A list of `Atom` instances representing the atoms in the molecule.\n        bonds (Optional[list[Bond]]): A list of `Bond` instances representing the bonds in the molecule. Default is None.\n        angles (Optional[list[Angle]]): A list of `Angle` instances representing the angles in the molecule. Default is None.\n        constraints (Optional[list[Constraint]]): A list of `Constraint` instances representing the constraints in the molecule. Default is None.\n\n    Methods:\n        num_atoms (property): Returns the number of atoms in the molecule.\n        generate_coordinates(self, jitter: float = 0.1) -&gt; np.ndarray: Generates 3D coordinates for the atoms in the molecule.\n        parse_from_itp_entry(cls, entry: dict) -&gt; \"Molecule\": Class method to parse a molecule from a topology file entry.\n    \"\"\"\n\n    name: str\n    number_excl: int\n    atoms: list[Atom]\n    bonds: Optional[list[Bond]] = None\n    angles: Optional[list[Angle]] = None\n    constraints: Optional[list[Constraint]] = None\n\n    @property\n    def num_atoms(self) -&gt; int:\n        return len(self.atoms)\n\n    @property\n    def has_charged_beads(self) -&gt; bool:\n        return any(atom.is_charged for atom in self.atoms)\n\n    def generate_coordinates(self, jitter: float = 0.1) -&gt; np.ndarray:\n        coordinates = np.array([[0.0, 0.0, 0.0] for _ in range(self.num_atoms)])\n        placed_atoms = set()\n\n        def add_jitter(coord):\n            return [val + uniform(-jitter, jitter) for val in coord]\n\n        def get_next_coordinate(id_ref, length):\n            if id_ref - 1 not in placed_atoms:\n                return add_jitter([length, 0, 0])\n            else:\n                return add_jitter([coordinates[id_ref - 1][0] + length, 0, 0])\n\n        if self.constraints:\n            for constraint in self.constraints:\n                coordinates[constraint.id_j - 1] = get_next_coordinate(\n                    constraint.id_i, constraint.length\n                )\n                placed_atoms.add(constraint.id_j - 1)\n\n        if self.bonds:\n            for bond in self.bonds:\n                if bond.id_j - 1 not in placed_atoms:\n                    coordinates[bond.id_j - 1] = get_next_coordinate(\n                        bond.id_i, bond.length\n                    )\n                    placed_atoms.add(bond.id_j - 1)\n\n        return coordinates\n\n    @classmethod\n    def parse_from_itp_entry(cls, entry: dict) -&gt; \"Molecule\":\n        name = entry[\"moleculetype\"][0][0]\n        number_excl = entry[\"moleculetype\"][0][1]\n        atoms = [Atom.parse_from_itp_entry(e) for e in entry[\"atoms\"]]\n        bonds, angles, constraints = [], [], []\n        with suppress(KeyError):\n            bonds = [Bond.parse_from_itp_entry(e) for e in entry[\"bonds\"]]\n        with suppress(KeyError):\n            angles = [Angle.parse_from_itp_entry(e) for e in entry[\"angles\"]]\n        with suppress(KeyError):\n            constraints = [\n                Constraint.parse_from_itp_entry(e) for e in entry[\"constraints\"]\n            ]\n        return Molecule(\n            name=name,\n            number_excl=number_excl,\n            atoms=atoms,\n            bonds=bonds,\n            angles=angles,\n            constraints=constraints,\n        )\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.find_molecule_from_name","title":"<code>find_molecule_from_name(itp_filenames, molecule_name)</code>","text":"<p>Searches for and returns a Molecule instance matching the specified name from a list of .itp files.</p> <p>This function iterates over a list of GROMACS topology (.itp) files, parsing each to find a molecule that matches the given name. It leverages the <code>parse_molecules_from_itp</code> function to parse the .itp files and then searches through the resulting list of Molecule instances for a name match. The first matching Molecule instance found is returned. If no match is found after all files have been searched, a StopIteration exception is raised.</p> <p>Parameters:</p> Name Type Description Default <code>itp_filenames</code> <code>list[str]</code> <p>A list of paths to .itp files to be searched.</p> required <code>molecule_name</code> <code>str</code> <p>The name of the molecule to find.</p> required <p>Returns:</p> Name Type Description <code>Molecule</code> <code>Molecule</code> <p>The first Molecule instance found with a name matching <code>molecule_name</code>.</p> <p>Raises:</p> Type Description <code>StopIteration</code> <p>If no molecule with the specified name is found in the provided .itp files.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>def find_molecule_from_name(itp_filenames: list[str], molecule_name: str) -&gt; Molecule:\n    \"\"\"\n    Searches for and returns a Molecule instance matching the specified name from a list of .itp files.\n\n    This function iterates over a list of GROMACS topology (.itp) files, parsing each to find a molecule\n    that matches the given name. It leverages the `parse_molecules_from_itp` function to parse the .itp files\n    and then searches through the resulting list of Molecule instances for a name match. The first matching\n    Molecule instance found is returned. If no match is found after all files have been searched, a StopIteration\n    exception is raised.\n\n    Parameters:\n        itp_filenames (list[str]): A list of paths to .itp files to be searched.\n        molecule_name (str): The name of the molecule to find.\n\n    Returns:\n        Molecule: The first Molecule instance found with a name matching `molecule_name`.\n\n    Raises:\n        StopIteration: If no molecule with the specified name is found in the provided .itp files.\n    \"\"\"\n    molecules = []\n    for itp_filename in itp_filenames:\n        with suppress(KeyError):\n            molecules = [*molecules, *parse_molecules_from_itp(itp_filename)]\n    return next(m for m in molecules if m.name == molecule_name)\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.generate_gro_file_for_molecule","title":"<code>generate_gro_file_for_molecule(molecule, gro_filename, box_length=100.0)</code>","text":"<p>Generates a GROMACS .gro file for a given molecule.</p> <p>This function creates a .gro file, which is a GROMACS file format used to describe the positions of atoms in a molecule. It sets up a simulation box with a specified box length and places the atoms of the molecule within this box. The positions of the atoms are determined by the <code>generate_coordinates</code> method of the <code>Molecule</code> class, and additional molecular properties such as bonds are also considered if present.</p> <p>Parameters:</p> Name Type Description Default <code>molecule</code> <code>Molecule</code> <p>The molecule for which to generate the .gro file.</p> required <code>gro_filename</code> <code>str</code> <p>The path and name of the .gro file to be generated.</p> required <code>box_length</code> <code>float</code> <p>The length of the sides of the cubic simulation box in which the molecule is placed. Default is 100.0.</p> <code>100.0</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes directly to a file.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>def generate_gro_file_for_molecule(\n    molecule: Molecule, gro_filename: str, box_length: float = 100.0\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS .gro file for a given molecule.\n\n    This function creates a .gro file, which is a GROMACS file format used to describe the positions of atoms in a molecule.\n    It sets up a simulation box with a specified box length and places the atoms of the molecule within this box. The positions\n    of the atoms are determined by the `generate_coordinates` method of the `Molecule` class, and additional molecular properties\n    such as bonds are also considered if present.\n\n    Parameters:\n        molecule (Molecule): The molecule for which to generate the .gro file.\n        gro_filename (str): The path and name of the .gro file to be generated.\n        box_length (float): The length of the sides of the cubic simulation box in which the molecule is placed. Default is 100.0.\n\n    Returns:\n        None: This function does not return a value but writes directly to a file.\n    \"\"\"\n    n_atoms = len(molecule.atoms)\n    dtype = [\n        (\"name\", np.dtype(\"&lt;U4\")),\n        (\"type\", np.dtype(\"&lt;U4\")),\n        (\"resid\", int),\n        (\"resname\", np.dtype(\"&lt;U4\")),\n        (\"charge\", float),\n        (\"id\", int),\n    ]\n\n    atom_data = np.zeros(n_atoms, dtype=dtype)\n\n    for i, atom in enumerate(molecule.atoms):\n        atom_data[i] = (\n            atom.atom,\n            atom.type,\n            atom.residue_number,\n            atom.residue,\n            atom.charge,\n            atom.id,\n        )\n\n    assert len(set(atom_data[\"resid\"])) == 1, \"only one resid supported\"\n    assert len(set(atom_data[\"resname\"])) == 1, \"only one resname supported\"\n    residue_indices = [0] * n_atoms\n    u = Universe.empty(\n        n_atoms=n_atoms, n_residues=1, atom_resindex=residue_indices, trajectory=True\n    )\n    u.add_TopologyAttr(\"name\", atom_data[\"name\"])\n    u.add_TopologyAttr(\"type\", atom_data[\"type\"])\n    resid = atom_data[\"resid\"][0] if len(atom_data[\"resid\"]) &gt; 1 else atom_data[\"resid\"]\n    resname = (\n        atom_data[\"resname\"][0]\n        if len(atom_data[\"resname\"]) &gt; 1\n        else atom_data[\"resname\"]\n    )\n    resid = [resid] if type(resid) not in [list, np.ndarray] else resid\n    resname = [resname] if type(resname) not in [list, np.ndarray] else resname\n    u.add_TopologyAttr(\"resid\", resid)\n    u.add_TopologyAttr(\"resname\", resname)\n    u.add_TopologyAttr(\"charge\", atom_data[\"charge\"])\n    u.add_TopologyAttr(\"id\", atom_data[\"id\"])\n\n    u.atoms.positions = [\n        [x * 10 for x in coord] for coord in molecule.generate_coordinates()\n    ]\n    if molecule.bonds:\n        bond_tuples = [\n            (bond.id_i - 1, bond.id_j - 1) for bond in molecule.bonds\n        ]  # adjust index by -1\n        u.add_TopologyAttr(\"bonds\", bond_tuples)\n\n    box_size = [box_length, box_length, box_length, 90.0, 90.0, 90.0]\n    u.dimensions = box_size\n\n    logger.info(f\"Generating {gro_filename} for molecule {molecule.name}\")\n    u.atoms.write(gro_filename)\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.generate_itp_file_for_molecule","title":"<code>generate_itp_file_for_molecule(molecule, itp_filename)</code>","text":"<p>Generates a GROMACS topology (.itp) file for a specified molecule.</p> <p>This function writes a .itp file containing the definition of a molecule, including atoms, bonds, angles, and constraints. The file format adheres to the GROMACS topology file standards, making it suitable for use in molecular dynamics simulations. The function outputs sections for moleculetype, atoms, bonds (if any), angles (if any), and constraints (if any), providing a comprehensive description of the molecule's structure.</p> <p>Parameters:</p> Name Type Description Default <code>molecule</code> <code>Molecule</code> <p>The molecule instance for which to generate the .itp file. This object should contain                  all necessary information about the molecule, including its atoms, bonds, angles, and                  constraints.</p> required <code>itp_filename</code> <code>str</code> <p>The path and name of the .itp file to be generated. If the file already exists, it will                 be overwritten.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes directly to a file specified by <code>itp_filename</code>.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>def generate_itp_file_for_molecule(\n    molecule: Molecule,\n    itp_filename: str,\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS topology (.itp) file for a specified molecule.\n\n    This function writes a .itp file containing the definition of a molecule, including atoms, bonds, angles,\n    and constraints. The file format adheres to the GROMACS topology file standards, making it suitable for\n    use in molecular dynamics simulations. The function outputs sections for moleculetype, atoms, bonds (if any),\n    angles (if any), and constraints (if any), providing a comprehensive description of the molecule's structure.\n\n    Parameters:\n        molecule (Molecule): The molecule instance for which to generate the .itp file. This object should contain\n                             all necessary information about the molecule, including its atoms, bonds, angles, and\n                             constraints.\n        itp_filename (str): The path and name of the .itp file to be generated. If the file already exists, it will\n                            be overwritten.\n\n    Returns:\n        None: This function does not return a value but writes directly to a file specified by `itp_filename`.\n    \"\"\"\n    with open(itp_filename, \"w\") as f:\n        f.write(f\"\\n;;;;;; {molecule.name} molecule\\n\")\n        f.write(\"\\n[moleculetype]\\n\")\n        f.write(\"; molname       nrexcl\\n\")\n        f.write(f\" {molecule.name}\\t{molecule.number_excl}\\n\")\n        f.write(\"\\n[atoms]\\n\")\n        f.write(\"; id    type    resnr   residu  atom    cgnr    charge\\n\")\n        for atom in molecule.atoms:\n            f.write(\n                f\" {atom.id}\\t{atom.type}\\t{atom.residue_number}\\t{atom.residue}\\t\"\n                f\"{atom.atom}\\t{atom.charge_number}\\t{atom.charge}\\n\"\n            )\n        if molecule.bonds is not None:\n            f.write(\"\\n[bonds]\\n\")\n            f.write(\"; i     j       funct   length  force_constant\\n\")\n            for bond in molecule.bonds:\n                f.write(\n                    f\" {bond.id_i}\\t{bond.id_j}\\t{bond.funct}\\t{bond.length}\\t{bond.force_constant}\\n\"\n                )\n        if molecule.angles is not None:\n            f.write(\"\\n[angles]\\n\")\n            f.write(\"; i     j       k       funct   angle   force_constant\\n\")\n            for angle in molecule.angles:\n                f.write(\n                    f\" {angle.id_i}\\t{angle.id_j}\\t{angle.id_k}\\t{angle.funct}\\t{angle.angle}\\t{angle.force_constant}\\n\"\n                )\n        if molecule.constraints is not None:\n            f.write(\"\\n[constraints]\\n\")\n            f.write(\"; i     j       funct   length\\n\")\n            for constraint in molecule.constraints:\n                f.write(\n                    f\" {constraint.id_i}\\t{constraint.id_j}\\t{constraint.funct}\\t{constraint.length}\\n\"\n                )\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.generate_top_file_for_molecule","title":"<code>generate_top_file_for_molecule(molecule, force_field_filenames, top_filename, num_molecules=1)</code>","text":"<p>Generates a GROMACS topology (.top) file for a given molecule using specified force fields.</p> <p>This function delegates the task of generating a .top file to the <code>generate_top_file_for_generic_molecule</code> utility function. It prepares the necessary parameters, including the molecule's name, the list of force field filenames, the target .top file name, and the number of molecules to be included in the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>molecule</code> <code>Molecule</code> <p>The molecule instance for which to generate the .top file.</p> required <code>force_field_filenames</code> <code>list[str]</code> <p>A list of strings representing the paths to the force field files to be used.</p> required <code>top_filename</code> <code>str</code> <p>The path and name of the .top file to be generated.</p> required <code>num_molecules</code> <code>int</code> <p>The number of molecules to be included in the .top file. Default is 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes directly to a file.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>def generate_top_file_for_molecule(\n    molecule: Molecule,\n    force_field_filenames: list[str],\n    top_filename: str,\n    num_molecules: int = 1,\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS topology (.top) file for a given molecule using specified force fields.\n\n    This function delegates the task of generating a .top file to the `generate_top_file_for_generic_molecule`\n    utility function. It prepares the necessary parameters, including the molecule's name, the list of force field\n    filenames, the target .top file name, and the number of molecules to be included in the simulation.\n\n    Parameters:\n        molecule (Molecule): The molecule instance for which to generate the .top file.\n        force_field_filenames (list[str]): A list of strings representing the paths to the force field files to be used.\n        top_filename (str): The path and name of the .top file to be generated.\n        num_molecules (int): The number of molecules to be included in the .top file. Default is 1.\n\n    Returns:\n        None: This function does not return a value but writes directly to a file.\n    \"\"\"\n    return generate_top_file_for_generic_molecule(\n        molecule.name, force_field_filenames, top_filename, num_molecules\n    )\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.get_molecule_from_name","title":"<code>get_molecule_from_name(molecule_name, bond_length, bond_constant=None, number_excl=3, molecule_label=None)</code>","text":"<p>Constructs a Molecule instance from a simplified molecule name string.</p> <p>This function allows for the creation of a Molecule object by specifying a string that represents the molecule's composition, bond lengths, and optionally, bond constants. It supports the definition of atoms, bonds, and constraints within the molecule based on the provided string format. The molecule name string format should include atom types, followed by bond information (if any), separated by commas.</p> <p>Parameters:</p> Name Type Description Default <code>molecule_name</code> <code>str</code> <p>A string representing the molecule's composition and structure. Atom types should be                  separated by spaces, and bond information (if any) should follow after a comma. Bonds are                  indicated by indices of atoms (starting from 1) connected by a dash (\"-\") for bonds or an                  underscore (\"_\") for constraints.</p> required <code>bond_length</code> <code>float</code> <p>The default length for bonds and constraints within the molecule, in nanometers.</p> required <code>bond_constant</code> <code>Optional[float]</code> <p>The force constant for the bonds within the molecule. This parameter is required                              if the molecule_name string includes bond information. Default is None.</p> <code>None</code> <code>number_excl</code> <code>int</code> <p>The number of exclusions for the molecule, used in simulations to define non-bonded interactions.                Default is 3.</p> <code>3</code> <code>molecule_label</code> <code>Optional[str]</code> <p>An optional label for the molecule. If not provided, a label is generated from the                             first five characters of the concatenated atom types. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Molecule</code> <code>Molecule</code> <p>An instance of the Molecule class, constructed based on the provided parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If bond_constant is None but the molecule_name string includes bond information.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>def get_molecule_from_name(\n    molecule_name: str,\n    bond_length: float,\n    bond_constant: Optional[float] = None,\n    number_excl: int = 3,\n    molecule_label: Optional[str] = None,\n) -&gt; Molecule:\n    \"\"\"\n    Constructs a Molecule instance from a simplified molecule name string.\n\n    This function allows for the creation of a Molecule object by specifying a string that represents the molecule's\n    composition, bond lengths, and optionally, bond constants. It supports the definition of atoms, bonds, and constraints\n    within the molecule based on the provided string format. The molecule name string format should include atom types,\n    followed by bond information (if any), separated by commas.\n\n    Parameters:\n        molecule_name (str): A string representing the molecule's composition and structure. Atom types should be\n                             separated by spaces, and bond information (if any) should follow after a comma. Bonds are\n                             indicated by indices of atoms (starting from 1) connected by a dash (\"-\") for bonds or an\n                             underscore (\"_\") for constraints.\n        bond_length (float): The default length for bonds and constraints within the molecule, in nanometers.\n        bond_constant (Optional[float]): The force constant for the bonds within the molecule. This parameter is required\n                                         if the molecule_name string includes bond information. Default is None.\n        number_excl (int): The number of exclusions for the molecule, used in simulations to define non-bonded interactions.\n                           Default is 3.\n        molecule_label (Optional[str]): An optional label for the molecule. If not provided, a label is generated from the\n                                        first five characters of the concatenated atom types. Default is None.\n\n    Returns:\n        Molecule: An instance of the Molecule class, constructed based on the provided parameters.\n\n    Raises:\n        ValueError: If bond_constant is None but the molecule_name string includes bond information.\n    \"\"\"\n    particle_names = molecule_name.split(\",\")[0].split()\n    if molecule_label is None:\n        molecule_label = \"\".join(particle_names)[:4]\n    # Construct list of atoms\n    atoms = [\n        _get_atom_from_string(name, i, molecule_label)\n        for i, name in enumerate(particle_names)\n    ]\n    molecule = Molecule(molecule_label, number_excl, atoms)\n    # Add bonds and constraints to the molecule\n    if \",\" in molecule_name:\n        # Obtain bonds and constraints from molecule string\n        bond_constraints_info = molecule_name.split(\",\")[1].split()\n        bond_info = [\n            [int(idx) + 1 for idx in b.split(\"-\")]\n            for b in bond_constraints_info\n            if \"-\" in b\n        ]\n        constraint_info = [\n            [int(idx) + 1 for idx in c.split(\"_\")]\n            for c in bond_constraints_info\n            if \"_\" in c\n        ]\n        # Add bonds and constraints to the molecule\n        if bond_constant is None and len(bond_info) &gt; 0:\n            raise ValueError(\n                \"bond_constant must be specified if the molecule contains bonds\"\n            )\n        if len(constraint_info) &gt; 0:\n            constraints = []\n            for id_i, id_j in constraint_info:\n                constraint = Constraint(id_i, id_j, 1, bond_length)\n                constraints.append(constraint)\n            molecule.constraints = constraints\n        if len(bond_info) &gt; 0:\n            bonds = []\n            for id_i, id_j in bond_info:\n                bond = Bond(id_i, id_j, 1, bond_length, bond_constant)\n                bonds.append(bond)\n            molecule.bonds = bonds\n    return molecule\n</code></pre>"},{"location":"parsers/gromacs_forcefields/#martignac.parsers.gromacs_forcefields.parse_molecules_from_itp","title":"<code>parse_molecules_from_itp(itp_filename)</code>","text":"<p>Parses molecules from a GROMACS topology (.itp) file.</p> <p>This function reads a .itp file, extracts molecule information, and creates a list of Molecule instances based on the data found in the file. It handles multiple molecules within the same file, separating them based on the [moleculetype] directive in the .itp file format. Each molecule's data is parsed and used to instantiate a Molecule object, which is then added to the list of molecules to be returned.</p> <p>Parameters:</p> Name Type Description Default <code>itp_filename</code> <code>str</code> <p>The path to the .itp file to be parsed.</p> required <p>Returns:</p> Type Description <code>list[Molecule]</code> <p>list[Molecule]: A list of Molecule instances representing each molecule found in the .itp file.</p> Source code in <code>martignac/parsers/gromacs_forcefields.py</code> <pre><code>def parse_molecules_from_itp(itp_filename: str) -&gt; list[Molecule]:\n    \"\"\"\n    Parses molecules from a GROMACS topology (.itp) file.\n\n    This function reads a .itp file, extracts molecule information, and creates a list of Molecule instances\n    based on the data found in the file. It handles multiple molecules within the same file, separating them\n    based on the [moleculetype] directive in the .itp file format. Each molecule's data is parsed and used to\n    instantiate a Molecule object, which is then added to the list of molecules to be returned.\n\n    Parameters:\n        itp_filename (str): The path to the .itp file to be parsed.\n\n    Returns:\n        list[Molecule]: A list of Molecule instances representing each molecule found in the .itp file.\n    \"\"\"\n    with open(itp_filename) as f:\n        content = f.read()\n\n    # Pattern to find and process conditional compilation blocks\n    conditional_block_pattern = re.compile(\n        r\"#ifdef FLEXIBLE\\s*\\[bonds\\]\\s*(.*?)#else\\s*\\[constraints\\]\\s*(.*?)#endif\",\n        re.DOTALL,\n    )\n\n    # Function to keep the 'bonds' part and discard the 'constraints' part\n    def choose_bonds_over_constraints(match):\n        bonds_part = match.group(1)  # The 'bonds' section of the match\n        return f\"[bonds]{bonds_part}\"\n\n    # Replace the matched sections with only the 'bonds' part\n    modified_content = re.sub(\n        conditional_block_pattern, choose_bonds_over_constraints, content\n    )\n\n    # Split the modified content into lines for further processing\n    lines = modified_content.splitlines()\n\n    molecules = []\n    molecule_data = {}\n    section = None\n\n    for line in lines:\n        line = line.strip()\n\n        # Skip comments and empty lines\n        if line.startswith(\";\") or not line:\n            continue\n\n        # Detect section headers\n        if line.startswith(\"[\"):\n            section = line.strip(\"[] \").lower()\n\n            # If a new molecule starts\n            if section == \"moleculetype\" and molecule_data:\n                molecules.append(molecule_data)\n                molecule_data = {}\n\n            molecule_data[section] = []\n            continue\n\n        # Add data for the current section\n        if section:\n            molecule_data[section].append(line.split())\n\n    # Add the last molecule\n    if molecule_data:\n        molecules.append(molecule_data)\n\n    return [Molecule.parse_from_itp_entry(m) for m in molecules]\n</code></pre>"},{"location":"parsers/gromacs_particle_definitions/","title":"GROMACS particle definitions","text":""},{"location":"parsers/gromacs_particle_definitions/#martignac.parsers.gromacs_particle_definitions.ParticleType","title":"<code>ParticleType</code>  <code>dataclass</code>","text":"<p>Represents a particle type in a molecular dynamics simulation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the particle type.</p> <code>mass</code> <code>float</code> <p>The mass of the particle type.</p> <code>charge</code> <code>float</code> <p>The charge of the particle type.</p> <code>ptype</code> <code>str</code> <p>The type of the particle (e.g., atomistic, coarse-grained).</p> <code>c6</code> <code>float</code> <p>The Lennard-Jones C6 parameter for the particle type.</p> <code>c12</code> <code>float</code> <p>The Lennard-Jones C12 parameter for the particle type.</p> Source code in <code>martignac/parsers/gromacs_particle_definitions.py</code> <pre><code>@dataclass\nclass ParticleType:\n    \"\"\"\n    Represents a particle type in a molecular dynamics simulation.\n\n    Attributes:\n        name (str): The name of the particle type.\n        mass (float): The mass of the particle type.\n        charge (float): The charge of the particle type.\n        ptype (str): The type of the particle (e.g., atomistic, coarse-grained).\n        c6 (float): The Lennard-Jones C6 parameter for the particle type.\n        c12 (float): The Lennard-Jones C12 parameter for the particle type.\n    \"\"\"\n\n    name: str\n    mass: float\n    charge: float\n    ptype: str\n    c6: float\n    c12: float\n</code></pre>"},{"location":"parsers/gromacs_particle_definitions/#martignac.parsers.gromacs_particle_definitions.find_particle_type_from_name","title":"<code>find_particle_type_from_name(itp_filename, particle_name)</code>","text":"<p>Finds and returns a ParticleType object from a GROMACS .itp file based on the particle name.</p> <p>This function searches through the particle types defined in a specified .itp file, looking for a particle type that matches the given name. It utilizes the <code>parse_particle_types_from_itp</code> function to read and parse the .itp file, extracting all defined particle types into a list of ParticleType objects. It then iterates through this list to find a particle type with a name that matches the <code>particle_name</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>itp_filename</code> <code>str</code> <p>The path to the .itp file to be searched.</p> required <code>particle_name</code> <code>str</code> <p>The name of the particle type to find.</p> required <p>Returns:</p> Name Type Description <code>ParticleType</code> <code>ParticleType</code> <p>The ParticleType object corresponding to the specified particle name.</p> <p>Raises:</p> Type Description <code>StopIteration</code> <p>If no particle type with the specified name is found in the .itp file.</p> Source code in <code>martignac/parsers/gromacs_particle_definitions.py</code> <pre><code>def find_particle_type_from_name(itp_filename: str, particle_name: str) -&gt; ParticleType:\n    \"\"\"\n    Finds and returns a ParticleType object from a GROMACS .itp file based on the particle name.\n\n    This function searches through the particle types defined in a specified .itp file, looking for a particle\n    type that matches the given name. It utilizes the `parse_particle_types_from_itp` function to read and parse\n    the .itp file, extracting all defined particle types into a list of ParticleType objects. It then iterates\n    through this list to find a particle type with a name that matches the `particle_name` parameter.\n\n    Parameters:\n        itp_filename (str): The path to the .itp file to be searched.\n        particle_name (str): The name of the particle type to find.\n\n    Returns:\n        ParticleType: The ParticleType object corresponding to the specified particle name.\n\n    Raises:\n        StopIteration: If no particle type with the specified name is found in the .itp file.\n    \"\"\"\n    particle_types = parse_particle_types_from_itp(itp_filename)\n    return next(p for p in particle_types if p.name == particle_name)\n</code></pre>"},{"location":"parsers/gromacs_particle_definitions/#martignac.parsers.gromacs_particle_definitions.generate_gro_for_particle_type","title":"<code>generate_gro_for_particle_type(particle_type, gro_filename, box_length=100.0)</code>","text":"<p>Generates a GROMACS .gro file for a single particle type with specified box dimensions.</p> <p>This function creates a .gro file representing a simulation box containing a single particle of the specified type. The particle is placed at the origin of the box. The function uses MDAnalysis to create an empty universe, sets the particle's attributes, and then writes the .gro file with the specified box dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>particle_type</code> <code>ParticleType</code> <p>The particle type for which to generate the .gro file. This should be an instance                           of the ParticleType class, containing the necessary attributes like name, mass,                           and charge.</p> required <code>gro_filename</code> <code>str</code> <p>The path and filename where the .gro file will be saved. If the file already exists, it will                 be overwritten.</p> required <code>box_length</code> <code>float</code> <p>The length of the sides of the cubic simulation box in which the particle is placed. The                 default value is 100.0 \u00c5ngstr\u00f6ms.</p> <code>100.0</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes directly to a file specified by <code>gro_filename</code>.</p> Source code in <code>martignac/parsers/gromacs_particle_definitions.py</code> <pre><code>def generate_gro_for_particle_type(\n    particle_type: ParticleType, gro_filename: str, box_length: float = 100.0\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS .gro file for a single particle type with specified box dimensions.\n\n    This function creates a .gro file representing a simulation box containing a single particle of the specified type.\n    The particle is placed at the origin of the box. The function uses MDAnalysis to create an empty universe, sets the\n    particle's attributes, and then writes the .gro file with the specified box dimensions.\n\n    Parameters:\n        particle_type (ParticleType): The particle type for which to generate the .gro file. This should be an instance\n                                      of the ParticleType class, containing the necessary attributes like name, mass,\n                                      and charge.\n        gro_filename (str): The path and filename where the .gro file will be saved. If the file already exists, it will\n                            be overwritten.\n        box_length (float): The length of the sides of the cubic simulation box in which the particle is placed. The\n                            default value is 100.0 \u00c5ngstr\u00f6ms.\n\n    Returns:\n        None: This function does not return a value but writes directly to a file specified by `gro_filename`.\n    \"\"\"\n    u = mda.Universe.empty(n_atoms=1, trajectory=True)\n\n    # Setting properties\n    u.add_TopologyAttr(\"name\", values=[particle_type.name])\n    u.add_TopologyAttr(\"type\", values=[particle_type.ptype])\n    u.add_TopologyAttr(\"resid\", values=[1])\n    u.add_TopologyAttr(\"resname\", values=[particle_type.name])\n    u.add_TopologyAttr(\"masses\", values=[particle_type.mass])\n    u.add_TopologyAttr(\"charges\", values=[particle_type.charge])\n    u.atoms.positions = [[0, 0, 0]]  # Setting it to the origin for simplicity\n    box_size = [box_length, box_length, box_length, 90.0, 90.0, 90.0]\n    u.dimensions = box_size\n\n    logger.info(f\"generating {gro_filename} for molecule {particle_type.name}\")\n    u.atoms.write(gro_filename)\n</code></pre>"},{"location":"parsers/gromacs_particle_definitions/#martignac.parsers.gromacs_particle_definitions.generate_itp_file_for_particle","title":"<code>generate_itp_file_for_particle(particle, itp_filename)</code>","text":"<p>Generates a GROMACS .itp file for a single particle type.</p> <p>This function writes to a .itp file specific information about a particle type, including its name, type, and charge. The .itp (include topology) file format is used by GROMACS to define molecule types in simulations. This function creates a minimal .itp file containing a single [moleculetype] entry and one [atoms] entry for the specified particle.</p> <p>Parameters:</p> Name Type Description Default <code>particle</code> <code>ParticleType</code> <p>The particle type for which to generate the .itp file. This should be an instance                      of the ParticleType class, containing the necessary attributes like name, mass,                      and charge.</p> required <code>itp_filename</code> <code>str</code> <p>The path and filename where the .itp file will be saved. If the file already exists, it                 will be overwritten.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes directly to a file specified by <code>itp_filename</code>.</p> Source code in <code>martignac/parsers/gromacs_particle_definitions.py</code> <pre><code>def generate_itp_file_for_particle(\n    particle: ParticleType,\n    itp_filename: str,\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS .itp file for a single particle type.\n\n    This function writes to a .itp file specific information about a particle type, including its name, type, and charge.\n    The .itp (include topology) file format is used by GROMACS to define molecule types in simulations. This function\n    creates a minimal .itp file containing a single [moleculetype] entry and one [atoms] entry for the specified particle.\n\n    Parameters:\n        particle (ParticleType): The particle type for which to generate the .itp file. This should be an instance\n                                 of the ParticleType class, containing the necessary attributes like name, mass,\n                                 and charge.\n        itp_filename (str): The path and filename where the .itp file will be saved. If the file already exists, it\n                            will be overwritten.\n\n    Returns:\n        None: This function does not return a value but writes directly to a file specified by `itp_filename`.\n    \"\"\"\n    with open(itp_filename, \"w\") as f:\n        f.write(f\";;;;;; {particle.name} bead\\n\")\n        f.write(\"[moleculetype]\\n\")\n        f.write(\"; molname       nrexcl\\n\")\n        f.write(f\"  {particle.name}\\t1\\n\\n\")\n\n        f.write(\"[atoms]\\n\")\n        f.write(\"; id    type    resnr   residu  atom    cgnr    charge\\n\")\n        f.write(\n            f\"  1\\t{particle.name}\\t1\\t{particle.name}\\t{particle.ptype}\\t1\\t{particle.charge}\\n\"\n        )\n</code></pre>"},{"location":"parsers/gromacs_particle_definitions/#martignac.parsers.gromacs_particle_definitions.generate_top_file_for_particle","title":"<code>generate_top_file_for_particle(particle, force_field_filenames, top_filename, num_molecules=1)</code>","text":"<p>Generates a GROMACS topology (.top) file for a single particle type.</p> <p>This function creates a .top file for a specified particle type, incorporating the specified force field files. The generated .top file includes the definition of the particle type and the number of molecules of that type to be included in the simulation. It delegates the actual writing of the file to the <code>generate_top_file_for_generic_molecule</code> function, which handles the formatting and inclusion of force field parameters.</p> <p>Parameters:</p> Name Type Description Default <code>particle</code> <code>ParticleType</code> <p>The particle type for which to generate the .top file. This should be an instance                      of the ParticleType class, containing the necessary attributes like name, mass,                      and charge.</p> required <code>force_field_filenames</code> <code>list[str]</code> <p>A list of paths to the force field files to be included in the .top file.                                These files contain the parameters necessary for the simulation, such as                                bond lengths, angles, and Lennard-Jones parameters.</p> required <code>top_filename</code> <code>str</code> <p>The path and filename where the .top file will be saved. If the file already exists, it                 will be overwritten.</p> required <code>num_molecules</code> <code>int</code> <p>The number of molecules of the specified particle type to include in the simulation.                  Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes directly to a file specified by <code>top_filename</code>.</p> Source code in <code>martignac/parsers/gromacs_particle_definitions.py</code> <pre><code>def generate_top_file_for_particle(\n    particle: ParticleType,\n    force_field_filenames: list[str],\n    top_filename: str,\n    num_molecules: int = 1,\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS topology (.top) file for a single particle type.\n\n    This function creates a .top file for a specified particle type, incorporating the specified force field files.\n    The generated .top file includes the definition of the particle type and the number of molecules of that type\n    to be included in the simulation. It delegates the actual writing of the file to the\n    `generate_top_file_for_generic_molecule` function, which handles the formatting and inclusion of force field\n    parameters.\n\n    Parameters:\n        particle (ParticleType): The particle type for which to generate the .top file. This should be an instance\n                                 of the ParticleType class, containing the necessary attributes like name, mass,\n                                 and charge.\n        force_field_filenames (list[str]): A list of paths to the force field files to be included in the .top file.\n                                           These files contain the parameters necessary for the simulation, such as\n                                           bond lengths, angles, and Lennard-Jones parameters.\n        top_filename (str): The path and filename where the .top file will be saved. If the file already exists, it\n                            will be overwritten.\n        num_molecules (int): The number of molecules of the specified particle type to include in the simulation.\n                             Defaults to 1.\n\n    Returns:\n        None: This function does not return a value but writes directly to a file specified by `top_filename`.\n    \"\"\"\n    return generate_top_file_for_generic_molecule(\n        particle.name, force_field_filenames, top_filename, num_molecules\n    )\n</code></pre>"},{"location":"parsers/gromacs_particle_definitions/#martignac.parsers.gromacs_particle_definitions.parse_particle_types_from_itp","title":"<code>parse_particle_types_from_itp(filename)</code>","text":"<p>Parses particle types from a GROMACS .itp file.</p> <p>This function reads a GROMACS topology (.itp) file and extracts the definitions of particle types listed under the [ atomtypes ] section. Each particle type is represented by a <code>ParticleType</code> object, which includes properties such as name, mass, charge, particle type (ptype), and Lennard-Jones parameters (c6, c12).</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the .itp file to be parsed.</p> required <p>Returns:</p> Type Description <code>list[ParticleType]</code> <p>list[ParticleType]: A list of <code>ParticleType</code> objects extracted from the .itp file.</p> Source code in <code>martignac/parsers/gromacs_particle_definitions.py</code> <pre><code>def parse_particle_types_from_itp(filename: str) -&gt; list[ParticleType]:\n    \"\"\"\n    Parses particle types from a GROMACS .itp file.\n\n    This function reads a GROMACS topology (.itp) file and extracts the definitions of particle types\n    listed under the [ atomtypes ] section. Each particle type is represented by a `ParticleType` object,\n    which includes properties such as name, mass, charge, particle type (ptype), and Lennard-Jones parameters (c6, c12).\n\n    Parameters:\n        filename (str): The path to the .itp file to be parsed.\n\n    Returns:\n        list[ParticleType]: A list of `ParticleType` objects extracted from the .itp file.\n    \"\"\"\n    particle_types = []\n    with open(filename) as file:\n        lines = file.readlines()\n        in_atomtypes = False\n        for line in lines:\n            line = line.strip()\n            if line == \"[ atomtypes ]\":\n                in_atomtypes = True\n            elif in_atomtypes:\n                if line.startswith(\";\") or not line:  # Skip comments and empty lines\n                    continue\n                try:\n                    parts = line.split()\n                    name = parts[0]\n                    mass = float(parts[1])\n                    charge = float(parts[2])\n                    ptype = parts[3]\n                    c6 = float(parts[4])\n                    c12 = float(parts[5])\n                    bead = ParticleType(name, mass, charge, ptype, c6, c12)\n                    particle_types.append(bead)\n                except (\n                    ValueError,\n                    IndexError,\n                ):  # Exit the loop if line format doesn't match\n                    break\n\n    return particle_types\n</code></pre>"},{"location":"parsers/gromacs_structures/","title":"GROMACS structures","text":""},{"location":"parsers/gromacs_structures/#martignac.parsers.gromacs_structures.get_number_of_molecules_from_gro","title":"<code>get_number_of_molecules_from_gro(gro_filename)</code>","text":"<p>Calculates the number of molecules in a GROMACS .gro file.</p> <p>This function utilizes MDAnalysis to load a .gro file and counts the number of residues, which corresponds to the number of molecules present in the file. It's useful for quickly assessing the composition of a simulation box without manually parsing the file.</p> <p>Parameters:</p> Name Type Description Default <code>gro_filename</code> <code>str</code> <p>The path to the .gro file from which to count molecules.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of molecules found in the specified .gro file.</p> Source code in <code>martignac/parsers/gromacs_structures.py</code> <pre><code>def get_number_of_molecules_from_gro(gro_filename: str) -&gt; int:\n    \"\"\"\n    Calculates the number of molecules in a GROMACS .gro file.\n\n    This function utilizes MDAnalysis to load a .gro file and counts the number of residues, which corresponds\n    to the number of molecules present in the file. It's useful for quickly assessing the composition of a\n    simulation box without manually parsing the file.\n\n    Parameters:\n        gro_filename (str): The path to the .gro file from which to count molecules.\n\n    Returns:\n        int: The number of molecules found in the specified .gro file.\n    \"\"\"\n    u = mda.Universe(gro_filename)\n    return len(u.residues)\n</code></pre>"},{"location":"parsers/gromacs_topologies/","title":"GROMACS topologies","text":""},{"location":"parsers/gromacs_topologies/#martignac.parsers.gromacs_topologies.MoleculeTopology","title":"<code>MoleculeTopology</code>  <code>dataclass</code>","text":"<p>Represents the topology of a molecule within a GROMACS simulation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the molecule.</p> <code>number_elements</code> <code>int</code> <p>The number of elements (atoms) in the molecule.</p> Source code in <code>martignac/parsers/gromacs_topologies.py</code> <pre><code>@dataclass\nclass MoleculeTopology:\n    \"\"\"\n    Represents the topology of a molecule within a GROMACS simulation.\n\n    Attributes:\n        name (str): The name of the molecule.\n        number_elements (int): The number of elements (atoms) in the molecule.\n    \"\"\"\n\n    name: str\n    number_elements: int\n</code></pre>"},{"location":"parsers/gromacs_topologies/#martignac.parsers.gromacs_topologies.Topology","title":"<code>Topology</code>  <code>dataclass</code>","text":"<p>Represents the overall topology of a molecular system in a GROMACS simulation.</p> <p>This class encapsulates the system's name, the molecules present within the system, and any include files necessary for the simulation. It provides methods to parse topology files (.top), update molecule counts based on a given .gro file, and output a new topology file.</p> <p>Attributes:</p> Name Type Description <code>system</code> <code>str</code> <p>A descriptive name for the system.</p> <code>molecules</code> <code>list[MoleculeTopology]</code> <p>A list of <code>MoleculeTopology</code> instances representing the molecules                                 present in the system.</p> <code>includes</code> <code>list[str]</code> <p>A list of paths to additional topology files to be included in the simulation.</p> <p>Methods:</p> Name Description <code>parse_top_file</code> <p>str) -&gt; \"Topology\": Class method to parse a GROMACS topology file (.top) and return a <code>Topology</code> instance representing the parsed data.</p> <code>update_counts_against_gro</code> <p>str) -&gt; None: Updates the molecule counts in the topology based on the actual counts found in a .gro file.</p> <code>output_top</code> <p>str) -&gt; None: Writes the topology to a new .top file, including all molecules, system name, and include files.</p> Source code in <code>martignac/parsers/gromacs_topologies.py</code> <pre><code>@dataclass\nclass Topology:\n    \"\"\"\n    Represents the overall topology of a molecular system in a GROMACS simulation.\n\n    This class encapsulates the system's name, the molecules present within the system, and any include files\n    necessary for the simulation. It provides methods to parse topology files (.top), update molecule counts based\n    on a given .gro file, and output a new topology file.\n\n    Attributes:\n        system (str): A descriptive name for the system.\n        molecules (list[MoleculeTopology]): A list of `MoleculeTopology` instances representing the molecules\n                                            present in the system.\n        includes (list[str]): A list of paths to additional topology files to be included in the simulation.\n\n    Methods:\n        parse_top_file(cls, top_filename: str) -&gt; \"Topology\":\n            Class method to parse a GROMACS topology file (.top) and return a `Topology` instance representing\n            the parsed data.\n\n        update_counts_against_gro(self, gro_filename: str) -&gt; None:\n            Updates the molecule counts in the topology based on the actual counts found in a .gro file.\n\n        output_top(self, filename: str) -&gt; None:\n            Writes the topology to a new .top file, including all molecules, system name, and include files.\n    \"\"\"\n\n    system: str = \"\"\n    molecules: list[MoleculeTopology] = field(default_factory=list)\n    includes: list[str] = field(default_factory=list)\n\n    @classmethod\n    def parse_top_file(cls, top_filename: str) -&gt; \"Topology\":\n        with open(top_filename) as file:\n            lines = file.readlines()\n\n        includes = []\n        system = \"\"\n        molecules = []\n\n        # Identify sections\n        in_system_section = False\n        in_molecules_section = False\n\n        for line in lines:\n            line = line.strip()\n\n            # Skip comments and empty lines\n            if not line or line.startswith(\";\"):\n                continue\n\n            # Identify the start of a section\n            if line.startswith(\"[\"):\n                section = line.strip(\"[]\").strip().lower()\n                if section == \"system\":\n                    in_system_section = True\n                    in_molecules_section = False\n                elif section == \"molecules\":\n                    in_molecules_section = True\n                    in_system_section = False\n                continue\n\n            # Process the sections\n            if in_system_section:\n                system = line\n            elif in_molecules_section:\n                molecule_name, molecule_count = line.split()\n                molecules.append(MoleculeTopology(molecule_name, int(molecule_count)))\n            elif line.startswith(\"#include\"):\n                includes.append(line.split('\"')[1])\n\n        return Topology(includes=includes, system=system, molecules=molecules)\n\n    def update_counts_against_gro(self, gro_filename: str) -&gt; None:\n        u = mda.Universe(gro_filename)\n        existing_mol_names = []\n        final_list_of_molecules = []\n        for molecule in self.molecules:\n            if molecule.name not in existing_mol_names:\n                atom_selection = u.select_atoms(f\"resname {molecule.name}\")\n                molecule.number_elements = atom_selection.residues.n_residues\n                logger.info(\n                    f\"found {molecule.number_elements} {molecule.name} in {gro_filename}\"\n                )\n                existing_mol_names.append(molecule.name)\n                final_list_of_molecules.append(molecule)\n        self.molecules = final_list_of_molecules\n\n    def output_top(self, filename: str) -&gt; None:\n        with open(filename, \"w\") as file:\n            # Write includes\n            for include in self.includes:\n                file.write(f'#include \"{include}\"\\n')\n            file.write(\"\\n\")\n\n            # Write system\n            file.write(\"[ system ]\\n\")\n            file.write(f\"{self.system}\\n\")\n            file.write(\"\\n\")\n\n            # Write molecules\n            file.write(\"[ molecules ]\\n\")\n            for molecule in self.molecules:\n                file.write(f\"{molecule.name:&lt;20}{molecule.number_elements}\\n\")\n</code></pre>"},{"location":"parsers/gromacs_topologies/#martignac.parsers.gromacs_topologies.append_all_includes_to_top","title":"<code>append_all_includes_to_top(main_top, others)</code>","text":"<p>Combines the include files from multiple Topology instances into a single Topology instance.</p> <p>This function takes a main Topology instance and a list of other Topology instances, then combines all unique include file paths from these instances into the main Topology instance. The main Topology's include list is first cleared to ensure no duplicates from its original includes, and then it is populated with unique includes from all provided Topology instances.</p> <p>Parameters:</p> Name Type Description Default <code>main_top</code> <code>Topology</code> <p>The main Topology instance to which all unique include file paths from other Topology                  instances will be added.</p> required <code>others</code> <code>list[Topology]</code> <p>A list of other Topology instances from which to gather all unique include file paths.</p> required <p>Returns:</p> Name Type Description <code>Topology</code> <code>Topology</code> <p>The updated main Topology instance with a combined list of unique include file paths.</p> Source code in <code>martignac/parsers/gromacs_topologies.py</code> <pre><code>def append_all_includes_to_top(main_top: Topology, others: list[Topology]) -&gt; Topology:\n    \"\"\"\n    Combines the include files from multiple Topology instances into a single Topology instance.\n\n    This function takes a main Topology instance and a list of other Topology instances, then combines all unique\n    include file paths from these instances into the main Topology instance. The main Topology's include list is\n    first cleared to ensure no duplicates from its original includes, and then it is populated with unique includes\n    from all provided Topology instances.\n\n    Parameters:\n        main_top (Topology): The main Topology instance to which all unique include file paths from other Topology\n                             instances will be added.\n        others (list[Topology]): A list of other Topology instances from which to gather all unique include file paths.\n\n    Returns:\n        Topology: The updated main Topology instance with a combined list of unique include file paths.\n    \"\"\"\n    new_top = copy(main_top)\n    new_top.includes = []\n    for top in others:\n        for i in top.includes:\n            if i not in new_top.includes:\n                new_top.includes.append(i)\n    return new_top\n</code></pre>"},{"location":"parsers/gromacs_topologies/#martignac.parsers.gromacs_topologies.combine_multiple_topology_files","title":"<code>combine_multiple_topology_files(topology_files, system_name)</code>","text":"<p>Combines multiple GROMACS topology files into a single Topology instance.</p> <p>This function parses multiple topology (.top) files, each representing a part of a molecular system, and combines them into a single Topology instance. It aggregates all molecules and include files from each topology file, ensuring no duplicates in the include files. The system name for the combined topology is specified by the user.</p> <p>Parameters:</p> Name Type Description Default <code>topology_files</code> <code>list[str]</code> <p>A list of paths to the topology files to be combined.</p> required <code>system_name</code> <code>str</code> <p>The name to assign to the combined system.</p> required <p>Returns:</p> Name Type Description <code>Topology</code> <code>Topology</code> <p>An instance of the Topology class representing the combined topology of all input files.</p> Source code in <code>martignac/parsers/gromacs_topologies.py</code> <pre><code>def combine_multiple_topology_files(\n    topology_files: list[str], system_name: str\n) -&gt; Topology:\n    \"\"\"\n    Combines multiple GROMACS topology files into a single Topology instance.\n\n    This function parses multiple topology (.top) files, each representing a part of a molecular system, and combines\n    them into a single Topology instance. It aggregates all molecules and include files from each topology file,\n    ensuring no duplicates in the include files. The system name for the combined topology is specified by the user.\n\n    Parameters:\n        topology_files (list[str]): A list of paths to the topology files to be combined.\n        system_name (str): The name to assign to the combined system.\n\n    Returns:\n        Topology: An instance of the Topology class representing the combined topology of all input files.\n    \"\"\"\n    comb_topology = Topology(system_name, molecules=[], includes=[])\n    for top_file in topology_files:\n        top = Topology.parse_top_file(top_file)\n        comb_topology.molecules.extend(top.molecules)\n        for include in top.includes:\n            if include not in comb_topology.includes:\n                comb_topology.includes.append(include)\n    return comb_topology\n</code></pre>"},{"location":"utils/dashboard/","title":"Dashboard","text":""},{"location":"utils/dashboard/#martignac.utils.dashboard.generate_gravis_network","title":"<code>generate_gravis_network(project)</code>","text":"<p>Generates a directed graph visualization for a given MartiniFlowProject using Gravis.</p> <p>This function takes a MartiniFlowProject instance, extracts its operations and the operation graph, and generates a directed graph visualization. The visualization is created using the Gravis library, which is built on top of D3.js for interactive and dynamic graph visualizations in Jupyter notebooks and other web-based environments.</p> <p>Parameters:</p> Name Type Description Default <code>project</code> <code>MartiniFlowProject</code> <p>An instance of MartiniFlowProject containing operations and their relationships.</p> required <p>Returns:</p> Type Description <p>gv.d3: A Gravis D3 graph object that can be displayed in Jupyter notebooks or web environments.</p> Source code in <code>martignac/utils/dashboard.py</code> <pre><code>def generate_gravis_network(project: MartiniFlowProject):\n    \"\"\"\n    Generates a directed graph visualization for a given MartiniFlowProject using Gravis.\n\n    This function takes a MartiniFlowProject instance, extracts its operations and the operation graph,\n    and generates a directed graph visualization. The visualization is created using the Gravis library,\n    which is built on top of D3.js for interactive and dynamic graph visualizations in Jupyter notebooks\n    and other web-based environments.\n\n    Parameters:\n        project (MartiniFlowProject): An instance of MartiniFlowProject containing operations and their relationships.\n\n    Returns:\n        gv.d3: A Gravis D3 graph object that can be displayed in Jupyter notebooks or web environments.\n    \"\"\"\n    ops = project.operations.keys()\n    adj = np.asarray(project.detect_operation_graph())\n\n    g = nx.DiGraph(adj)\n    for i, op in enumerate(ops):\n        g.nodes[i][\"label\"] = op\n    return gv.d3(g, node_label_data_source=\"label\", zoom_factor=1.5)\n</code></pre>"},{"location":"utils/gromacs/","title":"GROMACS","text":""},{"location":"utils/gromacs/#martignac.utils.gromacs.generate_lambdas","title":"<code>generate_lambdas(num_sim, turn_off_coulomb=False)</code>","text":"<p>Generates van der Waals and Coulomb lambda schedules for Gromacs alchemical transformations.</p> <p>Parameters: - num_sim (int): Number of state points. - turn_off_coulomb (bool): If True, Coulomb interactions are turned off and the schedule is dedicated to vdw.</p> <p>Returns: - Tuple[List[float], List[float]]: Lambda schedules for van der Waals and Coulomb interactions.</p> Source code in <code>martignac/utils/gromacs.py</code> <pre><code>def generate_lambdas(num_sim: int, turn_off_coulomb: bool = False):\n    \"\"\"\n    Generates van der Waals and Coulomb lambda schedules for Gromacs alchemical transformations.\n\n    Parameters:\n    - num_sim (int): Number of state points.\n    - turn_off_coulomb (bool): If True, Coulomb interactions are turned off and the schedule is dedicated to vdw.\n\n    Returns:\n    - Tuple[List[float], List[float]]: Lambda schedules for van der Waals and Coulomb interactions.\n    \"\"\"\n    if num_sim &lt; 2:\n        raise ValueError(\"Number of state points must be at least 2.\")\n\n    # Adjust the calculation for vdw_points to ensure a linear increase\n    vdw_points = num_sim if turn_off_coulomb else (num_sim + 1) // 2\n\n    # Generate linearly increasing lambda values for vdw\n    vdw_lambdas = [i / (vdw_points - 1) for i in range(vdw_points)]\n\n    if turn_off_coulomb:\n        coul_lambdas = [0.0] * num_sim\n    else:\n        # Adjust the lambda values for Coulomb, starting from 0 after vdw is fully coupled\n        coul_lambdas = [0.0] * (vdw_points - 1) + [\n            (i - (vdw_points - 1)) / (num_sim - vdw_points)\n            for i in range(vdw_points - 1, num_sim)\n        ]\n\n    # Ensure lambdas list length is num_sim for vdw_lambdas when turn_off_coulomb is False\n    if not turn_off_coulomb:\n        vdw_lambdas += [1.0] * (num_sim - vdw_points)\n\n    return vdw_lambdas, coul_lambdas\n</code></pre>"},{"location":"utils/gromacs/#martignac.utils.gromacs.generate_solvent_with_gromacs","title":"<code>generate_solvent_with_gromacs(gro_solvent_mol, box_length, output_name='solvent', scale=0.1)</code>","text":"<p>Generates a command to solvate a given solvent molecule file using GROMACS.</p> <p>This function constructs a command for the GROMACS 'solvate' tool, which is used to solvate a given solvent molecule file within a cubic box of a specified length. The density of the solvent can be adjusted using the scale parameter.</p> <p>Parameters:</p> Name Type Description Default <code>gro_solvent_mol</code> <code>str</code> <p>The path to the GRO file of the solvent molecules.</p> required <code>box_length</code> <code>float</code> <p>The length of each side of the cubic box in which the solvent molecules will be placed, in nm.</p> required <code>output_name</code> <code>str</code> <p>The base name for the output GRO file. Defaults to \"solvent\".</p> <code>'solvent'</code> <code>scale</code> <code>float</code> <p>The scaling factor for adjusting the density of the solvent. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to execute in GROMACS to generate the solvated system.</p> Source code in <code>martignac/utils/gromacs.py</code> <pre><code>def generate_solvent_with_gromacs(\n    gro_solvent_mol: str,\n    box_length: float,\n    output_name: str = \"solvent\",\n    scale: float = 0.1,\n) -&gt; str:\n    \"\"\"\n    Generates a command to solvate a given solvent molecule file using GROMACS.\n\n    This function constructs a command for the GROMACS 'solvate' tool, which is used to solvate a given\n    solvent molecule file within a cubic box of a specified length. The density of the solvent can be\n    adjusted using the scale parameter.\n\n    Parameters:\n        gro_solvent_mol (str): The path to the GRO file of the solvent molecules.\n        box_length (float): The length of each side of the cubic box in which the solvent molecules will be placed, in nm.\n        output_name (str): The base name for the output GRO file. Defaults to \"solvent\".\n        scale (float): The scaling factor for adjusting the density of the solvent. Defaults to 0.1.\n\n    Returns:\n        str: The command to execute in GROMACS to generate the solvated system.\n    \"\"\"\n    box_size = \" \".join([str(box_length) for _ in range(3)])\n    return f\"gmx solvate -cs {gro_solvent_mol} -box {box_size} -o {output_name}.gro -scale {scale}\"\n</code></pre>"},{"location":"utils/gromacs/#martignac.utils.gromacs.gromacs_simulation_command","title":"<code>gromacs_simulation_command(mdp, top, gro, name, n_max_warn=10, n_threads=1, verbose=True)</code>","text":"<p>Prepares and executes a molecular dynamics simulation using GROMACS.</p> <p>This function generates the necessary commands to prepare (grompp) and run (mdrun) a simulation in GROMACS. It allows for specifying the input files, the number of threads, and whether to run in verbose mode. The function combines the preparation and execution steps into a single command, facilitating streamlined execution of simulations.</p> <p>Parameters:</p> Name Type Description Default <code>mdp</code> <code>str</code> <p>The path to the MDP file containing the simulation parameters.</p> required <code>top</code> <code>str</code> <p>The path to the topology file for the system.</p> required <code>gro</code> <code>str</code> <p>The path to the GRO file containing the system's initial structure.</p> required <code>name</code> <code>str</code> <p>The base name for the output files.</p> required <code>n_max_warn</code> <code>int</code> <p>The maximum number of allowed warnings during the preparation step. Defaults to 10.</p> <code>10</code> <code>n_threads</code> <code>int</code> <p>The number of threads to use for the simulation. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>If True, runs the simulation in verbose mode. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to execute in GROMACS that combines the preparation and execution steps.</p> Source code in <code>martignac/utils/gromacs.py</code> <pre><code>def gromacs_simulation_command(\n    mdp: str,\n    top: str,\n    gro: str,\n    name: str,\n    n_max_warn: int = 10,\n    n_threads: int = 1,\n    verbose: bool = True,\n) -&gt; str:\n    \"\"\"\n    Prepares and executes a molecular dynamics simulation using GROMACS.\n\n    This function generates the necessary commands to prepare (grompp) and run (mdrun) a simulation in GROMACS. It allows\n    for specifying the input files, the number of threads, and whether to run in verbose mode. The function combines the\n    preparation and execution steps into a single command, facilitating streamlined execution of simulations.\n\n    Parameters:\n        mdp (str): The path to the MDP file containing the simulation parameters.\n        top (str): The path to the topology file for the system.\n        gro (str): The path to the GRO file containing the system's initial structure.\n        name (str): The base name for the output files.\n        n_max_warn (int, optional): The maximum number of allowed warnings during the preparation step. Defaults to 10.\n        n_threads (int, optional): The number of threads to use for the simulation. Defaults to 1.\n        verbose (bool, optional): If True, runs the simulation in verbose mode. Defaults to True.\n\n    Returns:\n        str: The command to execute in GROMACS that combines the preparation and execution steps.\n    \"\"\"\n    grompp_cmd = f\"gmx grompp -f {mdp} -p {top} -c {gro} -o {name}.tpr -po {name}_out.mdp -maxwarn {n_max_warn}\"\n    mdrun_cmd = f\"gmx mdrun -nt {n_threads} -deffnm {name}\"\n    if verbose:\n        mdrun_cmd += \" -v\"\n    return f\"{grompp_cmd} &amp;&amp; {mdrun_cmd}\"\n</code></pre>"},{"location":"utils/gromacs/#martignac.utils.gromacs.run_gmx_wham","title":"<code>run_gmx_wham(tpr_files, pullf_files, output_profile, output_hist, output_bstrap, output_bsprof, num_boostrap=100, unit='kT', z_min=0.0, z_max=5.0)</code>","text":"<p>Generates a command to perform Weighted Histogram Analysis Method (WHAM) analysis using GROMACS.</p> <p>This function constructs a command for the GROMACS 'wham' tool, which is used to analyze the results of simulations, particularly for calculating free energy landscapes from umbrella sampling simulations. It supports specifying multiple input files for tpr and pullf files, outputting various analysis results, and setting the number of bootstrap analyses to improve statistical reliability.</p> <p>Parameters:</p> Name Type Description Default <code>tpr_files</code> <code>str</code> <p>The path to the text file containing a list of TPR files for the analysis.</p> required <code>pullf_files</code> <code>str</code> <p>The path to the text file containing a list of pull force files for the analysis.</p> required <code>output_profile</code> <code>str</code> <p>The path for the output free energy profile.</p> required <code>output_hist</code> <code>str</code> <p>The path for the output histogram file.</p> required <code>output_bstrap</code> <code>str</code> <p>The path for the output bootstrap results file.</p> required <code>output_bsprof</code> <code>str</code> <p>The path for the output bootstrap profile file.</p> required <code>num_boostrap</code> <code>int</code> <p>The number of bootstrap analyses to perform. Defaults to 100.</p> <code>100</code> <code>unit</code> <code>str</code> <p>The unit for the free energy calculation. Defaults to \"kT\".</p> <code>'kT'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to execute in GROMACS for WHAM analysis.</p> Source code in <code>martignac/utils/gromacs.py</code> <pre><code>def run_gmx_wham(\n    tpr_files: str,\n    pullf_files: str,\n    output_profile: str,\n    output_hist: str,\n    output_bstrap: str,\n    output_bsprof: str,\n    num_boostrap: int = 100,\n    unit: str = \"kT\",\n    z_min: float = 0.0,\n    z_max: float = 5.0,\n) -&gt; str:\n    \"\"\"\n    Generates a command to perform Weighted Histogram Analysis Method (WHAM) analysis using GROMACS.\n\n    This function constructs a command for the GROMACS 'wham' tool, which is used to analyze the results of\n    simulations, particularly for calculating free energy landscapes from umbrella sampling simulations. It\n    supports specifying multiple input files for tpr and pullf files, outputting various analysis results,\n    and setting the number of bootstrap analyses to improve statistical reliability.\n\n    Parameters:\n        tpr_files (str): The path to the text file containing a list of TPR files for the analysis.\n        pullf_files (str): The path to the text file containing a list of pull force files for the analysis.\n        output_profile (str): The path for the output free energy profile.\n        output_hist (str): The path for the output histogram file.\n        output_bstrap (str): The path for the output bootstrap results file.\n        output_bsprof (str): The path for the output bootstrap profile file.\n        num_boostrap (int): The number of bootstrap analyses to perform. Defaults to 100.\n        unit (str): The unit for the free energy calculation. Defaults to \"kT\".\n\n    Returns:\n        str: The command to execute in GROMACS for WHAM analysis.\n    \"\"\"\n    cmd = (\n        f\"gmx wham -it {tpr_files} -if {pullf_files} -o {output_profile} \"\n        f\"-hist {output_hist} -bsres {output_bstrap} -bsprof {output_bsprof} \"\n        f\"-min {z_min} -max {z_max} -zprof0 {z_max} \"\n        f\"-nBootstrap {num_boostrap} -unit {unit}\"\n    )\n    return cmd\n</code></pre>"},{"location":"utils/gromacs/#martignac.utils.gromacs.solvate_solute_command","title":"<code>solvate_solute_command(gro_solute, gro_solvent, top_solute, top_output='topol.top', output_name='solvate')</code>","text":"<p>Generates a command to solvate a solute with a given solvent using GROMACS.</p> <p>This function constructs a command for the GROMACS 'solvate' tool, which is used to combine a solute and solvent in a simulation box. The dimensions of the box are extracted from the solvent .gro file. It also updates the topology file to include the solvent molecules.</p> <p>Parameters:</p> Name Type Description Default <code>gro_solute</code> <code>str</code> <p>The path to the GRO file of the solute.</p> required <code>gro_solvent</code> <code>str</code> <p>The path to the GRO file of the solvent molecules.</p> required <code>top_solute</code> <code>str</code> <p>The path to the topology file of the solute.</p> required <code>top_output</code> <code>str</code> <p>The path for the output topology file. Defaults to \"topol.top\".</p> <code>'topol.top'</code> <code>output_name</code> <code>str</code> <p>The base name for the output GRO file. Defaults to \"solvate\".</p> <code>'solvate'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to execute in GROMACS to solvate the solute with the solvent.</p> Source code in <code>martignac/utils/gromacs.py</code> <pre><code>def solvate_solute_command(\n    gro_solute: str,\n    gro_solvent: str,\n    top_solute: str,\n    top_output: str = \"topol.top\",\n    output_name: str = \"solvate\",\n) -&gt; str:\n    \"\"\"\n    Generates a command to solvate a solute with a given solvent using GROMACS.\n\n    This function constructs a command for the GROMACS 'solvate' tool, which is used to combine a solute and solvent\n    in a simulation box. The dimensions of the box are extracted from the solvent .gro file. It also updates the topology\n    file to include the solvent molecules.\n\n    Parameters:\n        gro_solute (str): The path to the GRO file of the solute.\n        gro_solvent (str): The path to the GRO file of the solvent molecules.\n        top_solute (str): The path to the topology file of the solute.\n        top_output (str, optional): The path for the output topology file. Defaults to \"topol.top\".\n        output_name (str, optional): The base name for the output GRO file. Defaults to \"solvate\".\n\n    Returns:\n        str: The command to execute in GROMACS to solvate the solute with the solvent.\n    \"\"\"\n\n    def extract_box_size_from_gro(gro_file):\n        with open(gro_file) as f:\n            lines = f.readlines()\n            box_dimensions = lines[-1].split()\n            return \" \".join([str(dim) for dim in box_dimensions])\n\n    box_size = extract_box_size_from_gro(gro_solvent)\n    shutil.copy(top_solute, top_output)\n    cmd = f\"gmx solvate -cp {gro_solute} -cs {gro_solvent} -box {box_size} -p {top_output} -o {output_name}.gro \"\n    return cmd\n</code></pre>"},{"location":"utils/insane/","title":"INSANE","text":""},{"location":"utils/insane/#martignac.utils.insane.generate_bilayer_with_insane","title":"<code>generate_bilayer_with_insane(lipids, solvent, box_length_xy, box_length_z, gro_bilayer_gen, top_bilayer)</code>","text":"<p>Generates a command for creating a lipid bilayer system using the INSANE tool.</p> <p>This function constructs a command line instruction for the INSANE (INitiation of Solvated membrANEs) tool, which is used to generate a lipid bilayer system. The command includes specifications for the lipid and solvent compositions, the dimensions of the simulation box, and the output files for the generated system.</p> <p>Parameters:</p> Name Type Description Default <code>lipids</code> <code>LiquidMixture</code> <p>A LiquidMixture object representing the lipid composition of the bilayer.</p> required <code>solvent</code> <code>LiquidMixture</code> <p>A LiquidMixture object representing the solvent composition.</p> required <code>box_length_xy</code> <code>float</code> <p>The length of the simulation box in the x and y dimensions, in nanometers.</p> required <code>box_length_z</code> <code>float</code> <p>The height of the simulation box in the z dimension, in nanometers.</p> required <code>gro_bilayer_gen</code> <code>str</code> <p>The filename for the generated GRO file of the bilayer system.</p> required <code>top_bilayer</code> <code>str</code> <p>The filename for the generated topology (TOP) file of the bilayer system.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to be executed for generating the bilayer system with INSANE.</p> Source code in <code>martignac/utils/insane.py</code> <pre><code>def generate_bilayer_with_insane(\n    lipids: LiquidMixture,\n    solvent: LiquidMixture,\n    box_length_xy: float,\n    box_length_z: float,\n    gro_bilayer_gen: str,\n    top_bilayer: str,\n) -&gt; str:\n    \"\"\"\n    Generates a command for creating a lipid bilayer system using the INSANE tool.\n\n    This function constructs a command line instruction for the INSANE (INitiation of Solvated membrANEs) tool,\n    which is used to generate a lipid bilayer system. The command includes specifications for the lipid and solvent\n    compositions, the dimensions of the simulation box, and the output files for the generated system.\n\n    Parameters:\n        lipids (LiquidMixture): A LiquidMixture object representing the lipid composition of the bilayer.\n        solvent (LiquidMixture): A LiquidMixture object representing the solvent composition.\n        box_length_xy (float): The length of the simulation box in the x and y dimensions, in nanometers.\n        box_length_z (float): The height of the simulation box in the z dimension, in nanometers.\n        gro_bilayer_gen (str): The filename for the generated GRO file of the bilayer system.\n        top_bilayer (str): The filename for the generated topology (TOP) file of the bilayer system.\n\n    Returns:\n        str: The command to be executed for generating the bilayer system with INSANE.\n    \"\"\"\n\n    return (\n        f\"insane -l {lipids.to_insane_format(separator=' -l ')} -d {box_length_xy} -dz {box_length_z} \"\n        f\"-sol {solvent.to_insane_format(separator=' -sol ')} -o {gro_bilayer_gen} -p {top_bilayer}\"\n    )\n</code></pre>"},{"location":"utils/martini_flow_projects/","title":"Martini flow projects","text":""},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.MartiniFlowProject","title":"<code>MartiniFlowProject</code>","text":"<p>               Bases: <code>FlowProject</code></p> <p>A specialized FlowProject for managing and executing Martini-based molecular dynamics simulations.</p> <p>This class extends the FlowProject class from the signac framework, providing functionalities specific to the setup, execution, and analysis of simulations using the Martini force field. It includes methods for registering simulation input files, uploading results to the NOMAD repository, and managing the simulation workflow states.</p> <p>Attributes:</p> Name Type Description <code>workspaces_path</code> <code>str</code> <p>Absolute path to the directory where simulation workspaces are stored.</p> <code>input_files_path</code> <code>str</code> <p>Absolute path to the directory containing input files for simulations.</p> <code>itp_path</code> <code>str</code> <p>Absolute path to the directory containing ITP (GROMACS topology) files.</p> <code>nomad_use_prod_database</code> <code>bool</code> <p>Flag indicating whether to use the production NOMAD database.</p> <code>nomad_dataset_id</code> <code>str</code> <p>Identifier for the dataset within the NOMAD repository.</p> <code>nomad_coauthors</code> <code>list[str]</code> <p>List of co-authors to be included in the NOMAD metadata.</p> <code>workspace_path</code> <code>str</code> <p>Path to the current job's workspace directory.</p> <code>itp_files</code> <code>Dict[str, str]</code> <p>Dictionary mapping ITP file names to their paths.</p> <code>mdp_path</code> <code>str</code> <p>Path to the directory containing MDP (GROMACS parameters) files.</p> <code>mdp_files</code> <code>Dict[str, str]</code> <p>Dictionary mapping MDP file names to their paths.</p> <code>simulation_settings</code> <code>Dict[str, Any]</code> <p>Dictionary containing settings for the simulation.</p> <code>system_name</code> <code>str</code> <p>Name of the simulation system.</p> <code>output_names</code> <code>Dict[str, str]</code> <p>Dictionary mapping output file types to their names.</p> <code>nomad_workflow</code> <code>str</code> <p>Identifier for the workflow within the NOMAD repository.</p> <code>nomad_top_level_workflow</code> <code>str</code> <p>Identifier for the top-level workflow within NOMAD.</p> <code>ff_parameters</code> <code>Dict[str, Any]</code> <p>Dictionary containing force field parameters.</p> <code>operation_to_workflow</code> <code>Dict[str, str]</code> <p>Mapping of operation names to workflow identifiers.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>class MartiniFlowProject(FlowProject):\n    \"\"\"\n    A specialized FlowProject for managing and executing Martini-based molecular dynamics simulations.\n\n    This class extends the FlowProject class from the signac framework, providing functionalities specific to\n    the setup, execution, and analysis of simulations using the Martini force field. It includes methods for\n    registering simulation input files, uploading results to the NOMAD repository, and managing the simulation\n    workflow states.\n\n    Attributes:\n        workspaces_path (str): Absolute path to the directory where simulation workspaces are stored.\n        input_files_path (str): Absolute path to the directory containing input files for simulations.\n        itp_path (str): Absolute path to the directory containing ITP (GROMACS topology) files.\n        nomad_use_prod_database (bool): Flag indicating whether to use the production NOMAD database.\n        nomad_dataset_id (str): Identifier for the dataset within the NOMAD repository.\n        nomad_coauthors (list[str]): List of co-authors to be included in the NOMAD metadata.\n        workspace_path (str): Path to the current job's workspace directory.\n        itp_files (Dict[str, str]): Dictionary mapping ITP file names to their paths.\n        mdp_path (str): Path to the directory containing MDP (GROMACS parameters) files.\n        mdp_files (Dict[str, str]): Dictionary mapping MDP file names to their paths.\n        simulation_settings (Dict[str, Any]): Dictionary containing settings for the simulation.\n        system_name (str): Name of the simulation system.\n        output_names (Dict[str, str]): Dictionary mapping output file types to their names.\n        nomad_workflow (str): Identifier for the workflow within the NOMAD repository.\n        nomad_top_level_workflow (str): Identifier for the top-level workflow within NOMAD.\n        ff_parameters (Dict[str, Any]): Dictionary containing force field parameters.\n        operation_to_workflow (Dict[str, str]): Mapping of operation names to workflow identifiers.\n    \"\"\"\n\n    workspaces_path: str = config()[\"local\"][\"workspaces\"][\"absolute_path\"].get(str)\n    input_files_path: str = config()[\"local\"][\"input_files\"][\"absolute_path\"].get(str)\n    itp_path: str = config()[\"local\"][\"input_files\"][\"itp_files\"].get(str)\n    nomad_use_prod_database: bool = config()[\"nomad\"][\"use_prod\"].get(bool)\n    nomad_dataset_id: str = config()[\"nomad\"][\"dataset\"][\"id\"].get(str)\n    try:\n        nomad_coauthors: list[str] = [\n            c.get(str) for c in config()[\"nomad\"][\"coauthors\"]\n        ]\n    except KeyError:\n        nomad_coauthors: list[str] = []\n    allow_symlinks: bool = config()[\"local\"][\"allow_symlinks\"].get(bool)\n    workspace_path: str = \"\"\n    itp_files: Dict[str, str] = {}\n    mdp_path: str\n    mdp_files: Dict[str, str] = {}\n    simulation_settings: Dict[str, Any] = {}\n    system_name: str\n    output_names: Dict[str, str] = {}\n    nomad_workflow: str = \"\"\n    nomad_top_level_workflow: str = \"\"\n    ff_parameters: Dict[str, Any] = {}\n    operation_to_workflow: Dict[str, str] = {}\n\n    @classmethod\n    def class_name(cls) -&gt; str:\n        return cls.__name__\n\n    @classmethod\n    def get_hash_for_files(cls, job: Job, files: list[str]) -&gt; str:\n        readouts = []\n        for filename in files:\n            with open(job.fn(filename)) as fp:\n                readouts.append(fp.read())\n        return md5(\" \".join(readouts).encode(\"utf-8\")).hexdigest()\n\n    @classmethod\n    def register_mdp_files(cls, job: Job) -&gt; None:\n        job.doc = update_nested_dict(\n            job.doc,\n            {\n                cls.class_name(): {\n                    \"mdp_files\": cls.get_hash_for_files(\n                        job, list(cls.mdp_files.values())\n                    )\n                }\n            },\n        )\n\n    @classmethod\n    def register_itp_files(cls, job: Job) -&gt; None:\n        job.doc = update_nested_dict(\n            job.doc,\n            {\n                cls.class_name(): {\n                    \"itp_files\": cls.get_hash_for_files(\n                        job, list(cls.itp_files.values())\n                    )\n                }\n            },\n        )\n\n    @classmethod\n    def get_state_name(cls, state_name: str = \"\", extension: str = \"\") -&gt; str:\n        state_ext = f\"_{state_name}\" if state_name else \"\"\n        file_ext = f\".{extension}\" if extension else \"\"\n        return f\"{cls.system_name}{state_ext}{file_ext}\"\n\n    @classmethod\n    def nomad_comment(cls, job: Job) -&gt; dict:\n        return {\n            \"job_id\": job.id,\n            \"workflow_name\": cls.class_name(),\n            \"state_point\": job.sp(),\n            \"mdp_files\": job.doc[cls.class_name()][\"mdp_files\"],\n            \"itp_files\": job.doc[cls.class_name()][\"itp_files\"],\n        }\n\n    @classmethod\n    def upload_to_nomad(\n        cls,\n        job: Job,\n        nomad_upload_flag: bool = UPLOAD_TO_NOMAD,\n        publish_flag: bool = PUBLISH_TO_NOMAD,\n    ) -&gt; None:\n        if not nomad_upload_flag:\n            logger.info(\"NOMAD upload turned off\")\n            return None\n        if uploaded_to_nomad(job):\n            project_name = cast(\"MartiniFlowProject\", job.project).class_name()\n            upload_id = job.doc[project_name].get(\"nomad_upload_id\", \"\")\n            logger.info(f\"Workflow {cls.class_name()} already uploaded to {upload_id}\")\n            return None\n        dataset = get_dataset_by_id(\n            cls.nomad_dataset_id, use_prod=cls.nomad_use_prod_database\n        )\n        logger.info(f\"made connection to dataset {dataset.dataset_id}\")\n        generate_user_metadata(\n            file_name=job.fn(\"nomad.yaml\"),\n            comment=json.dumps(cls.nomad_comment(job)),\n            coauthors=cls.nomad_coauthors,\n            datasets=[dataset.dataset_id],\n        )\n        job.doc = update_nested_dict(job.doc, {\"nomad_dataset_id\": dataset.dataset_id})\n        zip_file = zip_directories([job.path], job.id)\n        upload_id = upload_files_to_nomad(zip_file, cls.nomad_use_prod_database)\n        job.doc = update_nested_dict(\n            job.doc, {cls.class_name(): {\"nomad_upload_id\": upload_id}}\n        )\n        if publish_flag:\n            sleep(1)\n            nomad_upload = get_upload_by_id(\n                upload_id=upload_id, use_prod=cls.nomad_use_prod_database\n            )\n            nomad_upload.safe_publish()\n        os.remove(zip_file)\n        return None\n\n    @classmethod\n    def upload_to_nomad_multiple_jobs(\n        cls,\n        jobs: list[Job],\n        nomad_upload_flag: bool = UPLOAD_TO_NOMAD,\n        publish_flag: bool = PUBLISH_TO_NOMAD,\n    ) -&gt; None:\n        if not nomad_upload_flag:\n            logger.info(\"NOMAD upload turned off\")\n            return None\n        dataset = get_dataset_by_id(\n            cls.nomad_dataset_id, use_prod=cls.nomad_use_prod_database\n        )\n        logger.info(f\"made connection to dataset {dataset.dataset_id}\")\n        for job in jobs:\n            if uploaded_to_nomad(job):\n                project_name = cast(\"MartiniFlowProject\", job.project).class_name()\n                upload_id = job.doc[project_name].get(\"nomad_upload_id\", \"\")\n                logger.info(\n                    f\"Workflow {cls.class_name()} already uploaded to {upload_id}\"\n                )\n                return None\n            job.doc = update_nested_dict(\n                job.doc, {\"nomad_dataset_id\": dataset.dataset_id}\n            )\n            generate_user_metadata(\n                file_name=job.fn(\"nomad.yaml\"),\n                comment=json.dumps(cls.nomad_comment(job)),\n                coauthors=cls.nomad_coauthors,\n                datasets=[dataset.dataset_id],\n            )\n        zip_file = zip_directories([job.path for job in jobs], jobs[0].id)\n        upload_id = upload_files_to_nomad(zip_file, cls.nomad_use_prod_database)\n        os.remove(zip_file)\n        for job in jobs:\n            job.doc = update_nested_dict(\n                job.doc, {cls.class_name(): {\"nomad_upload_id\": upload_id}}\n            )\n        if publish_flag:\n            sleep(1)\n            nomad_upload = get_upload_by_id(\n                upload_id=upload_id, use_prod=cls.nomad_use_prod_database\n            )\n            nomad_upload.safe_publish()\n        return None\n\n    @classmethod\n    def unlink_itp_and_mdp_files(cls, job: Job) -&gt; None:\n        project = cast(\"MartiniFlowProject\", job.project)\n        logger.info(f\"removing symbolic links for {job.id} @ {project.class_name()}\")\n        for root, _, files in os.walk(job.path):\n            for file in filter(\n                lambda f: f.endswith((\".itp\", \".mdp\"))\n                and os.path.islink(os.path.join(root, f)),\n                files,\n            ):\n                if project.allow_symlinks:\n                    os.unlink(os.path.join(root, file))\n                else:\n                    os.remove(os.path.join(root, file))\n        if \"files_symlinked\" not in job.document:\n            job.document[\"files_symlinked\"] = {}\n        job.document[\"files_symlinked\"][project.class_name()] = False\n\n    @classmethod\n    def init_and_get_project(cls) -&gt; MartiniTypeFlow:\n        if not os.path.isdir(cls.workspace_path):\n            os.makedirs(cls.workspace_path)\n        signac.init_project(path=cls.workspace_path)\n        return cls.get_project(path=cls.workspace_path)\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.fetch_from_nomad","title":"<code>fetch_from_nomad(*jobs)</code>","text":"<p>Fetches data for a given set of jobs from the NOMAD repository.</p> <p>This operation attempts to download raw data associated with each job from the NOMAD repository. It logs the success or failure of data retrieval for each job. If data is successfully fetched, it updates the job's document to reflect this. This function is useful for synchronizing local job data with data stored in NOMAD, ensuring that the local project state accurately reflects the data stored in the repository.</p> <p>Parameters:</p> Name Type Description Default <code>*jobs</code> <code>Job</code> <p>A variable number of signac job instances for which data is being fetched from NOMAD.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but updates each job's document with the fetch status.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>@MartiniFlowProject.pre(itp_mdp_files_symlinked)\n@MartiniFlowProject.post(fetched_from_nomad)\n@MartiniFlowProject.operation(with_job=True)\ndef fetch_from_nomad(*jobs) -&gt; None:\n    \"\"\"\n    Fetches data for a given set of jobs from the NOMAD repository.\n\n    This operation attempts to download raw data associated with each job from the NOMAD repository. It logs\n    the success or failure of data retrieval for each job. If data is successfully fetched, it updates the job's\n    document to reflect this. This function is useful for synchronizing local job data with data stored in NOMAD,\n    ensuring that the local project state accurately reflects the data stored in the repository.\n\n    Parameters:\n        *jobs (Job): A variable number of signac job instances for which data is being fetched from NOMAD.\n\n    Returns:\n        None: This function does not return a value but updates each job's document with the fetch status.\n    \"\"\"\n    from martignac.nomad.entries import download_raw_data_of_job\n\n    for job in jobs:\n        logger.info(f\"Attempting to fetch job {job.id} from NOMAD\")\n        initialize_job_doc(job)\n        result = download_raw_data_of_job(job)\n        if result:\n            logger.info(f\"Remote data was found on NOMAD for {job.id}\")\n        else:\n            logger.info(f\"No remote data was found on NOMAD for {job.id}\")\n        project_name = cast(\"MartiniFlowProject\", job.project).class_name()\n        job.doc[project_name][\"fetched_nomad\"] = True\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.import_job_from_other_flow","title":"<code>import_job_from_other_flow(job, child_project, child_job, keys_for_files_to_copy, run_child_job=True)</code>","text":"<p>Imports data from a job in a child project into the current job's context.</p> <p>This function is designed to facilitate the transfer of data between jobs across different projects within the MartiniFlow framework. It optionally runs the child job before copying specified files from the child job's directory to the current job's directory. This is particularly useful for workflows that require data generated in one project to be used in another.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The current signac job instance into which data is being imported.</p> required <code>child_project</code> <code>MartiniTypeFlow</code> <p>The child project instance from which data is being imported.</p> required <code>child_job</code> <code>Job</code> <p>The child project's signac job instance from which data is being imported.</p> required <code>keys_for_files_to_copy</code> <code>list[str]</code> <p>A list of keys identifying the files in the child job's document                                 that should be copied to the current job's directory.</p> required <code>run_child_job</code> <code>bool</code> <p>A flag indicating whether the child job should be executed before                             data is imported. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but updates the current job's directory with the imported   files and updates the job's document with information from the child job's document.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def import_job_from_other_flow(\n    job: Job,\n    child_project: MartiniTypeFlow,\n    child_job: Job,\n    keys_for_files_to_copy: list[str],\n    run_child_job: bool = True,\n) -&gt; None:\n    \"\"\"\n    Imports data from a job in a child project into the current job's context.\n\n    This function is designed to facilitate the transfer of data between jobs across different projects within\n    the MartiniFlow framework. It optionally runs the child job before copying specified files from the child\n    job's directory to the current job's directory. This is particularly useful for workflows that require\n    data generated in one project to be used in another.\n\n    Parameters:\n        job (Job): The current signac job instance into which data is being imported.\n        child_project (MartiniTypeFlow): The child project instance from which data is being imported.\n        child_job (Job): The child project's signac job instance from which data is being imported.\n        keys_for_files_to_copy (list[str]): A list of keys identifying the files in the child job's document\n                                            that should be copied to the current job's directory.\n        run_child_job (bool, optional): A flag indicating whether the child job should be executed before\n                                        data is imported. Defaults to True.\n\n    Returns:\n        None: This function does not return a value but updates the current job's directory with the imported\n              files and updates the job's document with information from the child job's document.\n    \"\"\"\n    if run_child_job:\n        logger.info(f\"Running job {child_job.id} @  {child_project.class_name()}\")\n        child_project.run(jobs=[child_job])\n        logger.info(\n            f\"Finished running job {child_job.id} @ {child_project.class_name()}\"\n        )\n    for key in keys_for_files_to_copy:\n        shutil.copy(\n            child_job.fn(child_job.doc[child_project.class_name()].get(key)), job.path\n        )\n    job.doc = update_nested_dict(\n        job.doc, {child_project.class_name(): child_job.doc[child_project.class_name()]}\n    )\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_gromacs_log_to_doc","title":"<code>store_gromacs_log_to_doc(operation_name, job)</code>","text":"<p>Stores the GROMACS log file information in the job document without state point differentiation.</p> <p>This function is a simplified wrapper around <code>_store_gromacs_log_to_doc_flexible</code>, specifically designed for cases where differentiation based on state points is not required. It logs the GROMACS simulation details into the job's document, using only the operation name for identification.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation being logged. This typically corresponds to the                   GROMACS command being executed.</p> required <code>job</code> <code>Job</code> <p>The signac job instance for which the log is being stored. This job contains the document        where the log information is stored.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job's document with the log file information.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_gromacs_log_to_doc(operation_name: str, job: Job):\n    \"\"\"\n    Stores the GROMACS log file information in the job document without state point differentiation.\n\n    This function is a simplified wrapper around `_store_gromacs_log_to_doc_flexible`, specifically designed\n    for cases where differentiation based on state points is not required. It logs the GROMACS simulation\n    details into the job's document, using only the operation name for identification.\n\n    Parameters:\n        operation_name (str): The name of the operation being logged. This typically corresponds to the\n                              GROMACS command being executed.\n        job (Job): The signac job instance for which the log is being stored. This job contains the document\n                   where the log information is stored.\n\n    Returns:\n        None: This function does not return a value but updates the job's document with the log file information.\n    \"\"\"\n    _store_gromacs_log_to_doc_flexible(operation_name, job, False)\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_gromacs_log_to_doc_with_depth_from_bilayer_core","title":"<code>store_gromacs_log_to_doc_with_depth_from_bilayer_core(operation_name, job)</code>","text":"<p>Stores the GROMACS log file information in the job document, including differentiation based on the depth from the bilayer core.</p> <p>This function is specifically designed for simulations where the depth from the bilayer core is a relevant parameter. It utilizes <code>_store_gromacs_log_to_doc_flexible</code> with the <code>with_state_point</code> flag set to True and specifies \"depth_from_bilayer_core\" as the state point key for differentiation. This allows for the inclusion of depth-related details in the log file's identification, facilitating more granular analysis of simulation results based on their proximity to the bilayer core.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation being logged. This typically corresponds to the                   GROMACS command being executed.</p> required <code>job</code> <code>Job</code> <p>The signac job instance for which the log is being stored. This job contains the document        where the log information is stored.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job's document with the log file information,   including differentiation based on the depth from the bilayer core.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_gromacs_log_to_doc_with_depth_from_bilayer_core(\n    operation_name: str, job: Job\n):\n    \"\"\"\n    Stores the GROMACS log file information in the job document, including differentiation based on the depth from the bilayer core.\n\n    This function is specifically designed for simulations where the depth from the bilayer core is a relevant parameter. It utilizes\n    `_store_gromacs_log_to_doc_flexible` with the `with_state_point` flag set to True and specifies \"depth_from_bilayer_core\" as the\n    state point key for differentiation. This allows for the inclusion of depth-related details in the log file's identification,\n    facilitating more granular analysis of simulation results based on their proximity to the bilayer core.\n\n    Parameters:\n        operation_name (str): The name of the operation being logged. This typically corresponds to the\n                              GROMACS command being executed.\n        job (Job): The signac job instance for which the log is being stored. This job contains the document\n                   where the log information is stored.\n\n    Returns:\n        None: This function does not return a value but updates the job's document with the log file information,\n              including differentiation based on the depth from the bilayer core.\n    \"\"\"\n    _store_gromacs_log_to_doc_flexible(\n        operation_name, job, True, state_point_key=\"depth_from_bilayer_core\"\n    )\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_gromacs_log_to_doc_with_state_point","title":"<code>store_gromacs_log_to_doc_with_state_point(operation_name, job)</code>","text":"<p>Stores the GROMACS log file information in the job document with state point differentiation.</p> <p>This function is designed to log GROMACS simulation details into the job's document, incorporating state point information for differentiation. It utilizes <code>_store_gromacs_log_to_doc_flexible</code> with the <code>with_state_point</code> flag set to True, allowing for the inclusion of state point details in the log file's identification.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation being logged. This typically corresponds to the                   GROMACS command being executed.</p> required <code>job</code> <code>Job</code> <p>The signac job instance for which the log is being stored. This job contains the document        where the log information is stored.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job's document with the log file information,   including state point differentiation.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_gromacs_log_to_doc_with_state_point(operation_name: str, job: Job):\n    \"\"\"\n    Stores the GROMACS log file information in the job document with state point differentiation.\n\n    This function is designed to log GROMACS simulation details into the job's document, incorporating\n    state point information for differentiation. It utilizes `_store_gromacs_log_to_doc_flexible` with\n    the `with_state_point` flag set to True, allowing for the inclusion of state point details in the\n    log file's identification.\n\n    Parameters:\n        operation_name (str): The name of the operation being logged. This typically corresponds to the\n                              GROMACS command being executed.\n        job (Job): The signac job instance for which the log is being stored. This job contains the document\n                   where the log information is stored.\n\n    Returns:\n        None: This function does not return a value but updates the job's document with the log file information,\n              including state point differentiation.\n    \"\"\"\n    _store_gromacs_log_to_doc_flexible(operation_name, job, True)\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_task","title":"<code>store_task(operation_name, job)</code>","text":"<p>Logs a workflow task for a given job in the project's documentation.</p> <p>This function updates the job's document to log the execution of a specific task within the workflow. It is part of the project's utilities for tracking the progress and state of jobs, specifically by recording which tasks have been run. This aids in the management and review of the job's lifecycle within the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation or task being logged. This name should correspond to a                   defined operation within the workflow.</p> required <code>job</code> <code>Job</code> <p>The signac job instance for which the task is being logged. This job's document is updated with        the task information.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job's document with the task information.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_task(operation_name: str, job: Job):\n    \"\"\"\n    Logs a workflow task for a given job in the project's documentation.\n\n    This function updates the job's document to log the execution of a specific task within the workflow. It is\n    part of the project's utilities for tracking the progress and state of jobs, specifically by recording which\n    tasks have been run. This aids in the management and review of the job's lifecycle within the workflow.\n\n    Parameters:\n        operation_name (str): The name of the operation or task being logged. This name should correspond to a\n                              defined operation within the workflow.\n        job (Job): The signac job instance for which the task is being logged. This job's document is updated with\n                   the task information.\n\n    Returns:\n        None: This function does not return a value but updates the job's document with the task information.\n    \"\"\"\n    logger.info(f\"logging workflow task {operation_name} @ {job.id}\")\n    project_ = cast(MartiniFlowProject, job.project)\n    job.doc = update_nested_dict(\n        job.doc, {project_.class_name(): {\"tasks\": {operation_name: \"run\"}}}\n    )\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_task_for_many_jobs","title":"<code>store_task_for_many_jobs(operation_name, *jobs)</code>","text":"<p>Logs a workflow task for multiple jobs in the project's documentation.</p> <p>This function iterates over a collection of jobs, logging the execution of a specified task within the workflow for each job. It leverages the <code>store_task</code> function to individually update each job's document. This is useful for batch processing or when the same task is executed across multiple jobs, ensuring consistent documentation and tracking of workflow tasks across the project.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation or task being logged. This name should correspond to a                   defined operation within the workflow.</p> required <code>*jobs</code> <code>Job</code> <p>A variable number of signac job instances for which the task is being logged. Each job's          document is updated with the task information.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates each job's document with the task information.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_task_for_many_jobs(operation_name: str, *jobs):\n    \"\"\"\n    Logs a workflow task for multiple jobs in the project's documentation.\n\n    This function iterates over a collection of jobs, logging the execution of a specified task within the workflow\n    for each job. It leverages the `store_task` function to individually update each job's document. This is useful\n    for batch processing or when the same task is executed across multiple jobs, ensuring consistent documentation\n    and tracking of workflow tasks across the project.\n\n    Parameters:\n        operation_name (str): The name of the operation or task being logged. This name should correspond to a\n                              defined operation within the workflow.\n        *jobs (Job): A variable number of signac job instances for which the task is being logged. Each job's\n                     document is updated with the task information.\n\n    Returns:\n        None: This function does not return a value but updates each job's document with the task information.\n    \"\"\"\n    for job in jobs:\n        store_task(operation_name, job)\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_workflow","title":"<code>store_workflow(operation_name, job)</code>","text":"<p>Logs the association of a workflow with a given job in the project's documentation.</p> <p>This function updates the job's document to log the association of a specific workflow, identified by the operation name, with the job. It is part of the project's utilities for tracking the progress and state of jobs, specifically by recording which workflows have been associated with them. This aids in the management and review of the job's lifecycle within the workflow system.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation or workflow being logged. This name should correspond to a                   defined operation within the project's workflow system.</p> required <code>job</code> <code>Job</code> <p>The signac job instance for which the workflow association is being logged. This job's document        is updated with the workflow association information.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the operation name is not registered within the project's operation to workflow mapping,         indicating that the operation is not recognized by the project.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job's document with the workflow association   information.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_workflow(operation_name: str, job: Job):\n    \"\"\"\n    Logs the association of a workflow with a given job in the project's documentation.\n\n    This function updates the job's document to log the association of a specific workflow, identified by the\n    operation name, with the job. It is part of the project's utilities for tracking the progress and state of\n    jobs, specifically by recording which workflows have been associated with them. This aids in the management\n    and review of the job's lifecycle within the workflow system.\n\n    Parameters:\n        operation_name (str): The name of the operation or workflow being logged. This name should correspond to a\n                              defined operation within the project's workflow system.\n        job (Job): The signac job instance for which the workflow association is being logged. This job's document\n                   is updated with the workflow association information.\n\n    Raises:\n        ValueError: If the operation name is not registered within the project's operation to workflow mapping,\n                    indicating that the operation is not recognized by the project.\n\n    Returns:\n        None: This function does not return a value but updates the job's document with the workflow association\n              information.\n    \"\"\"\n    project_ = cast(MartiniFlowProject, job.project)\n    logger.info(\n        f\"logging workflow {project_.class_name()} for {operation_name} @ {job.id}\"\n    )\n    if operation_name not in project_.operation_to_workflow:\n        raise ValueError(\n            f\"operation {operation_name} @ {job.id} has not been registered\"\n        )\n    job.doc = update_nested_dict(\n        job.doc,\n        {\n            project_.class_name(): {\n                \"workflows\": {\n                    operation_name: project_.operation_to_workflow[operation_name]\n                }\n            }\n        },\n    )\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.store_workflow_for_many_jobs","title":"<code>store_workflow_for_many_jobs(operation_name, *jobs)</code>","text":"<p>Logs the association of a specified workflow with multiple jobs in the project's documentation.</p> <p>This function iterates over a collection of jobs, logging the association of a specified workflow, identified by the operation name, with each job. It leverages the <code>store_workflow</code> function to individually update each job's document. This is useful for batch processing or when the same workflow is associated across multiple jobs, ensuring consistent documentation and tracking of workflow associations across the project.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The name of the operation or workflow being logged. This name should correspond to a                   defined operation within the project's workflow system.</p> required <code>*jobs</code> <code>Job</code> <p>A variable number of signac job instances for which the workflow association is being logged.          Each job's document is updated with the workflow association information.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates each job's document with the workflow association   information.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>def store_workflow_for_many_jobs(operation_name: str, *jobs):\n    \"\"\"\n    Logs the association of a specified workflow with multiple jobs in the project's documentation.\n\n    This function iterates over a collection of jobs, logging the association of a specified workflow, identified by the\n    operation name, with each job. It leverages the `store_workflow` function to individually update each job's document.\n    This is useful for batch processing or when the same workflow is associated across multiple jobs, ensuring consistent\n    documentation and tracking of workflow associations across the project.\n\n    Parameters:\n        operation_name (str): The name of the operation or workflow being logged. This name should correspond to a\n                              defined operation within the project's workflow system.\n        *jobs (Job): A variable number of signac job instances for which the workflow association is being logged.\n                     Each job's document is updated with the workflow association information.\n\n    Returns:\n        None: This function does not return a value but updates each job's document with the workflow association\n              information.\n    \"\"\"\n    for job in jobs:\n        store_workflow(operation_name, job)\n</code></pre>"},{"location":"utils/martini_flow_projects/#martignac.utils.martini_flow_projects.symlink_itp_and_mdp_files","title":"<code>symlink_itp_and_mdp_files(job)</code>","text":"<p>Creates symbolic links for ITP and MDP files in the job's directory.</p> <p>This function generates symbolic links for each ITP (GROMACS topology) and MDP (GROMACS parameters) file within the job's directory, facilitating their use in simulation workflows. It ensures that the necessary simulation input files are accessible in the job's working directory without duplicating data. If a file already exists in the job's directory, it will not create a duplicate symlink.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The signac job instance for which the symbolic links are being created.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but updates the job's directory with symbolic links.</p> Source code in <code>martignac/utils/martini_flow_projects.py</code> <pre><code>@MartiniFlowProject.post(itp_mdp_files_symlinked)\n@MartiniFlowProject.operation(with_job=True)\ndef symlink_itp_and_mdp_files(job: Job) -&gt; None:\n    \"\"\"\n    Creates symbolic links for ITP and MDP files in the job's directory.\n\n    This function generates symbolic links for each ITP (GROMACS topology) and MDP (GROMACS parameters) file\n    within the job's directory, facilitating their use in simulation workflows. It ensures that the necessary\n    simulation input files are accessible in the job's working directory without duplicating data. If a file\n    already exists in the job's directory, it will not create a duplicate symlink.\n\n    Parameters:\n        job (Job): The signac job instance for which the symbolic links are being created.\n\n    Returns:\n        None: This function does not return a value but updates the job's directory with symbolic links.\n    \"\"\"\n    project = cast(\"MartiniFlowProject\", job.project)\n    logger.info(f\"generating symbolic links for {job.id} @ {project.class_name()}\")\n\n    def symlink_or_copy(files, _path):\n        for file in files:\n            if not job.isfile(os.path.basename(file)):\n                if not os.path.isfile(f\"{_path}/{file}\"):\n                    raise FileNotFoundError(f\"{_path}/{file} not found\")\n                if project.allow_symlinks:\n                    os.symlink(f\"{_path}/{file}\", job.fn(os.path.basename(file)))\n                else:\n                    shutil.copy(f\"{_path}/{file}\", job.fn(os.path.basename(file)))\n\n    symlink_or_copy(project.itp_files.values(), project.itp_path)\n    symlink_or_copy(project.mdp_files.values(), project.mdp_path)\n\n    job.doc = update_nested_dict(\n        job.doc, {project.class_name(): {\"files_symlinked\": True}}\n    )\n</code></pre>"},{"location":"utils/misc/","title":"Misc.","text":""},{"location":"utils/misc/#martignac.utils.misc.calculate_average_com","title":"<code>calculate_average_com(gro_file_path, molecule_names)</code>","text":"<p>Calculates the average center of mass (COM) of specified molecules in a GRO file.</p> <p>This function loads a molecular structure from a GRO file and calculates the average center of mass for the specified molecules. If no molecule names are provided, it calculates the COM for all atoms in the file. This can be useful for determining the central point of a group of molecules or the entire system for further analysis or manipulation.</p> <p>Parameters:</p> Name Type Description Default <code>gro_file_path</code> <code>str</code> <p>The path to the input GRO file containing the molecular structure.</p> required <code>molecule_names</code> <code>list[str]</code> <p>A list of molecule names (residue names) for which to calculate the COM. If empty,                         the COM of all atoms in the file is calculated.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A 1D numpy array containing the x, y, z coordinates of the average center of mass.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no atoms are found for the specified molecule names in the GRO file.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def calculate_average_com(gro_file_path: str, molecule_names: list[str]) -&gt; np.ndarray:\n    \"\"\"\n    Calculates the average center of mass (COM) of specified molecules in a GRO file.\n\n    This function loads a molecular structure from a GRO file and calculates the average center of mass for the\n    specified molecules. If no molecule names are provided, it calculates the COM for all atoms in the file. This\n    can be useful for determining the central point of a group of molecules or the entire system for further\n    analysis or manipulation.\n\n    Parameters:\n        gro_file_path (str): The path to the input GRO file containing the molecular structure.\n        molecule_names (list[str]): A list of molecule names (residue names) for which to calculate the COM. If empty,\n                                    the COM of all atoms in the file is calculated.\n\n    Returns:\n        np.ndarray: A 1D numpy array containing the x, y, z coordinates of the average center of mass.\n\n    Raises:\n        ValueError: If no atoms are found for the specified molecule names in the GRO file.\n    \"\"\"\n    u = Universe(gro_file_path)\n    if not molecule_names:\n        molecule_atoms = u.atoms\n    else:\n        selection_str = \" or \".join([f\"resname {mol}\" for mol in molecule_names])\n        molecule_atoms = u.select_atoms(selection_str)\n\n    if len(molecule_atoms) &gt; 0:\n        return molecule_atoms.center_of_mass()\n    else:\n        raise ValueError(\n            f\"No atoms found for the types {molecule_names} in {gro_file_path}\"\n        )\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.convert_pdb_to_gro","title":"<code>convert_pdb_to_gro(pdb_file, output_gro, box_vector)</code>","text":"<p>Converts a PDB file to a GROMACS GRO file with specified box dimensions.</p> <p>This function utilizes MDAnalysis to load a PDB file, set the unit cell dimensions to the provided box vector, and then save the structure in GROMACS GRO format. This is useful for preparing molecular dynamics simulations where a specific box size is required.</p> <p>Parameters:</p> Name Type Description Default <code>pdb_file</code> <code>str</code> <p>The path to the input PDB file.</p> required <code>output_gro</code> <code>str</code> <p>The path where the output GRO file will be saved.</p> required <code>box_vector</code> <code>ndarray</code> <p>A 1D array containing the box dimensions (x, y, z, alpha, beta, gamma) in nanometers.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes the converted file to <code>output_gro</code>.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def convert_pdb_to_gro(pdb_file: str, output_gro: str, box_vector: np.ndarray) -&gt; None:\n    \"\"\"\n    Converts a PDB file to a GROMACS GRO file with specified box dimensions.\n\n    This function utilizes MDAnalysis to load a PDB file, set the unit cell dimensions to the provided box vector,\n    and then save the structure in GROMACS GRO format. This is useful for preparing molecular dynamics simulations\n    where a specific box size is required.\n\n    Parameters:\n        pdb_file (str): The path to the input PDB file.\n        output_gro (str): The path where the output GRO file will be saved.\n        box_vector (np.ndarray): A 1D array containing the box dimensions (x, y, z, alpha, beta, gamma) in nanometers.\n\n    Returns:\n        None: This function does not return a value but writes the converted file to `output_gro`.\n    \"\"\"\n    universe = Universe(pdb_file)\n    universe.dimensions = box_vector\n    universe.atoms.write(output_gro)\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.copy_files_to","title":"<code>copy_files_to(files, destination_dir)</code>","text":"<p>Copies a list of files to a specified destination directory.</p> <p>This function iterates over a list of file paths, copying each file to the destination directory specified. If a file already exists at the destination, a message is logged, and the file is not copied again to avoid overwriting. This is useful for organizing files or preparing directories with necessary files without manual copying.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>A list of file paths to be copied.</p> required <code>destination_dir</code> <code>str</code> <p>The directory path where the files should be copied to.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but copies files and logs actions.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def copy_files_to(files: list[str], destination_dir: str) -&gt; None:\n    \"\"\"\n    Copies a list of files to a specified destination directory.\n\n    This function iterates over a list of file paths, copying each file to the destination directory specified.\n    If a file already exists at the destination, a message is logged, and the file is not copied again to avoid\n    overwriting. This is useful for organizing files or preparing directories with necessary files without manual\n    copying.\n\n    Parameters:\n        files (list[str]): A list of file paths to be copied.\n        destination_dir (str): The directory path where the files should be copied to.\n\n    Returns:\n        None: This function does not return a value but copies files and logs actions.\n    \"\"\"\n    for file in files:\n        logger.info(f\"copying {file} to {destination_dir}\")\n        try:\n            shutil.copy(file, join(destination_dir, basename(file)))\n        except shutil.SameFileError:\n            logger.info(f\"file {file} already located at {destination_dir}\")\n            pass\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.generate_top_file_for_generic_molecule","title":"<code>generate_top_file_for_generic_molecule(molecule_name, force_field_filenames, top_filename, num_molecules=1)</code>","text":"<p>Generates a GROMACS topology file for a generic molecule.</p> <p>This function creates a topology file (.top) for a specified molecule using a list of force field filenames. It writes the necessary include statements for the force field files, defines the system, and specifies the number of molecules present. This is particularly useful for setting up molecular dynamics simulations where custom molecules or force fields are involved.</p> <p>Parameters:</p> Name Type Description Default <code>molecule_name</code> <code>str</code> <p>The name of the molecule for which the topology is being generated.</p> required <code>force_field_filenames</code> <code>list[str]</code> <p>A list of filenames for the force field files to be included in the topology.</p> required <code>top_filename</code> <code>str</code> <p>The path and filename where the topology file will be saved.</p> required <code>num_molecules</code> <code>int</code> <p>The number of molecules of this type present in the system. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes a .top file at the specified location.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def generate_top_file_for_generic_molecule(\n    molecule_name: str,\n    force_field_filenames: list[str],\n    top_filename: str,\n    num_molecules: int = 1,\n) -&gt; None:\n    \"\"\"\n    Generates a GROMACS topology file for a generic molecule.\n\n    This function creates a topology file (.top) for a specified molecule using a list of force field filenames.\n    It writes the necessary include statements for the force field files, defines the system, and specifies the\n    number of molecules present. This is particularly useful for setting up molecular dynamics simulations where\n    custom molecules or force fields are involved.\n\n    Parameters:\n        molecule_name (str): The name of the molecule for which the topology is being generated.\n        force_field_filenames (list[str]): A list of filenames for the force field files to be included in the topology.\n        top_filename (str): The path and filename where the topology file will be saved.\n        num_molecules (int, optional): The number of molecules of this type present in the system. Defaults to 1.\n\n    Returns:\n        None: This function does not return a value but writes a .top file at the specified location.\n    \"\"\"\n    with open(top_filename, \"w\") as f:\n        for ff_file in force_field_filenames:\n            f.write(f'#include \"{ff_file}\"\\n')\n\n        f.write(\"\\n\")\n        f.write(\"[ system ]\\n\")\n        f.write(f\"{molecule_name} system\\n\\n\")\n        f.write(\"[ molecules ]\\n\")\n        f.write(f\"{molecule_name:4s}            {num_molecules:5d}\\n\")\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.sub_template_mdp","title":"<code>sub_template_mdp(mdp_source, template, new_entry, mdp_dest)</code>","text":"<p>Substitutes a template placeholder in a GROMACS MDP file with a new entry.</p> <p>This function reads a GROMACS MDP (molecular dynamics parameters) file, searches for a specified template placeholder, and replaces it with a new entry. The modified MDP content is then written to a new destination file. This is useful for dynamically adjusting simulation parameters without manually editing MDP files.</p> <p>Parameters:</p> Name Type Description Default <code>mdp_source</code> <code>str</code> <p>The path to the source MDP file containing the template placeholder.</p> required <code>template</code> <code>str</code> <p>The template placeholder to be replaced. This should be a regex pattern.</p> required <code>new_entry</code> <code>str</code> <p>The new entry to replace the template placeholder with.</p> required <code>mdp_dest</code> <code>str</code> <p>The path where the modified MDP file will be saved.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes the modified MDP content to a new file.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def sub_template_mdp(\n    mdp_source: str, template: str, new_entry: str, mdp_dest: str\n) -&gt; None:\n    \"\"\"\n    Substitutes a template placeholder in a GROMACS MDP file with a new entry.\n\n    This function reads a GROMACS MDP (molecular dynamics parameters) file, searches for a specified template\n    placeholder, and replaces it with a new entry. The modified MDP content is then written to a new destination file.\n    This is useful for dynamically adjusting simulation parameters without manually editing MDP files.\n\n    Parameters:\n        mdp_source (str): The path to the source MDP file containing the template placeholder.\n        template (str): The template placeholder to be replaced. This should be a regex pattern.\n        new_entry (str): The new entry to replace the template placeholder with.\n        mdp_dest (str): The path where the modified MDP file will be saved.\n\n    Returns:\n        None: This function does not return a value but writes the modified MDP content to a new file.\n    \"\"\"\n    with open(mdp_source) as pipe:\n        mdp_content = pipe.read()\n    mdp_content = regex.sub(template, new_entry, mdp_content)\n    with open(mdp_dest, \"w\") as pipe:\n        pipe.write(mdp_content)\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.translate_gro_by_vector","title":"<code>translate_gro_by_vector(gro_file_path, output_gro_file_path, com_diff_vector)</code>","text":"<p>Translates the positions of all atoms in a GRO file by a specified vector and saves the result to a new file.</p> <p>This function loads a molecular structure from a GRO file, applies a translation to all atom positions by adding the specified center of mass difference vector, and then writes the modified structure to a new GRO file. This can be useful for adjusting the position of molecules within a simulation box, for example, to center a molecule or to move it to a specific location within the box.</p> <p>Parameters:</p> Name Type Description Default <code>gro_file_path</code> <code>str</code> <p>The path to the input GRO file containing the molecular structure to be translated.</p> required <code>output_gro_file_path</code> <code>str</code> <p>The path where the translated GRO file will be saved.</p> required <code>com_diff_vector</code> <code>ndarray</code> <p>A 1D numpy array containing the x, y, z components of the translation vector.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes the translated structure to <code>output_gro_file_path</code>.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def translate_gro_by_vector(\n    gro_file_path: str, output_gro_file_path: str, com_diff_vector: np.ndarray\n) -&gt; None:\n    \"\"\"\n    Translates the positions of all atoms in a GRO file by a specified vector and saves the result to a new file.\n\n    This function loads a molecular structure from a GRO file, applies a translation to all atom positions by adding\n    the specified center of mass difference vector, and then writes the modified structure to a new GRO file. This\n    can be useful for adjusting the position of molecules within a simulation box, for example, to center a molecule\n    or to move it to a specific location within the box.\n\n    Parameters:\n        gro_file_path (str): The path to the input GRO file containing the molecular structure to be translated.\n        output_gro_file_path (str): The path where the translated GRO file will be saved.\n        com_diff_vector (np.ndarray): A 1D numpy array containing the x, y, z components of the translation vector.\n\n    Returns:\n        None: This function does not return a value but writes the translated structure to `output_gro_file_path`.\n    \"\"\"\n    u = Universe(gro_file_path)\n    u.atoms.positions += com_diff_vector\n    u.atoms.write(output_gro_file_path)\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.update_nested_dict","title":"<code>update_nested_dict(d, u)</code>","text":"<p>Recursively updates a nested dictionary with another dictionary.</p> <p>This function takes two dictionaries, <code>d</code> and <code>u</code>. It iterates through <code>u</code>, updating <code>d</code> with <code>u</code>'s key-value pairs. If a value in <code>u</code> is a dictionary and the corresponding key exists in <code>d</code> with a dictionary as its value, this function recursively updates the nested dictionary. Otherwise, it directly updates the value. This is useful for merging configurations or settings where nested structures are involved without losing the nested specificity.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>The original dictionary to be updated.</p> required <code>u</code> <code>dict</code> <p>The dictionary with updates to apply to <code>d</code>.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The updated dictionary <code>d</code> after applying updates from <code>u</code>.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def update_nested_dict(d, u):\n    \"\"\"\n    Recursively updates a nested dictionary with another dictionary.\n\n    This function takes two dictionaries, `d` and `u`. It iterates through `u`, updating `d` with `u`'s key-value pairs.\n    If a value in `u` is a dictionary and the corresponding key exists in `d` with a dictionary as its value, this\n    function recursively updates the nested dictionary. Otherwise, it directly updates the value. This is useful for\n    merging configurations or settings where nested structures are involved without losing the nested specificity.\n\n    Parameters:\n        d (dict): The original dictionary to be updated.\n        u (dict): The dictionary with updates to apply to `d`.\n\n    Returns:\n        dict: The updated dictionary `d` after applying updates from `u`.\n    \"\"\"\n    for k, v in u.items():\n        if isinstance(v, Mapping):\n            d[k] = update_nested_dict(d.get(k, {}), v)\n        else:\n            d[k] = v\n    return d\n</code></pre>"},{"location":"utils/misc/#martignac.utils.misc.zip_directories","title":"<code>zip_directories(directory_names, output_file_name)</code>","text":"<p>Zips multiple directories into a single archive and moves it to a specified output path.</p> <p>This function takes a list of directory paths and an output file name, creates a ZIP archive of these directories, and then moves the archive to the current working directory or a specified directory. It excludes symlinks from the archive and ensures that the archive's internal structure reflects the relative paths of files to the directories being zipped. This is useful for bundling multiple directories into a single, compressed file for easy distribution or storage.</p> <p>Parameters:</p> Name Type Description Default <code>directory_names</code> <code>list</code> <p>A list of strings representing the paths to the directories to be zipped.</p> required <code>output_file_name</code> <code>str</code> <p>The name for the output ZIP file. The '.zip' extension is appended automatically.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The path to the final output ZIP file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>directory_names</code> list is empty.</p> Source code in <code>martignac/utils/misc.py</code> <pre><code>def zip_directories(directory_names: list, output_file_name: str) -&gt; str:\n    \"\"\"\n    Zips multiple directories into a single archive and moves it to a specified output path.\n\n    This function takes a list of directory paths and an output file name, creates a ZIP archive of these directories,\n    and then moves the archive to the current working directory or a specified directory. It excludes symlinks from\n    the archive and ensures that the archive's internal structure reflects the relative paths of files to the\n    directories being zipped. This is useful for bundling multiple directories into a single, compressed file for\n    easy distribution or storage.\n\n    Parameters:\n        directory_names (list): A list of strings representing the paths to the directories to be zipped.\n        output_file_name (str): The name for the output ZIP file. The '.zip' extension is appended automatically.\n\n    Returns:\n        str: The path to the final output ZIP file.\n\n    Raises:\n        ValueError: If the `directory_names` list is empty.\n    \"\"\"\n    if not directory_names:\n        raise ValueError(\"directory_names list cannot be empty\")\n\n    # Assume all directories are at the same parent level for the output path\n    parent_dir = abspath(join(directory_names[0], os.pardir))\n    intermediate_output_path = join(parent_dir, basename(output_file_name)) + \".zip\"\n\n    logger.info(f\"Zipping directories {directory_names} to {intermediate_output_path}\")\n\n    with ZipFile(intermediate_output_path, \"w\", ZIP_DEFLATED) as zipf:\n        for directory_name in directory_names:\n            for root, _, files in os.walk(directory_name):\n                for file in files:\n                    file_path = join(root, file)\n                    # Exclude symlinks\n                    if not islink(file_path):\n                        # Calculate archive name based on the file's relative path to the directory being zipped\n                        arcname = os.path.relpath(\n                            file_path, start=os.path.commonpath(directory_names)\n                        )\n                        zipf.write(file_path, arcname=arcname)\n\n    # The final output path could be in the same directory as the script or a specific directory\n    final_output_path = join(os.getcwd(), basename(output_file_name) + \".zip\")\n    os.rename(intermediate_output_path, final_output_path)\n\n    logger.info(f\"Moved archive to {final_output_path}\")\n    return final_output_path\n</code></pre>"},{"location":"utils/nomad/","title":"NOMAD","text":""},{"location":"utils/nomad/#martignac.utils.nomad.generate_user_metadata","title":"<code>generate_user_metadata(file_name, comment=None, references=None, coauthors=None, datasets=None)</code>","text":"<p>Generates a JSON file containing user metadata for a project.</p> <p>This function creates a JSON file with metadata information such as comments, references, coauthors, and datasets related to a project. It's useful for documenting project details, collaborations, and data sources.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the file where the metadata will be saved.</p> required <code>comment</code> <code>Optional[str]</code> <p>An optional comment or description about the project.</p> <code>None</code> <code>references</code> <code>list[str]</code> <p>An optional list of references or citations related to the project.</p> <code>None</code> <code>coauthors</code> <code>list[str]</code> <p>An optional list of coauthors involved in the project.</p> <code>None</code> <code>datasets</code> <code>list[str]</code> <p>An optional list of datasets used or generated during the project.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but writes the metadata to a file.</p> Source code in <code>martignac/utils/nomad.py</code> <pre><code>def generate_user_metadata(\n    file_name: str,\n    comment: Optional[str] = None,\n    references: Optional[list[str]] = None,\n    coauthors: Optional[list[str]] = None,\n    datasets: Optional[list[str]] = None,\n) -&gt; None:\n    \"\"\"\n    Generates a JSON file containing user metadata for a project.\n\n    This function creates a JSON file with metadata information such as comments, references, coauthors, and datasets\n    related to a project. It's useful for documenting project details, collaborations, and data sources.\n\n    Parameters:\n        file_name (str): The name of the file where the metadata will be saved.\n        comment (Optional[str]): An optional comment or description about the project.\n        references (list[str]): An optional list of references or citations related to the project.\n        coauthors (list[str]): An optional list of coauthors involved in the project.\n        datasets (list[str]): An optional list of datasets used or generated during the project.\n\n    Returns:\n        None: This function does not return a value but writes the metadata to a file.\n    \"\"\"\n    user_metadata = {\n        \"comment\": comment,\n        \"references\": references,\n        \"coauthors\": coauthors,\n        \"datasets\": datasets,\n    }\n    with open(file_name, \"w\") as f:\n        json.dump(user_metadata, f)\n</code></pre>"},{"location":"utils/packmol/","title":"PACKMOL","text":""},{"location":"utils/packmol/#martignac.utils.packmol.generate_solvent_with_packmol","title":"<code>generate_solvent_with_packmol(gro_solvent_mol, box_length, output_pdb, packmol_input_file='packmol.inp')</code>","text":"<p>Generates a solvent box with specified dimensions using PACKMOL.</p> <p>This function converts a GROMACS .gro file of a solvent molecule to a .pdb file, calculates the number of molecules needed to fill a box of the given volume, and generates a PACKMOL input file to create a solvent box. The function then returns the command to run PACKMOL with the generated input file.</p> <p>Parameters:</p> Name Type Description Default <code>gro_solvent_mol</code> <code>str</code> <p>Path to the .gro file of the solvent molecule.</p> required <code>box_length</code> <code>float</code> <p>Length of the cubic box in nm to be filled with solvent molecules.</p> required <code>output_pdb</code> <code>str</code> <p>Path where the output .pdb file containing the solvent box should be saved.</p> required <code>packmol_input_file</code> <code>str</code> <p>Path to the PACKMOL input file to be generated. Defaults to \"packmol.inp\".</p> <code>'packmol.inp'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to run PACKMOL with the generated input file.</p> Note <p>PACKMOL must be installed and accessible from the command line to execute the returned command successfully.</p> Source code in <code>martignac/utils/packmol.py</code> <pre><code>def generate_solvent_with_packmol(\n    gro_solvent_mol: str,\n    box_length: float,\n    output_pdb: str,\n    packmol_input_file: str = \"packmol.inp\",\n) -&gt; str:\n    \"\"\"\n    Generates a solvent box with specified dimensions using PACKMOL.\n\n    This function converts a GROMACS .gro file of a solvent molecule to a .pdb file, calculates the number of molecules\n    needed to fill a box of the given volume, and generates a PACKMOL input file to create a solvent box. The function\n    then returns the command to run PACKMOL with the generated input file.\n\n    Parameters:\n        gro_solvent_mol (str): Path to the .gro file of the solvent molecule.\n        box_length (float): Length of the cubic box in nm to be filled with solvent molecules.\n        output_pdb (str): Path where the output .pdb file containing the solvent box should be saved.\n        packmol_input_file (str, optional): Path to the PACKMOL input file to be generated. Defaults to \"packmol.inp\".\n\n    Returns:\n        str: The command to run PACKMOL with the generated input file.\n\n    Note:\n        PACKMOL must be installed and accessible from the command line to execute the returned command successfully.\n    \"\"\"\n    pdb_solvent_mol = f\"{gro_solvent_mol.rstrip('.gro')}.pdb\"\n    universe = Universe(gro_solvent_mol)\n    universe.atoms.write(pdb_solvent_mol)\n    length_in_a = box_length * 10.0\n    num_beads_per_mol = len(universe.residues[0].atoms)\n    volume_box = box_length**3\n    num_beads_in_box = int(volume_box / (num_beads_per_mol * VOLUME_PER_CG_BEAD_IN_NM3))\n    logger.info(f\"calling packmol to generate box with {num_beads_in_box} molecules\")\n    packmol_inp = f\"\"\"tolerance 2.0\nfiletype pdb\noutput {output_pdb}\n\nstructure {pdb_solvent_mol}\n  number {num_beads_in_box}\n  inside box 0. 0. 0. {length_in_a} {length_in_a} {length_in_a}\nend structure\n\"\"\"\n    with open(packmol_input_file, \"w\") as pipe:\n        pipe.write(packmol_inp)\n    return f\"packmol &lt; {packmol_input_file}\"\n</code></pre>"},{"location":"utils/packmol/#martignac.utils.packmol.place_solute_in_solvent_with_packmol","title":"<code>place_solute_in_solvent_with_packmol(gro_solute, gro_solvent, output_pdb, restraint_along_x=None, restraint_along_y=None, restraint_along_z=None, restraint_std_dev=1.0, packmol_input_file='packmol.inp')</code>","text":"<p>Places a solute molecule within a solvent box using PACKMOL with optional positional restraints.</p> <p>This function prepares a PACKMOL input file to place a solute molecule within a pre-existing solvent box, allowing for the specification of positional restraints along the x, y, and z axes. This can be particularly useful for simulations where the solute needs to be positioned at a specific location within the solvent box, such as near a surface or interface. The function returns the command to run PACKMOL with the generated input file.</p> <p>Parameters:</p> Name Type Description Default <code>gro_solute</code> <code>str</code> <p>Path to the .gro file of the solute molecule.</p> required <code>gro_solvent</code> <code>str</code> <p>Path to the .gro file of the solvent box.</p> required <code>output_pdb</code> <code>str</code> <p>Path where the output .pdb file, containing both solute and solvent, should be saved.</p> required <code>restraint_along_x</code> <code>Optional[float]</code> <p>Optional x-coordinate to restrain the solute molecule along the x-axis.</p> <code>None</code> <code>restraint_along_y</code> <code>Optional[float]</code> <p>Optional y-coordinate to restrain the solute molecule along the y-axis.</p> <code>None</code> <code>restraint_along_z</code> <code>Optional[float]</code> <p>Optional z-coordinate to restrain the solute molecule along the z-axis.</p> <code>None</code> <code>restraint_std_dev</code> <code>float</code> <p>Standard deviation for the positional restraint, defining the allowed fluctuation range.</p> <code>1.0</code> <code>packmol_input_file</code> <code>str</code> <p>Path to the PACKMOL input file to be generated. Defaults to \"packmol.inp\".</p> <code>'packmol.inp'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to run PACKMOL with the generated input file.</p> Note <p>PACKMOL must be installed and accessible from the command line to execute the returned command successfully.</p> Source code in <code>martignac/utils/packmol.py</code> <pre><code>def place_solute_in_solvent_with_packmol(\n    gro_solute: str,\n    gro_solvent: str,\n    output_pdb: str,\n    restraint_along_x: Optional[float] = None,\n    restraint_along_y: Optional[float] = None,\n    restraint_along_z: Optional[float] = None,\n    restraint_std_dev: float = 1.0,\n    packmol_input_file: str = \"packmol.inp\",\n) -&gt; str:\n    \"\"\"\n    Places a solute molecule within a solvent box using PACKMOL with optional positional restraints.\n\n    This function prepares a PACKMOL input file to place a solute molecule within a pre-existing solvent box,\n    allowing for the specification of positional restraints along the x, y, and z axes. This can be particularly\n    useful for simulations where the solute needs to be positioned at a specific location within the solvent box,\n    such as near a surface or interface. The function returns the command to run PACKMOL with the generated input file.\n\n    Parameters:\n        gro_solute (str): Path to the .gro file of the solute molecule.\n        gro_solvent (str): Path to the .gro file of the solvent box.\n        output_pdb (str): Path where the output .pdb file, containing both solute and solvent, should be saved.\n        restraint_along_x (Optional[float]): Optional x-coordinate to restrain the solute molecule along the x-axis.\n        restraint_along_y (Optional[float]): Optional y-coordinate to restrain the solute molecule along the y-axis.\n        restraint_along_z (Optional[float]): Optional z-coordinate to restrain the solute molecule along the z-axis.\n        restraint_std_dev (float): Standard deviation for the positional restraint, defining the allowed fluctuation range.\n        packmol_input_file (str): Path to the PACKMOL input file to be generated. Defaults to \"packmol.inp\".\n\n    Returns:\n        str: The command to run PACKMOL with the generated input file.\n\n    Note:\n        PACKMOL must be installed and accessible from the command line to execute the returned command successfully.\n    \"\"\"\n    logger.info(\"calling packmol to place solute in solvent\")\n    pdb_solute = f\"{gro_solute.rstrip('.gro')}.pdb\"\n    universe = Universe(gro_solute)\n    universe.atoms.write(pdb_solute)\n    pdb_solvent = f\"{gro_solvent.rstrip('.gro')}.pdb\"\n    universe = Universe(gro_solvent)\n    universe.atoms.write(pdb_solvent)\n    box_dimensions = universe.dimensions\n    logger.info(f\"box dimensions: {box_dimensions}\")\n    x_min, x_max = 0.0, box_dimensions[0]\n    if restraint_along_x is not None:\n        x_min = restraint_along_x - restraint_std_dev\n        x_max = restraint_along_x + restraint_std_dev\n    y_min, y_max = 0.0, box_dimensions[1]\n    if restraint_along_y is not None:\n        y_min = restraint_along_y - restraint_std_dev\n        y_max = restraint_along_y + restraint_std_dev\n    z_min, z_max = 0.0, box_dimensions[2]\n    if restraint_along_z is not None:\n        z_min = restraint_along_z - restraint_std_dev\n        z_max = restraint_along_z + restraint_std_dev\n    packmol_inp = f\"\"\"tolerance 2.0\n\nfiletype pdb\n\noutput {output_pdb}\n\nstructure {pdb_solvent}\n  number 1\n  fixed 0. 0. 0. 0. 0. 0.\nend structure\n\nstructure {pdb_solute}\n  number 1\n  inside box {x_min} {y_min} {z_min} {x_max} {y_max} {z_max}\nend structure\n\"\"\"\n    with open(packmol_input_file, \"w\") as pipe:\n        pipe.write(packmol_inp)\n    return f\"packmol &lt; {packmol_input_file}\"\n</code></pre>"},{"location":"workflows/bilayer_generation/","title":"Bilayer generation","text":""},{"location":"workflows/bilayer_generation/#martignac.workflows.bilayer_generation.BilayerGenFlow","title":"<code>BilayerGenFlow</code>","text":"<p>               Bases: <code>MartiniFlowProject</code></p> <p>A workflow for generating, minimizing, equilibrating, and sampling molecular dynamics simulations of lipid bilayers.</p> <p>This class extends <code>MartiniFlowProject</code> to provide a specialized workflow for the generation and analysis of lipid bilayer systems using the MARTINI force field. It includes operations for the initial generation of the bilayer, energy minimization, equilibration, and production phase sampling. The workflow is designed to be used with the GROMACS simulation package and utilizes various utilities for file manipulation and simulation setup.</p> <p>Attributes:</p> Name Type Description <code>workspace_path</code> <code>str</code> <p>The path to the workspace directory where simulation files are stored.</p> <code>mdp_path</code> <code>str</code> <p>The path to the directory containing MDP (Molecular Dynamics Parameters) files.</p> <code>itp_files</code> <code>dict</code> <p>A dictionary mapping from descriptive names to ITP (Include Topology) file paths.</p> <code>mdp_files</code> <code>dict</code> <p>A dictionary mapping from simulation stages to their corresponding MDP file paths.</p> <code>simulation_settings</code> <code>dict</code> <p>A dictionary containing simulation settings such as the number of threads,                         and box dimensions.</p> <code>solvent</code> <code>LiquidMixture</code> <p>An instance of <code>LiquidMixture</code> representing the solvent in the simulation.</p> <code>system_name</code> <code>str</code> <p>The name of the system being simulated.</p> <code>nomad_workflow</code> <code>str</code> <p>The name of the NOMAD workflow associated with this project.</p> <code>state_names</code> <code>dict</code> <p>A dictionary mapping from state descriptions to state names used in file naming.</p> <p>The workflow is configured through a YAML configuration file, which specifies paths, file names, and simulation parameters. This class provides methods to generate the initial bilayer structure, perform energy minimization, equilibrate the system, and carry out the production phase of the simulation. It also includes methods for integrating with the NOMAD database for data storage and retrieval.</p> Source code in <code>martignac/workflows/bilayer_generation.py</code> <pre><code>class BilayerGenFlow(MartiniFlowProject):\n    \"\"\"\n    A workflow for generating, minimizing, equilibrating, and sampling molecular dynamics simulations of lipid bilayers.\n\n    This class extends `MartiniFlowProject` to provide a specialized workflow for the generation and analysis of lipid\n    bilayer systems using the MARTINI force field. It includes operations for the initial generation of the bilayer,\n    energy minimization, equilibration, and production phase sampling. The workflow is designed to be used with the\n    GROMACS simulation package and utilizes various utilities for file manipulation and simulation setup.\n\n    Attributes:\n        workspace_path (str): The path to the workspace directory where simulation files are stored.\n        mdp_path (str): The path to the directory containing MDP (Molecular Dynamics Parameters) files.\n        itp_files (dict): A dictionary mapping from descriptive names to ITP (Include Topology) file paths.\n        mdp_files (dict): A dictionary mapping from simulation stages to their corresponding MDP file paths.\n        simulation_settings (dict): A dictionary containing simulation settings such as the number of threads,\n                                    and box dimensions.\n        solvent (LiquidMixture): An instance of `LiquidMixture` representing the solvent in the simulation.\n        system_name (str): The name of the system being simulated.\n        nomad_workflow (str): The name of the NOMAD workflow associated with this project.\n        state_names (dict): A dictionary mapping from state descriptions to state names used in file naming.\n\n    The workflow is configured through a YAML configuration file, which specifies paths, file names, and simulation\n    parameters. This class provides methods to generate the initial bilayer structure, perform energy minimization,\n    equilibrate the system, and carry out the production phase of the simulation. It also includes methods for\n    integrating with the NOMAD database for data storage and retrieval.\n    \"\"\"\n\n    workspace_path: str = (\n        f\"{MartiniFlowProject.workspaces_path}/{conf['relative_paths']['workspaces']}\"\n    )\n    mdp_path = (\n        f\"{MartiniFlowProject.input_files_path}/{conf['relative_paths']['mdp_files']}\"\n    )\n    itp_files = {k: v.get(str) for k, v in conf[\"itp_files\"].items()}\n    mdp_files = {k: v.get(str) for k, v in conf[\"mdp_files\"].items()}\n    simulation_settings = {\n        \"n_threads\": conf[\"settings\"][\"n_threads\"].get(int),\n        \"box_length_xy\": conf[\"settings\"][\"box_length_xy\"].get(float),\n        \"box_length_z\": conf[\"settings\"][\"box_length_z\"].get(float),\n    }\n    solvent: LiquidMixture = LiquidMixture.from_list_of_dicts(\n        [s.get(dict) for s in conf[\"settings\"][\"solvent\"]]\n    )\n    system_name = conf[\"output_names\"][\"system\"].get(str)\n    nomad_workflow: str = conf[\"output_names\"][\"nomad_workflow\"].get(str)\n    state_names = {k: v.get(str) for k, v in conf[\"output_names\"][\"states\"].items()}\n</code></pre>"},{"location":"workflows/bilayer_generation/#martignac.workflows.bilayer_generation.equilibrate","title":"<code>equilibrate(job)</code>","text":"<p>Equilibrates the minimized lipid bilayer structure for molecular dynamics simulations.</p> <p>This function prepares and executes the equilibration phase of the molecular dynamics simulation workflow, following the energy minimization step. It involves modifying the MDP (Molecular Dynamics Parameters) file to include specific lipid and solvent names, which are then used to run the equilibration simulation with GROMACS. The equilibration process allows the system to reach a stable state before proceeding to the production phase of the simulation.</p> <p>The MDP file for equilibration is customized based on the job's state point, which includes the lipid composition and solvent information. This customization ensures that the simulation parameters are correctly set for the specific bilayer system being simulated.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        information and provides context for the simulation, including paths to input and output files,        and the lipid and solvent composition.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the equilibration process, primarily for logging or debugging purposes.</p> Source code in <code>martignac/workflows/bilayer_generation.py</code> <pre><code>@BilayerGenFlow.pre(system_minimized, tag=\"system_minimized\")\n@BilayerGenFlow.post(system_equilibrated, tag=\"system_equilibrated\")\n@BilayerGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@BilayerGenFlow.operation(cmd=True, with_job=True)\ndef equilibrate(job):\n    \"\"\"\n    Equilibrates the minimized lipid bilayer structure for molecular dynamics simulations.\n\n    This function prepares and executes the equilibration phase of the molecular dynamics simulation workflow,\n    following the energy minimization step. It involves modifying the MDP (Molecular Dynamics Parameters) file\n    to include specific lipid and solvent names, which are then used to run the equilibration simulation with\n    GROMACS. The equilibration process allows the system to reach a stable state before proceeding to the production\n    phase of the simulation.\n\n    The MDP file for equilibration is customized based on the job's state point, which includes the lipid composition\n    and solvent information. This customization ensures that the simulation parameters are correctly set for the\n    specific bilayer system being simulated.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   information and provides context for the simulation, including paths to input and output files,\n                   and the lipid and solvent composition.\n\n    Returns:\n        str: The command executed for the equilibration process, primarily for logging or debugging purposes.\n    \"\"\"\n    mdp_file = BilayerGenFlow.mdp_files.get(\"equilibrate\")\n    return gromacs_simulation_command(\n        mdp=mdp_file,\n        top=BilayerGenFlow.get_state_name(extension=\"top\"),\n        gro=BilayerGenFlow.get_state_name(\"minimize\", \"gro\"),\n        name=BilayerGenFlow.get_state_name(\"equilibrate\"),\n        n_threads=BilayerGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/bilayer_generation/#martignac.workflows.bilayer_generation.generate_initial_bilayer","title":"<code>generate_initial_bilayer(job)</code>","text":"<p>Generates the initial structure of a lipid bilayer for molecular dynamics simulations.</p> <p>This function utilizes the INSANE (INsertion of Solutes At specified Norms and Extensions) tool to generate a lipid bilayer structure based on the specifications provided in the job's state point. The generated structure includes the specified lipid mixture and solvent, arranged according to the given box dimensions. The resulting structure is saved in a GRO file, and the topology of the bilayer is updated to reflect the composition of the generated system.</p> <p>The function updates the job's state point with the solvent information in a format compatible with INSANE, ensuring that the solvent is correctly represented in the generated bilayer structure.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        information specifying the lipid composition, solvent, and box dimensions for the bilayer        generation.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed to generate the bilayer with INSANE, primarily for logging or debugging purposes.</p> Source code in <code>martignac/workflows/bilayer_generation.py</code> <pre><code>@BilayerGenFlow.pre(fetched_from_nomad)\n@BilayerGenFlow.post(system_generated, tag=\"system_generated\")\n@BilayerGenFlow.operation_hooks.on_success(store_task)\n@BilayerGenFlow.operation(cmd=True, with_job=True)\ndef generate_initial_bilayer(job):\n    \"\"\"\n    Generates the initial structure of a lipid bilayer for molecular dynamics simulations.\n\n    This function utilizes the INSANE (INsertion of Solutes At specified Norms and Extensions) tool to generate\n    a lipid bilayer structure based on the specifications provided in the job's state point. The generated structure\n    includes the specified lipid mixture and solvent, arranged according to the given box dimensions. The resulting\n    structure is saved in a GRO file, and the topology of the bilayer is updated to reflect the composition of the\n    generated system.\n\n    The function updates the job's state point with the solvent information in a format compatible with INSANE,\n    ensuring that the solvent is correctly represented in the generated bilayer structure.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   information specifying the lipid composition, solvent, and box dimensions for the bilayer\n                   generation.\n\n    Returns:\n        str: The command executed to generate the bilayer with INSANE, primarily for logging or debugging purposes.\n    \"\"\"\n    lipid_mixture = LiquidMixture.from_list_of_dicts(job.sp.lipids)\n    return generate_bilayer_with_insane(\n        lipids=lipid_mixture,\n        solvent=BilayerGenFlow.solvent,\n        box_length_xy=BilayerGenFlow.simulation_settings.get(\"box_length_xy\"),\n        box_length_z=BilayerGenFlow.simulation_settings.get(\"box_length_z\"),\n        gro_bilayer_gen=BilayerGenFlow.get_state_name(\"generate\", \"gro\"),\n        top_bilayer=BilayerGenFlow.get_state_name(extension=\"top\"),\n    )\n</code></pre>"},{"location":"workflows/bilayer_generation/#martignac.workflows.bilayer_generation.minimize","title":"<code>minimize(_)</code>","text":"<p>Performs energy minimization on the initial lipid bilayer structure.</p> <p>This function is a critical step in the molecular dynamics simulation workflow, aiming to relax the system by minimizing its potential energy. This process helps in stabilizing the initial structure before proceeding to more computationally intensive equilibration and production phases. The function modifies the topology file to include necessary ITP (Include Topology) files, ensuring that all molecular interactions are correctly defined for the minimization process.</p> <p>The GROMACS simulation tool is invoked with parameters specified in the corresponding MDP (Molecular Dynamics Parameters) file for minimization. The output includes a minimized structure in GRO format and an updated topology file, both of which are essential for subsequent simulation steps.</p> <p>Parameters:</p> Name Type Description Default <code>_</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point      information and provides context for the simulation, including paths to input and output files.      The underscore is used to indicate that this parameter is not directly used within the function,      but is required for compatibility with the workflow's operation structure.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the energy minimization process, primarily for logging or debugging purposes.</p> Source code in <code>martignac/workflows/bilayer_generation.py</code> <pre><code>@BilayerGenFlow.pre(system_generated, tag=\"system_generated\")\n@BilayerGenFlow.post(system_minimized, tag=\"system_minimized\")\n@BilayerGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@BilayerGenFlow.operation(cmd=True, with_job=True)\ndef minimize(_):\n    \"\"\"\n    Performs energy minimization on the initial lipid bilayer structure.\n\n    This function is a critical step in the molecular dynamics simulation workflow, aiming to relax the system by\n    minimizing its potential energy. This process helps in stabilizing the initial structure before proceeding to\n    more computationally intensive equilibration and production phases. The function modifies the topology file to\n    include necessary ITP (Include Topology) files, ensuring that all molecular interactions are correctly defined\n    for the minimization process.\n\n    The GROMACS simulation tool is invoked with parameters specified in the corresponding MDP (Molecular Dynamics\n    Parameters) file for minimization. The output includes a minimized structure in GRO format and an updated topology\n    file, both of which are essential for subsequent simulation steps.\n\n    Args:\n        _ (Job): The job object associated with the current workflow operation. It contains the state point\n                 information and provides context for the simulation, including paths to input and output files.\n                 The underscore is used to indicate that this parameter is not directly used within the function,\n                 but is required for compatibility with the workflow's operation structure.\n\n    Returns:\n        str: The command executed for the energy minimization process, primarily for logging or debugging purposes.\n    \"\"\"\n    top = Topology.parse_top_file(BilayerGenFlow.get_state_name(extension=\"top\"))\n    top.includes = BilayerGenFlow.itp_files.values()\n    top.output_top(BilayerGenFlow.get_state_name(extension=\"top\"))\n    return gromacs_simulation_command(\n        mdp=BilayerGenFlow.mdp_files.get(\"minimize\"),\n        top=BilayerGenFlow.get_state_name(extension=\"top\"),\n        gro=BilayerGenFlow.get_state_name(\"generate\", \"gro\"),\n        name=BilayerGenFlow.get_state_name(\"minimize\"),\n        n_threads=BilayerGenFlow.simulation_settings.get(\"n_threads\"),\n        verbose=False,\n    )\n</code></pre>"},{"location":"workflows/bilayer_generation/#martignac.workflows.bilayer_generation.production","title":"<code>production(job)</code>","text":"<p>Executes the production phase of the molecular dynamics simulation for the lipid bilayer.</p> <p>This function is responsible for running the final, production phase of the molecular dynamics simulation workflow, following successful equilibration. It customizes the MDP (Molecular Dynamics Parameters) file for the production phase, incorporating specific lipid and solvent names. The simulation is executed using GROMACS, with the system now fully equilibrated and ready for detailed analysis and data collection.</p> <p>The MDP file for the production phase is tailored based on the job's state point, ensuring that simulation parameters are optimally set for the specific bilayer system under study. This phase is crucial for generating the simulation data that will be used for subsequent analysis and research findings.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        information and provides context for the simulation, including paths to input and output files,        and the lipid and solvent composition.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the production phase, primarily for logging or debugging purposes. This includes  the path to the modified MDP file, the output GRO file for the bilayer, and the updated topology file.</p> Source code in <code>martignac/workflows/bilayer_generation.py</code> <pre><code>@BilayerGenFlow.pre(system_equilibrated, tag=\"system_equilibrated\")\n@BilayerGenFlow.post(system_sampled, tag=\"system_sampled\")\n@BilayerGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@BilayerGenFlow.operation(cmd=True, with_job=True)\ndef production(job):\n    \"\"\"\n    Executes the production phase of the molecular dynamics simulation for the lipid bilayer.\n\n    This function is responsible for running the final, production phase of the molecular dynamics simulation\n    workflow, following successful equilibration. It customizes the MDP (Molecular Dynamics Parameters) file for\n    the production phase, incorporating specific lipid and solvent names. The simulation is executed using GROMACS,\n    with the system now fully equilibrated and ready for detailed analysis and data collection.\n\n    The MDP file for the production phase is tailored based on the job's state point, ensuring that simulation\n    parameters are optimally set for the specific bilayer system under study. This phase is crucial for generating\n    the simulation data that will be used for subsequent analysis and research findings.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   information and provides context for the simulation, including paths to input and output files,\n                   and the lipid and solvent composition.\n\n    Returns:\n        str: The command executed for the production phase, primarily for logging or debugging purposes. This includes\n             the path to the modified MDP file, the output GRO file for the bilayer, and the updated topology file.\n    \"\"\"\n    mdp_file = BilayerGenFlow.mdp_files.get(\"production\")\n    job.doc[project_name][\"bilayer_gro\"] = BilayerGenFlow.get_state_name(\n        \"production\", \"gro\"\n    )\n    job.doc[project_name][\"bilayer_top\"] = BilayerGenFlow.get_state_name(\n        extension=\"top\"\n    )\n    job.doc[project_name][\"lipid_names\"] = lipid_names(job)\n    return gromacs_simulation_command(\n        mdp=mdp_file,\n        top=BilayerGenFlow.get_state_name(extension=\"top\"),\n        gro=BilayerGenFlow.get_state_name(\"equilibrate\", \"gro\"),\n        name=BilayerGenFlow.get_state_name(\"production\"),\n        n_threads=BilayerGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_generation/","title":"Solute generation","text":""},{"location":"workflows/solute_generation/#martignac.workflows.solute_generation.SoluteGenFlow","title":"<code>SoluteGenFlow</code>","text":"<p>               Bases: <code>MartiniFlowProject</code></p> <p>Manages the workflow for generating, minimizing, and equilibrating solute systems for molecular dynamics simulations.</p> <p>This class extends <code>MartiniFlowProject</code> to provide specific functionalities for solute system preparation in the context of molecular dynamics simulations using GROMACS. It includes operations for generating the initial molecular structure, topology, and parameter files, minimizing the system's energy, and equilibrating the system under desired conditions.</p> <p>Attributes:</p> Name Type Description <code>workspace_path</code> <code>str</code> <p>Path to the workspace directory where simulation files are stored.</p> <code>mdp_path</code> <code>str</code> <p>Path to the directory containing MDP files for GROMACS simulations.</p> <code>itp_files</code> <code>dict</code> <p>Dictionary mapping solute names to their respective ITP file paths.</p> <code>mdp_files</code> <code>dict</code> <p>Dictionary mapping simulation types (e.g., 'minimize', 'equilibrate') to their MDP file paths.</p> <code>simulation_settings</code> <code>dict</code> <p>Settings for the simulation, such as the number of threads.</p> <code>system_name</code> <code>str</code> <p>The name of the system being simulated.</p> <code>nomad_workflow</code> <code>str</code> <p>The name of the NOMAD workflow associated with this project.</p> <code>state_names</code> <code>dict</code> <p>Dictionary mapping state names to their string representations.</p> <code>ff_parameters</code> <code>dict</code> <p>Force field parameters used in generating the molecular structure.</p> <p>The class provides methods for each step of the solute preparation process, including <code>build</code>, <code>minimize</code>, and <code>equilibrate</code>, as well as methods for managing the workflow's integration with the NOMAD database, such as <code>upload_to_nomad</code>.</p> Source code in <code>martignac/workflows/solute_generation.py</code> <pre><code>class SoluteGenFlow(MartiniFlowProject):\n    \"\"\"\n    Manages the workflow for generating, minimizing, and equilibrating solute systems for molecular dynamics simulations.\n\n    This class extends `MartiniFlowProject` to provide specific functionalities for solute system preparation in the\n    context of molecular dynamics simulations using GROMACS. It includes operations for generating the initial molecular\n    structure, topology, and parameter files, minimizing the system's energy, and equilibrating the system under desired\n    conditions.\n\n    Attributes:\n        workspace_path (str): Path to the workspace directory where simulation files are stored.\n        mdp_path (str): Path to the directory containing MDP files for GROMACS simulations.\n        itp_files (dict): Dictionary mapping solute names to their respective ITP file paths.\n        mdp_files (dict): Dictionary mapping simulation types (e.g., 'minimize', 'equilibrate') to their MDP file paths.\n        simulation_settings (dict): Settings for the simulation, such as the number of threads.\n        system_name (str): The name of the system being simulated.\n        nomad_workflow (str): The name of the NOMAD workflow associated with this project.\n        state_names (dict): Dictionary mapping state names to their string representations.\n        ff_parameters (dict): Force field parameters used in generating the molecular structure.\n\n    The class provides methods for each step of the solute preparation process, including `build`, `minimize`, and\n    `equilibrate`, as well as methods for managing the workflow's integration with the NOMAD database, such as\n    `upload_to_nomad`.\n    \"\"\"\n\n    workspace_path: str = (\n        f\"{MartiniFlowProject.workspaces_path}/{conf['relative_paths']['workspaces']}\"\n    )\n    mdp_path = (\n        f\"{MartiniFlowProject.input_files_path}/{conf['relative_paths']['mdp_files']}\"\n    )\n    itp_files = {k: v.get(str) for k, v in conf[\"itp_files\"].items()}\n    mdp_files = {k: v.get(str) for k, v in conf[\"mdp_files\"].items()}\n    simulation_settings = {\"n_threads\": conf[\"settings\"][\"n_threads\"].get(int)}\n    system_name = conf[\"output_names\"][\"system\"].get(str)\n    nomad_workflow: str = conf[\"output_names\"][\"nomad_workflow\"].get(str)\n    state_names = {k: v.get(str) for k, v in conf[\"output_names\"][\"states\"].items()}\n    ff_parameters = {\n        \"number_excl\": conf[\"parameters\"][\"number_excl\"].get(int),\n        \"bond_length\": conf[\"parameters\"][\"bond_length\"].get(float),\n        \"bond_constant\": conf[\"parameters\"][\"bond_constant\"].get(float),\n    }\n</code></pre>"},{"location":"workflows/solute_generation/#martignac.workflows.solute_generation.build","title":"<code>build(job)</code>","text":"<p>Generate the initial structure, topology, and parameter files for a solute.</p> <p>This function is responsible for generating the initial molecular structure (GRO file), topology (TOP file), and parameter (ITP file) files for the solute specified in the job. It utilizes the <code>get_molecule_from_name</code> function to fetch the molecular data based on the solute name provided in the job's state point. The generated files are essential for conducting molecular dynamics simulations using GROMACS.</p> <p>The function updates the job document with paths to the generated files, marking the solute's initial system generation as complete. This step is crucial for preparing the system for subsequent energy minimization, equilibration, and production simulations.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object representing the solute system for which the initial        structure, topology, and parameter files are to be generated.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but updates the job document with the   paths to the generated files.</p> Source code in <code>martignac/workflows/solute_generation.py</code> <pre><code>@SoluteGenFlow.pre(fetched_from_nomad)\n@SoluteGenFlow.post(system_generated, tag=\"system_generated\")\n@SoluteGenFlow.operation_hooks.on_success(store_task)\n@SoluteGenFlow.operation(with_job=True)\ndef build(job: Job) -&gt; None:\n    \"\"\"\n    Generate the initial structure, topology, and parameter files for a solute.\n\n    This function is responsible for generating the initial molecular structure (GRO file),\n    topology (TOP file), and parameter (ITP file) files for the solute specified in the job.\n    It utilizes the `get_molecule_from_name` function to fetch the molecular data based on the\n    solute name provided in the job's state point. The generated files are essential for\n    conducting molecular dynamics simulations using GROMACS.\n\n    The function updates the job document with paths to the generated files, marking the\n    solute's initial system generation as complete. This step is crucial for preparing the\n    system for subsequent energy minimization, equilibration, and production simulations.\n\n    Args:\n        job (Job): The job object representing the solute system for which the initial\n                   structure, topology, and parameter files are to be generated.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the\n              paths to the generated files.\n    \"\"\"\n    molecule = get_molecule_from_name(\n        job.sp.solute_name,\n        bond_length=SoluteGenFlow.ff_parameters[\"bond_length\"],\n        bond_constant=SoluteGenFlow.ff_parameters[\"bond_constant\"],\n        number_excl=SoluteGenFlow.ff_parameters[\"number_excl\"],\n    )\n    generate_gro_file_for_molecule(\n        molecule, SoluteGenFlow.get_state_name(\"generate\", \"gro\")\n    )\n    generate_itp_file_for_molecule(molecule, SoluteGenFlow.get_state_name(\"\", \"itp\"))\n    generate_top_file_for_molecule(\n        molecule,\n        [*SoluteGenFlow.itp_files.values(), SoluteGenFlow.get_state_name(\"\", \"itp\")],\n        SoluteGenFlow.get_state_name(\"\", \"top\"),\n    )\n    job.doc[project_name][\"solute_itp\"] = SoluteGenFlow.get_state_name(\"\", \"itp\")\n    job.doc[project_name][\"solute_top\"] = SoluteGenFlow.get_state_name(\"\", \"top\")\n    job.doc[project_name][\"solute_name\"] = molecule.name\n    job.doc[project_name][\"solute_has_charged_beads\"] = molecule.has_charged_beads\n    return None\n</code></pre>"},{"location":"workflows/solute_generation/#martignac.workflows.solute_generation.equilibrate","title":"<code>equilibrate(job)</code>","text":"<p>Perform the equilibration process for the solute in the simulation.</p> <p>This function runs the GROMACS equilibration simulation using the parameters defined in the <code>mdp_files[\"equilibrate\"]</code> file. It sets up the simulation with the minimized structure from the previous step as the input configuration and uses the topology file generated during the solute generation step. The number of threads for the simulation is determined by the <code>simulation_settings[\"n_threads\"]</code> configuration.</p> <p>The equilibration process is crucial for stabilizing the system at the desired temperature and pressure before the main production run. It helps in relaxing the system and achieving a more realistic distribution of velocities and positions.</p> <p>Upon successful completion, the function updates the job document with the path to the generated GRO file, marking the state of the system as equilibrated.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object for which the equilibration simulation is to be performed.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to execute the GROMACS equilibration simulation.</p> Source code in <code>martignac/workflows/solute_generation.py</code> <pre><code>@SoluteGenFlow.pre(system_minimized, tag=\"system_minimized\")\n@SoluteGenFlow.post(system_equilibrated, tag=\"system_equilibrated\")\n@SoluteGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SoluteGenFlow.operation(cmd=True, with_job=True)\ndef equilibrate(job: Job) -&gt; str:\n    \"\"\"\n    Perform the equilibration process for the solute in the simulation.\n\n    This function runs the GROMACS equilibration simulation using the parameters defined in the\n    `mdp_files[\"equilibrate\"]` file. It sets up the simulation with the minimized structure from the previous step as\n    the input configuration and uses the topology file generated during the solute generation step. The number of\n    threads for the simulation is determined by the `simulation_settings[\"n_threads\"]` configuration.\n\n    The equilibration process is crucial for stabilizing the system at the desired temperature and pressure before the\n    main production run. It helps in relaxing the system and achieving a more realistic distribution of velocities and\n    positions.\n\n    Upon successful completion, the function updates the job document with the path to the generated GRO file, marking\n    the state of the system as equilibrated.\n\n    Args:\n        job (Job): The job object for which the equilibration simulation is to be performed.\n\n    Returns:\n        str: The command to execute the GROMACS equilibration simulation.\n    \"\"\"\n    job.doc[project_name][\"solute_gro\"] = SoluteGenFlow.get_state_name(\n        \"equilibrate\", \"gro\"\n    )\n    return gromacs_simulation_command(\n        mdp=SoluteGenFlow.mdp_files[\"equilibrate\"],\n        top=SoluteGenFlow.get_state_name(\"\", \"top\"),\n        gro=SoluteGenFlow.get_state_name(\"minimize\", \"gro\"),\n        name=SoluteGenFlow.get_state_name(\"equilibrate\"),\n        n_threads=SoluteGenFlow.simulation_settings[\"n_threads\"],\n    )\n</code></pre>"},{"location":"workflows/solute_generation/#martignac.workflows.solute_generation.minimize","title":"<code>minimize(job)</code>","text":"<p>Minimize the energy of the solute system.</p> <p>This function executes the energy minimization step for the solute using GROMACS. It utilizes the parameters specified in the <code>mdp_files[\"minimize\"]</code> file for the minimization process. The minimized structure serves as a more stable starting point for subsequent equilibration and production simulations.</p> <p>The minimization process reduces the potential energy of the system, resolving any steric clashes or unrealistic geometries that may have arisen during the solute generation phase. This step is crucial for preparing the system for a stable simulation environment.</p> <p>Upon completion, the function updates the job document with the path to the minimized structure, indicating that the system has been successfully minimized.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object representing the solute system to be minimized.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The command to execute the GROMACS energy minimization.</p> Source code in <code>martignac/workflows/solute_generation.py</code> <pre><code>@SoluteGenFlow.pre(system_generated, tag=\"system_generated\")\n@SoluteGenFlow.post(system_minimized, tag=\"system_minimized\")\n@SoluteGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SoluteGenFlow.operation(cmd=True, with_job=True)\ndef minimize(job: Job) -&gt; str:\n    \"\"\"\n    Minimize the energy of the solute system.\n\n    This function executes the energy minimization step for the solute using GROMACS. It utilizes the parameters\n    specified in the `mdp_files[\"minimize\"]` file for the minimization process. The minimized structure serves as a\n    more stable starting point for subsequent equilibration and production simulations.\n\n    The minimization process reduces the potential energy of the system, resolving any steric clashes or unrealistic\n    geometries that may have arisen during the solute generation phase. This step is crucial for preparing the system\n    for a stable simulation environment.\n\n    Upon completion, the function updates the job document with the path to the minimized structure, indicating that\n    the system has been successfully minimized.\n\n    Args:\n        job (Job): The job object representing the solute system to be minimized.\n\n    Returns:\n        str: The command to execute the GROMACS energy minimization.\n    \"\"\"\n    return gromacs_simulation_command(\n        mdp=SoluteGenFlow.mdp_files[\"minimize\"],\n        top=SoluteGenFlow.get_state_name(\"\", \"top\"),\n        gro=SoluteGenFlow.get_state_name(\"generate\", \"gro\"),\n        name=SoluteGenFlow.get_state_name(\"minimize\"),\n        n_threads=SoluteGenFlow.simulation_settings[\"n_threads\"],\n    )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/","title":"Solute-in-bilayer umbrella sampling","text":""},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.SoluteInBilayerUmbrellaFlow","title":"<code>SoluteInBilayerUmbrellaFlow</code>","text":"<p>               Bases: <code>MartiniFlowProject</code></p> <p>Defines the workflow for simulating a solute within a lipid bilayer using umbrella sampling.</p> <p>This class extends the MartiniFlowProject, incorporating specific configurations and operations necessary for setting up, running, and analyzing molecular dynamics simulations of solutes in lipid bilayers. It includes methods for generating the solute and bilayer, translating the solute to the desired depth within the bilayer, and performing umbrella sampling simulations to calculate the potential of mean force (PMF) across different bilayer depths.</p> <p>Attributes:</p> Name Type Description <code>workspace_path</code> <code>str</code> <p>Path to the workspace directory for this project.</p> <code>itp_files</code> <code>dict</code> <p>Dictionary mapping solute and lipid component names to their respective ITP file paths.</p> <code>mdp_path</code> <code>str</code> <p>Path to the directory containing MDP files for GROMACS simulations.</p> <code>mdp_files</code> <code>dict</code> <p>Dictionary mapping simulation types (e.g., 'minimize', 'equilibrate') to their MDP file paths.</p> <code>simulation_settings</code> <code>dict</code> <p>General settings for the simulation, such as the number of threads.</p> <code>system_name</code> <code>str</code> <p>Name of the system being simulated.</p> <code>nomad_workflow</code> <code>str</code> <p>Name of the workflow file for NOMAD integration.</p> <code>nomad_top_level_workflow</code> <code>str</code> <p>Name of the top-level workflow file for NOMAD integration.</p> <code>state_names</code> <code>dict</code> <p>Dictionary mapping state names (e.g., 'generated', 'minimized') to their string representations.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>class SoluteInBilayerUmbrellaFlow(MartiniFlowProject):\n    \"\"\"\n    Defines the workflow for simulating a solute within a lipid bilayer using umbrella sampling.\n\n    This class extends the MartiniFlowProject, incorporating specific configurations and operations\n    necessary for setting up, running, and analyzing molecular dynamics simulations of solutes in\n    lipid bilayers. It includes methods for generating the solute and bilayer, translating the solute\n    to the desired depth within the bilayer, and performing umbrella sampling simulations to calculate\n    the potential of mean force (PMF) across different bilayer depths.\n\n    Attributes:\n        workspace_path (str): Path to the workspace directory for this project.\n        itp_files (dict): Dictionary mapping solute and lipid component names to their respective ITP file paths.\n        mdp_path (str): Path to the directory containing MDP files for GROMACS simulations.\n        mdp_files (dict): Dictionary mapping simulation types (e.g., 'minimize', 'equilibrate') to their MDP file paths.\n        simulation_settings (dict): General settings for the simulation, such as the number of threads.\n        system_name (str): Name of the system being simulated.\n        nomad_workflow (str): Name of the workflow file for NOMAD integration.\n        nomad_top_level_workflow (str): Name of the top-level workflow file for NOMAD integration.\n        state_names (dict): Dictionary mapping state names (e.g., 'generated', 'minimized') to their string representations.\n    \"\"\"\n\n    workspace_path: str = (\n        f\"{MartiniFlowProject.workspaces_path}/{conf['relative_paths']['workspaces']}\"\n    )\n    itp_files = {k: v.get(str) for k, v in conf[\"itp_files\"].items()}\n    mdp_path = (\n        f\"{MartiniFlowProject.input_files_path}/{conf['relative_paths']['mdp_files']}\"\n    )\n    mdp_files = {k: v.get(str) for k, v in conf[\"mdp_files\"].items()}\n    simulation_settings = {\"n_threads\": conf[\"settings\"][\"n_threads\"].get(int)}\n    system_name = conf[\"output_names\"][\"system\"].get(str)\n    nomad_workflow: str = conf[\"output_names\"][\"nomad_workflow\"].get(str)\n    nomad_top_level_workflow: str = conf[\"output_names\"][\n        \"nomad_top_level_workflow\"\n    ].get(str)\n    state_names = {k: v.get(str) for k, v in conf[\"output_names\"][\"states\"].items()}\n\n    @classmethod\n    def get_system_run_name(cls, depth_state: str) -&gt; str:\n        return SoluteInBilayerUmbrellaFlow.get_state_name(\n            state_name=f\"production-{depth_state}\"\n        )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.analyze_wham","title":"<code>analyze_wham(*jobs)</code>","text":"<p>Analyzes the WHAM (Weighted Histogram Analysis Method) results to calculate free energy profiles.</p> <p>This function processes the output from the WHAM analysis, converting the XVG files generated by GROMACS WHAM tool into numpy arrays for easier analysis and visualization. It focuses on the lowest depth job as a representative for the analysis, assuming that the WHAM analysis has been completed and the relevant XVG files are available.</p> <p>The function reads the WHAM profile, histogram, and bootstrap files, converting each into a numpy array. These arrays are then saved to the job's filesystem for future use. Additionally, the job document is updated with the paths to these numpy arrays, facilitating access to the analysis results.</p> <p>Parameters:</p> Name Type Description Default <code>*jobs</code> <p>A variable number of Job objects, each representing a simulation at a specific depth within the    bilayer. These jobs should have completed the WHAM analysis phase and contain the necessary files    for free energy calculation.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document and saves numpy arrays of the   WHAM analysis results to the job's filesystem.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(wham_calculated, tag=\"wham_calculated\")\n@SoluteInBilayerUmbrellaFlow.post(free_energy_calculated, tag=\"free_energy_calculated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_task_for_many_jobs)\n@SoluteInBilayerUmbrellaFlow.operation(\n    aggregator=aggregator(\n        aggregator_function=solute_in_bilayer_aggregator,\n        sort_by=\"depth_from_bilayer_core\",\n    )\n)\ndef analyze_wham(*jobs):\n    \"\"\"\n    Analyzes the WHAM (Weighted Histogram Analysis Method) results to calculate free energy profiles.\n\n    This function processes the output from the WHAM analysis, converting the XVG files generated by GROMACS WHAM tool\n    into numpy arrays for easier analysis and visualization. It focuses on the lowest depth job as a representative\n    for the analysis, assuming that the WHAM analysis has been completed and the relevant XVG files are available.\n\n    The function reads the WHAM profile, histogram, and bootstrap files, converting each into a numpy array. These\n    arrays are then saved to the job's filesystem for future use. Additionally, the job document is updated with\n    the paths to these numpy arrays, facilitating access to the analysis results.\n\n    Args:\n        *jobs: A variable number of Job objects, each representing a simulation at a specific depth within the\n               bilayer. These jobs should have completed the WHAM analysis phase and contain the necessary files\n               for free energy calculation.\n\n    Returns:\n        None: This function does not return a value but updates the job document and saves numpy arrays of the\n              WHAM analysis results to the job's filesystem.\n    \"\"\"\n    for job in jobs:\n        wham_job = lowest_depth_job(jobs)\n        if job == wham_job:\n            xvg_profile = gromacs.fileformats.XVG(job.fn(wham_profile_xvg))\n            np.save(job.fn(wham_profile), xvg_profile.array)\n            xvg_hist = gromacs.fileformats.XVG(job.fn(wham_hist_xvg))\n            np.save(job.fn(wham_hist), xvg_hist.array)\n            xvg_bstrap = gromacs.fileformats.XVG(job.fn(wham_bstrap_xvg))\n            np.save(job.fn(wham_bstrap), xvg_bstrap.array)\n        job.doc = update_nested_dict(\n            job.doc,\n            {\n                project_name: {\n                    \"free_energy\": {\n                        \"job_id\": wham_job.id,\n                        \"profile\": wham_profile,\n                        \"hist\": wham_hist,\n                        \"bootstrap\": wham_bstrap,\n                    }\n                }\n            },\n        )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.compute_wham","title":"<code>compute_wham(*jobs)</code>","text":"<p>Calculates the Weighted Histogram Analysis Method (WHAM) for a set of jobs.</p> <p>This function is responsible for computing the potential of mean force (PMF) across different bilayer depths using the WHAM. It aggregates the pull force and TPR files from all jobs, generates summary files for these, and then runs the GROMACS WHAM tool. The WHAM analysis is crucial for understanding the free energy landscape of the solute across the bilayer, providing insights into its stability and behavior at various depths.</p> <p>The function first identifies the job with the lowest depth (as a representative job) to perform the WHAM calculation. It then generates summary files listing all the pull force and TPR files from the jobs. These summary files are used as input for the GROMACS WHAM tool, which calculates the PMF and generates several output files, including the PMF profile and histograms.</p> <p>Parameters:</p> Name Type Description Default <code>*jobs</code> <p>A variable number of Job objects, each representing a simulation at a specific depth within the    bilayer. These jobs should have completed the production phase of the simulation and contain the    necessary files for WHAM analysis.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the WHAM analysis, primarily for logging or debugging purposes. This is  the command that invokes the GROMACS WHAM tool with the appropriate parameters and input files.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(all_depth_states_sampled, tag=\"system_sampled\")\n@SoluteInBilayerUmbrellaFlow.post(wham_calculated, tag=\"wham_calculated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_task_for_many_jobs)\n@SoluteInBilayerUmbrellaFlow.operation(\n    aggregator=aggregator(\n        aggregator_function=solute_in_bilayer_aggregator,\n        sort_by=\"depth_from_bilayer_core\",\n    ),\n    cmd=True,\n)\ndef compute_wham(*jobs):\n    \"\"\"\n    Calculates the Weighted Histogram Analysis Method (WHAM) for a set of jobs.\n\n    This function is responsible for computing the potential of mean force (PMF) across different bilayer depths\n    using the WHAM. It aggregates the pull force and TPR files from all jobs, generates summary files for these,\n    and then runs the GROMACS WHAM tool. The WHAM analysis is crucial for understanding the free energy landscape\n    of the solute across the bilayer, providing insights into its stability and behavior at various depths.\n\n    The function first identifies the job with the lowest depth (as a representative job) to perform the WHAM\n    calculation. It then generates summary files listing all the pull force and TPR files from the jobs. These\n    summary files are used as input for the GROMACS WHAM tool, which calculates the PMF and generates several\n    output files, including the PMF profile and histograms.\n\n    Args:\n        *jobs: A variable number of Job objects, each representing a simulation at a specific depth within the\n               bilayer. These jobs should have completed the production phase of the simulation and contain the\n               necessary files for WHAM analysis.\n\n    Returns:\n        str: The command executed for the WHAM analysis, primarily for logging or debugging purposes. This is\n             the command that invokes the GROMACS WHAM tool with the appropriate parameters and input files.\n    \"\"\"\n    logger.info(\"calculation of potential of mean force\")\n    xvg_files = [job.fn(job.doc[project_name][\"umbrella_pullf_xvg\"]) for job in jobs]\n    tpr_files = [job.fn(job.doc[project_name][\"tpr_file\"]) for job in jobs]\n\n    def generate_summary_file(output_filename: str, list_of_files: list[str]) -&gt; None:\n        with open(output_filename, \"w\") as file:\n            for fil in list_of_files:\n                file.write(f\"{fil}\\n\")\n\n    for job in jobs:\n        if job == lowest_depth_job(jobs):\n            with job:\n                generate_summary_file(wham_tpr_summary, tpr_files)\n                generate_summary_file(wham_xvg_summary, xvg_files)\n                return run_gmx_wham(\n                    job.fn(wham_tpr_summary),\n                    job.fn(wham_xvg_summary),\n                    job.fn(wham_profile_xvg),\n                    job.fn(wham_hist_xvg),\n                    job.fn(wham_bstrap_xvg),\n                    job.fn(wham_bsprof_xvg),\n                    z_min=lowest_depth_job(jobs).sp.depth_from_bilayer_core,\n                    z_max=highest_depth_job(jobs).sp.depth_from_bilayer_core,\n                )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.convert_box_to_gro","title":"<code>convert_box_to_gro(job)</code>","text":"<p>Converts the simulation box from PDB to GRO format after solute insertion.</p> <p>This operation is essential for preparing the simulation system in a format compatible with GROMACS simulations. It uses the MDAnalysis package to load the current state of the simulation box in PDB format, extracts the box dimensions, and then converts it to GRO format. The GRO format is required for subsequent simulation steps, including minimization, equilibration, and production runs in the GROMACS molecular dynamics package.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the path to the generated GRO file.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the path to the converted   GRO file, marking the box conversion step as complete.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(generated_box_pdb, tag=\"generated_box_pdb\")\n@SoluteInBilayerUmbrellaFlow.post(system_generated, tag=\"system_generated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_task)\n@SoluteInBilayerUmbrellaFlow.operation(with_job=True)\ndef convert_box_to_gro(job: Job):\n    \"\"\"\n    Converts the simulation box from PDB to GRO format after solute insertion.\n\n    This operation is essential for preparing the simulation system in a format compatible with GROMACS simulations.\n    It uses the MDAnalysis package to load the current state of the simulation box in PDB format, extracts the box\n    dimensions, and then converts it to GRO format. The GRO format is required for subsequent simulation steps,\n    including minimization, equilibration, and production runs in the GROMACS molecular dynamics package.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the path to the generated GRO file.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the path to the converted\n              GRO file, marking the box conversion step as complete.\n    \"\"\"\n    universe = Universe(job.doc[bilayer_gen_name][\"bilayer_gro\"])\n    box_dimensions = universe.dimensions\n    convert_pdb_to_gro(\n        SoluteInBilayerUmbrellaFlow.get_state_name(\"generate\", \"pdb\"),\n        SoluteInBilayerUmbrellaFlow.get_state_name(\"generate\", \"gro\"),\n        box_dimensions,\n    )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.equilibrate","title":"<code>equilibrate(job)</code>","text":"<p>Prepares and executes the equilibration step of the molecular dynamics simulation.</p> <p>This function is responsible for equilibrating the system after the minimization step, ensuring that the system reaches a stable state before proceeding to the production phase of the simulation. It dynamically generates an MDP file tailored to the specific depth state of the solute within the bilayer, incorporating the solute name and the first lipid name from the job's state point information into the MDP file. This customization allows for precise control over the equilibration conditions based on the system's configuration.</p> <p>The equilibration process uses GROMACS for simulation, with parameters specified in the dynamically generated MDP file. The function constructs and executes the GROMACS command for equilibration, using the topology file and the GRO file generated from the minimization step as inputs.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the results of the equilibration step.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the equilibration process, primarily for logging or debugging purposes.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(system_minimized, tag=\"system_minimized\")\n@SoluteInBilayerUmbrellaFlow.post(system_equilibrated, tag=\"system_equilibrated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(\n    store_gromacs_log_to_doc_with_depth_from_bilayer_core\n)\n@SoluteInBilayerUmbrellaFlow.operation(cmd=True, with_job=True)\ndef equilibrate(job):\n    \"\"\"\n    Prepares and executes the equilibration step of the molecular dynamics simulation.\n\n    This function is responsible for equilibrating the system after the minimization step, ensuring that the system\n    reaches a stable state before proceeding to the production phase of the simulation. It dynamically generates an\n    MDP file tailored to the specific depth state of the solute within the bilayer, incorporating the solute name and\n    the first lipid name from the job's state point information into the MDP file. This customization allows for\n    precise control over the equilibration conditions based on the system's configuration.\n\n    The equilibration process uses GROMACS for simulation, with parameters specified in the dynamically generated MDP\n    file. The function constructs and executes the GROMACS command for equilibration, using the topology file and the\n    GRO file generated from the minimization step as inputs.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the results of the equilibration step.\n\n    Returns:\n        str: The command executed for the equilibration process, primarily for logging or debugging purposes.\n    \"\"\"\n    depth_state = str(job.sp.depth_from_bilayer_core)\n    depth_mdp = f\"{SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state)}.mdp\"\n    sub_template_mdp(\n        SoluteInBilayerUmbrellaFlow.mdp_files.get(\"equilibrate\"),\n        \"sedstate\",\n        depth_state,\n        depth_mdp,\n    )\n    sub_template_mdp(\n        depth_mdp, \"sedmolecule\", job.doc[solute_gen_name].get(\"solute_name\"), depth_mdp\n    )\n    lipids = \" \".join(lipid_names(job))\n    sub_template_mdp(depth_mdp, \"sedlipid\", lipids, depth_mdp)\n    return gromacs_simulation_command(\n        mdp=depth_mdp,\n        top=SoluteInBilayerUmbrellaFlow.get_state_name(extension=\"top\"),\n        gro=SoluteInBilayerUmbrellaFlow.get_state_name(\"minimize\", \"gro\"),\n        name=SoluteInBilayerUmbrellaFlow.get_state_name(\"equilibrate\"),\n        n_threads=SoluteInBilayerUmbrellaFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.generate_bilayer","title":"<code>generate_bilayer(*jobs)</code>","text":"<p>Generates the lipid bilayer structure for the molecular dynamics simulation.</p> <p>This operation is a critical part of the SoluteInBilayerUmbrellaFlow workflow, focusing on the simulation of a solute within a lipid bilayer using umbrella sampling. It imports the bilayer's GRO and TOP files from a bilayer generation project into the current job's document. This step is essential for preparing the bilayer structure for subsequent operations, such as solute insertion, solvation, and the execution of molecular dynamics simulations.</p> <p>The function leverages the <code>import_job_from_other_flow</code> utility to facilitate the transfer of the necessary files from the bilayer generation project to the current project. It updates the job document with the paths to these files and sets the operation's name in the project's operation to workflow mapping, aiding in the tracking and management of the workflow's progress.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the        state point and document for the job, which will be updated with the bilayer        generation results.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the paths to   the bilayer's GRO and TOP files, marking the bilayer generation step as complete.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(fetched_from_nomad)\n@SoluteInBilayerUmbrellaFlow.post(bilayer_generated_all, tag=\"bilayer_generated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_workflow_for_many_jobs)\n@SoluteInBilayerUmbrellaFlow.operation(\n    aggregator=aggregator(aggregator_function=solute_in_bilayer_aggregator)\n)\ndef generate_bilayer(*jobs):\n    \"\"\"\n    Generates the lipid bilayer structure for the molecular dynamics simulation.\n\n    This operation is a critical part of the SoluteInBilayerUmbrellaFlow workflow, focusing on the\n    simulation of a solute within a lipid bilayer using umbrella sampling. It imports the bilayer's\n    GRO and TOP files from a bilayer generation project into the current job's document. This step\n    is essential for preparing the bilayer structure for subsequent operations, such as solute\n    insertion, solvation, and the execution of molecular dynamics simulations.\n\n    The function leverages the `import_job_from_other_flow` utility to facilitate the transfer of\n    the necessary files from the bilayer generation project to the current project. It updates the\n    job document with the paths to these files and sets the operation's name in the project's\n    operation to workflow mapping, aiding in the tracking and management of the workflow's progress.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the\n                   state point and document for the job, which will be updated with the bilayer\n                   generation results.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the paths to\n              the bilayer's GRO and TOP files, marking the bilayer generation step as complete.\n    \"\"\"\n    job = lowest_depth_job(jobs)\n    with job:\n        solvent_job: Job = get_solvent_job(job)\n        keys_for_files_to_copy = [\"bilayer_gro\", \"bilayer_top\"]\n        project.operation_to_workflow[func_name()] = bilayer_gen_name\n        import_job_from_other_flow(\n            job, bilayer_gen_project, solvent_job, keys_for_files_to_copy\n        )\n        lipid_names = job.doc[bilayer_gen_name].get(\"lipid_names\")\n        com_bilayer = calculate_average_com(\n            job.doc[bilayer_gen_name].get(\"bilayer_gro\"), lipid_names\n        )\n        logger.info(f\"bilayer COM: {com_bilayer}\")\n        job.doc[project_name][\"bilayer_z_mean\"] = com_bilayer[2]\n\n    for other_job in [j for j in jobs if j != job]:\n        with other_job:\n            logger.info(f\"Importing data to job {other_job.id}\")\n            import_job_from_other_flow(\n                other_job,\n                bilayer_gen_project,\n                solvent_job,\n                keys_for_files_to_copy,\n                run_child_job=False,\n            )\n            other_job.doc[project_name][\"bilayer_z_mean\"] = com_bilayer[2]\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.generate_solute","title":"<code>generate_solute(*jobs)</code>","text":"<p>Generates the solute for the molecular dynamics simulation within a lipid bilayer.</p> <p>This operation is part of the SoluteInBilayerUmbrellaFlow workflow, which simulates a solute within a lipid bilayer using umbrella sampling. It imports the solute's GRO, TOP, and ITP files from a solute generation project into the current job's document. This step is crucial for preparing the solute for subsequent operations, such as translation to the desired depth within the bilayer and solvation.</p> <p>The function utilizes the <code>import_job_from_other_flow</code> utility to facilitate the copying of the necessary files from the solute generation project to the current project. It updates the job document with the paths to these files and sets the operation's name in the project's operation to workflow mapping, aiding in the tracking and management of the workflow's progress.</p> <p>Parameters:</p> Name Type Description Default <code>*jobs</code> <code>Job</code> <p>A variable number of Job objects, representing different simulation setups or conditions.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the paths to the solute's   GRO, TOP, and ITP files, marking the solute generation step as complete.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(fetched_from_nomad)\n@SoluteInBilayerUmbrellaFlow.post(solute_generated_all, tag=\"solute_generated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_workflow_for_many_jobs)\n@SoluteInBilayerUmbrellaFlow.operation(\n    aggregator=aggregator(aggregator_function=solute_in_bilayer_aggregator)\n)\ndef generate_solute(*jobs):\n    \"\"\"\n    Generates the solute for the molecular dynamics simulation within a lipid bilayer.\n\n    This operation is part of the SoluteInBilayerUmbrellaFlow workflow, which simulates a solute\n    within a lipid bilayer using umbrella sampling. It imports the solute's GRO, TOP, and ITP files\n    from a solute generation project into the current job's document. This step is crucial for\n    preparing the solute for subsequent operations, such as translation to the desired depth within\n    the bilayer and solvation.\n\n    The function utilizes the `import_job_from_other_flow` utility to facilitate the copying of the\n    necessary files from the solute generation project to the current project. It updates the job\n    document with the paths to these files and sets the operation's name in the project's operation\n    to workflow mapping, aiding in the tracking and management of the workflow's progress.\n\n    Args:\n        *jobs (Job): A variable number of Job objects, representing different simulation setups or conditions.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the paths to the solute's\n              GRO, TOP, and ITP files, marking the solute generation step as complete.\n    \"\"\"\n    job = lowest_depth_job(jobs)\n    with job:\n        logger.info(f\"Generating solute for {job.id} @ SoluteInBilayerUmbrellaFlow\")\n        solute_job: Job = get_solute_job(job)\n        keys_for_files_to_copy = [\"solute_gro\", \"solute_top\", \"solute_itp\"]\n        project.operation_to_workflow[func_name()] = solute_gen_name\n        import_job_from_other_flow(\n            job, solute_gen_project, solute_job, keys_for_files_to_copy\n        )\n\n    for other_job in [j for j in jobs if j != job]:\n        with other_job:\n            logger.info(f\"Importing data to job {other_job.id}\")\n            import_job_from_other_flow(\n                other_job,\n                solute_gen_project,\n                solute_job,\n                keys_for_files_to_copy,\n                run_child_job=False,\n            )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.insert_solute_in_box","title":"<code>insert_solute_in_box(job)</code>","text":"<p>Inserts the solute into the simulation box with the lipid bilayer.</p> <p>This operation positions the solute within the lipid bilayer at a specified depth, using the Packmol tool to ensure the solute is correctly placed within the solvent environment. The depth is adjusted based on the job's state point information, specifically the 'depth_from_bilayer_core' parameter. The resulting structure is saved in a PDB file, which is later converted to GRO format for GROMACS simulations.</p> <p>The function calculates the restraint position along the z-axis for the solute, ensuring it is placed at the correct depth within the bilayer. This is crucial for simulating the interaction of the solute with the lipid bilayer at specific locations.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the path to the generated PDB file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command to execute Packmol with the specified parameters, placing the solute in the solvent  environment at the correct depth.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(solute_translated, tag=\"solute_translated\")\n@SoluteInBilayerUmbrellaFlow.pre(bilayer_generated, tag=\"bilayer_generated\")\n@SoluteInBilayerUmbrellaFlow.post(generated_box_pdb, tag=\"generated_box_pdb\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_task)\n@SoluteInBilayerUmbrellaFlow.operation(cmd=True, with_job=True)\ndef insert_solute_in_box(job):\n    \"\"\"\n    Inserts the solute into the simulation box with the lipid bilayer.\n\n    This operation positions the solute within the lipid bilayer at a specified depth, using the Packmol tool to\n    ensure the solute is correctly placed within the solvent environment. The depth is adjusted based on the\n    job's state point information, specifically the 'depth_from_bilayer_core' parameter. The resulting structure\n    is saved in a PDB file, which is later converted to GRO format for GROMACS simulations.\n\n    The function calculates the restraint position along the z-axis for the solute, ensuring it is placed at the\n    correct depth within the bilayer. This is crucial for simulating the interaction of the solute with the lipid\n    bilayer at specific locations.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the path to the generated PDB file.\n\n    Returns:\n        str: The command to execute Packmol with the specified parameters, placing the solute in the solvent\n             environment at the correct depth.\n    \"\"\"\n    return place_solute_in_solvent_with_packmol(\n        gro_solute=job.doc[project_name][\"solute_translated_gro\"],\n        gro_solvent=job.doc[bilayer_gen_name][\"bilayer_gro\"],\n        output_pdb=SoluteInBilayerUmbrellaFlow.get_state_name(\"generate\", \"pdb\"),\n        restraint_along_z=job.doc[project_name].get(\"bilayer_z_mean\")\n        + job.sp.depth_from_bilayer_core * 10.0,\n    )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.minimize","title":"<code>minimize(job)</code>","text":"<p>Executes the minimization step for the molecular dynamics simulation.</p> <p>This function prepares and runs the energy minimization step using GROMACS, which is essential for stabilizing the molecular system before further simulation steps. It utilizes the minimization parameters defined in the MDP file specified for the minimization process. The function constructs and executes the GROMACS command for energy minimization, ensuring the system is in a low-energy state and free of steric clashes or inappropriate geometries that could lead to simulation instabilities.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the results of the minimization step.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the minimization process, primarily for logging or debugging purposes.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(topology_updated, tag=\"topology_updated\")\n@SoluteInBilayerUmbrellaFlow.post(system_minimized, tag=\"system_minimized\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(\n    store_gromacs_log_to_doc_with_depth_from_bilayer_core\n)\n@SoluteInBilayerUmbrellaFlow.operation(cmd=True, with_job=True)\ndef minimize(job: Job):\n    \"\"\"\n    Executes the minimization step for the molecular dynamics simulation.\n\n    This function prepares and runs the energy minimization step using GROMACS, which is essential for stabilizing\n    the molecular system before further simulation steps. It utilizes the minimization parameters defined in the\n    MDP file specified for the minimization process. The function constructs and executes the GROMACS command for\n    energy minimization, ensuring the system is in a low-energy state and free of steric clashes or inappropriate\n    geometries that could lead to simulation instabilities.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the results of the minimization step.\n\n    Returns:\n        str: The command executed for the minimization process, primarily for logging or debugging purposes.\n    \"\"\"\n    return gromacs_simulation_command(\n        mdp=SoluteInBilayerUmbrellaFlow.mdp_files.get(\"minimize\"),\n        top=SoluteInBilayerUmbrellaFlow.get_state_name(extension=\"top\"),\n        gro=SoluteInBilayerUmbrellaFlow.get_state_name(\"generate\", \"gro\"),\n        name=SoluteInBilayerUmbrellaFlow.get_state_name(\"minimize\"),\n        n_threads=SoluteInBilayerUmbrellaFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.production","title":"<code>production(job)</code>","text":"<p>Executes the production phase of the molecular dynamics simulation.</p> <p>This function is responsible for running the production phase of the simulation, where the actual data collection occurs. It dynamically generates an MDP file tailored to the specific depth state of the solute within the bilayer, incorporating the solute name and the first lipid name from the job's state point information into the MDP file. This customization allows for precise control over the simulation conditions based on the system's configuration.</p> <p>The production process uses GROMACS for simulation, with parameters specified in the dynamically generated MDP file. The function constructs and executes the GROMACS command for the production run, using the topology file and the GRO file generated from the equilibration step as inputs. Additionally, it prepares files for umbrella sampling analysis by specifying output filenames for pull force and pull coordinate data, as well as the TPR and log files for the run.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the results of the production step and        the paths to the generated output files for umbrella sampling analysis.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the production process, primarily for logging or debugging purposes.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(system_equilibrated, tag=\"system_equilibrated\")\n@SoluteInBilayerUmbrellaFlow.post(bilayer_depth_sampled, tag=\"system_sampled\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(\n    store_gromacs_log_to_doc_with_depth_from_bilayer_core\n)\n@SoluteInBilayerUmbrellaFlow.operation(cmd=True, with_job=True)\ndef production(job):\n    \"\"\"\n    Executes the production phase of the molecular dynamics simulation.\n\n    This function is responsible for running the production phase of the simulation, where the actual data collection\n    occurs. It dynamically generates an MDP file tailored to the specific depth state of the solute within the bilayer,\n    incorporating the solute name and the first lipid name from the job's state point information into the MDP file.\n    This customization allows for precise control over the simulation conditions based on the system's configuration.\n\n    The production process uses GROMACS for simulation, with parameters specified in the dynamically generated MDP\n    file. The function constructs and executes the GROMACS command for the production run, using the topology file and\n    the GRO file generated from the equilibration step as inputs. Additionally, it prepares files for umbrella sampling\n    analysis by specifying output filenames for pull force and pull coordinate data, as well as the TPR and log files\n    for the run.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the results of the production step and\n                   the paths to the generated output files for umbrella sampling analysis.\n\n    Returns:\n        str: The command executed for the production process, primarily for logging or debugging purposes.\n    \"\"\"\n    depth_state = str(job.sp.depth_from_bilayer_core)\n    depth_mdp = f\"{SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state)}.mdp\"\n    sub_template_mdp(\n        SoluteInBilayerUmbrellaFlow.mdp_files.get(\"production\"),\n        \"sedstate\",\n        depth_state,\n        depth_mdp,\n    )\n    sub_template_mdp(\n        depth_mdp, \"sedmolecule\", job.doc[solute_gen_name].get(\"solute_name\"), depth_mdp\n    )\n    lipids = \" \".join(lipid_names(job))\n    sub_template_mdp(depth_mdp, \"sedlipid\", lipids, depth_mdp)\n    job.doc[project_name][\n        \"umbrella_pullf_xvg\"\n    ] = f\"{SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state)}_pullf.xvg\"\n    job.doc[project_name][\n        \"umbrella_pullx_xvg\"\n    ] = f\"{SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state)}_pullx.xvg\"\n    job.doc[project_name][\n        \"tpr_file\"\n    ] = f\"{SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state)}.tpr\"\n    job.doc[project_name][\n        \"umbrella_log\"\n    ] = f\"{SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state)}.log\"\n    return gromacs_simulation_command(\n        mdp=depth_mdp,\n        top=SoluteInBilayerUmbrellaFlow.get_state_name(extension=\"top\"),\n        gro=SoluteInBilayerUmbrellaFlow.get_state_name(\"equilibrate\", \"gro\"),\n        name=SoluteInBilayerUmbrellaFlow.get_system_run_name(depth_state),\n        n_threads=SoluteInBilayerUmbrellaFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.translate_solute","title":"<code>translate_solute(*jobs)</code>","text":"<p>Translates the solute to the center of mass (COM) of the bilayer.</p> <p>This operation is crucial for positioning the solute at the correct depth within the lipid bilayer, ensuring that the simulation reflects the intended physical scenario. It calculates the COM of the bilayer and the solute separately, then translates the solute's position to align its COM with that of the bilayer. The translation vector is determined by the difference in the COMs of the solute and the bilayer, effectively centering the solute within the bilayer along the z-axis. The translated coordinates are saved in a new GRO file.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the path to the translated solute GRO file.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the path to the translated   solute GRO file, marking the solute translation step as complete.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(solute_generated_all, tag=\"solute_generated\")\n@SoluteInBilayerUmbrellaFlow.post(solute_translated_all, tag=\"solute_translated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_workflow_for_many_jobs)\n@SoluteInBilayerUmbrellaFlow.operation(\n    aggregator=aggregator(aggregator_function=solute_in_bilayer_aggregator)\n)\ndef translate_solute(*jobs):\n    \"\"\"\n    Translates the solute to the center of mass (COM) of the bilayer.\n\n    This operation is crucial for positioning the solute at the correct depth within the lipid bilayer,\n    ensuring that the simulation reflects the intended physical scenario. It calculates the COM of the bilayer\n    and the solute separately, then translates the solute's position to align its COM with that of the bilayer.\n    The translation vector is determined by the difference in the COMs of the solute and the bilayer, effectively\n    centering the solute within the bilayer along the z-axis. The translated coordinates are saved in a new GRO file.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the path to the translated solute GRO file.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the path to the translated\n              solute GRO file, marking the solute translation step as complete.\n    \"\"\"\n    job = lowest_depth_job(jobs)\n    with job:\n        solute_gro = job.doc[solute_gen_name].get(\"solute_gro\")\n        solute_translated_gro = SoluteInBilayerUmbrellaFlow.get_state_name(\n            \"solute_translated\", \"gro\"\n        )\n        job.doc[project_name][\"solute_translated_gro\"] = solute_translated_gro\n        com_solute = calculate_average_com(solute_gro, [])\n        logger.debug(f\"solute COM: {com_solute}\")\n        diff_solute_com = -com_solute\n        logger.info(f\"Translating the solute COM by {diff_solute_com}\")\n        translate_gro_by_vector(solute_gro, solute_translated_gro, diff_solute_com)\n        project.operation_to_workflow[func_name()] = project_name\n\n    for other_job in [j for j in jobs if j != job]:\n        with other_job:\n            other_job.doc[project_name][\"solute_translated_gro\"] = solute_translated_gro\n            translate_gro_by_vector(solute_gro, solute_translated_gro, diff_solute_com)\n</code></pre>"},{"location":"workflows/solute_in_bilayer_umbrella/#martignac.workflows.solute_in_bilayer_umbrella.update_topology_file","title":"<code>update_topology_file(job)</code>","text":"<p>Updates the topology file by combining the solute and bilayer topology files.</p> <p>This operation is crucial for preparing the simulation system for GROMACS simulations. It combines the topology files of the solute and the bilayer into a single topology file that includes both components. This combined topology file is necessary for running simulations that involve both the solute and the bilayer, ensuring that the interactions between them are accurately represented.</p> <p>The function first gathers the paths to the solute and bilayer topology files from the job document. It then uses the <code>combine_multiple_topology_files</code> utility to merge these files into a single topology file. The combined topology file is then updated to ensure that the molecule counts match the actual system composition as defined by the GRO file generated in previous steps. Finally, the path to the combined topology file is stored in the job document for use in subsequent simulation steps.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the path to the combined topology file.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the path to the combined   topology file, marking the topology update step as complete.</p> Source code in <code>martignac/workflows/solute_in_bilayer_umbrella.py</code> <pre><code>@SoluteInBilayerUmbrellaFlow.pre(system_generated, tag=\"system_generated\")\n@SoluteInBilayerUmbrellaFlow.post(topology_updated, tag=\"topology_updated\")\n@SoluteInBilayerUmbrellaFlow.operation_hooks.on_success(store_task)\n@SoluteInBilayerUmbrellaFlow.operation(with_job=True)\ndef update_topology_file(job: Job):\n    \"\"\"\n    Updates the topology file by combining the solute and bilayer topology files.\n\n    This operation is crucial for preparing the simulation system for GROMACS simulations. It combines the topology\n    files of the solute and the bilayer into a single topology file that includes both components. This combined\n    topology file is necessary for running simulations that involve both the solute and the bilayer, ensuring that\n    the interactions between them are accurately represented.\n\n    The function first gathers the paths to the solute and bilayer topology files from the job document. It then\n    uses the `combine_multiple_topology_files` utility to merge these files into a single topology file. The combined\n    topology file is then updated to ensure that the molecule counts match the actual system composition as defined\n    by the GRO file generated in previous steps. Finally, the path to the combined topology file is stored in the\n    job document for use in subsequent simulation steps.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the path to the combined topology file.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the path to the combined\n              topology file, marking the topology update step as complete.\n    \"\"\"\n    comb_topology = combine_multiple_topology_files(\n        [\n            job.doc[bilayer_gen_name][\"bilayer_top\"],\n            job.doc[solute_gen_name][\"solute_top\"],\n        ],\n        \"solute in bilayer\",\n    )\n    top_file_name = SoluteInBilayerUmbrellaFlow.get_state_name(extension=\"top\")\n    job.doc[project_name][\"solute_bilayer_top\"] = top_file_name\n    comb_topology.update_counts_against_gro(\n        SoluteInBilayerUmbrellaFlow.get_state_name(\"generate\", \"gro\")\n    )\n    comb_topology.output_top(top_file_name)\n</code></pre>"},{"location":"workflows/solute_in_solvent_alchemical/","title":"Solute-in-solvent alchemical transformation","text":""},{"location":"workflows/solute_in_solvent_alchemical/#martignac.workflows.solute_in_solvent_alchemical.SoluteInSolventAlchemicalFlow","title":"<code>SoluteInSolventAlchemicalFlow</code>","text":"<p>               Bases: <code>MartiniFlowProject</code></p> <p>Defines the workflow for alchemical transformations of solutes in solvents within the Martini force field framework.</p> <p>This class extends the MartiniFlowProject, incorporating specific configurations and operations for conducting alchemical transformations. Alchemical transformations involve gradually changing the Hamiltonian of the system to transform a solute into another or modify its interactions with the solvent, which is a common technique in free energy calculations.</p> <p>Attributes:</p> Name Type Description <code>workspace_path</code> <code>str</code> <p>The path to the workspace directory where the project's files are stored.</p> <code>mdp_path</code> <code>str</code> <p>The path to the directory containing the MDP (Molecular Dynamics Parameters) files.</p> <code>itp_files</code> <code>dict</code> <p>A dictionary mapping the names of ITP (Include Topology) files to their paths.</p> <code>mdp_files</code> <code>dict</code> <p>A dictionary mapping the names of MDP files to their paths.</p> <code>simulation_settings</code> <code>dict</code> <p>A dictionary containing simulation settings such as the number of threads and temperature.</p> <code>system_name</code> <code>str</code> <p>The name of the system being simulated.</p> <code>nomad_workflow</code> <code>str</code> <p>The name of the workflow file for integration with the NOMAD framework.</p> <code>nomad_top_level_workflow</code> <code>str</code> <p>The name of the top-level workflow file for NOMAD.</p> <code>state_names</code> <code>dict</code> <p>A dictionary mapping state names to their string representations.</p> <p>The class provides methods for preparing the system, running production simulations, computing free energies, and generating and uploading workflows to NOMAD, facilitating an automated and scalable approach to molecular simulations.</p> Source code in <code>martignac/workflows/solute_in_solvent_alchemical.py</code> <pre><code>class SoluteInSolventAlchemicalFlow(MartiniFlowProject):\n    \"\"\"\n    Defines the workflow for alchemical transformations of solutes in solvents within the Martini force field framework.\n\n    This class extends the MartiniFlowProject, incorporating specific configurations and operations for conducting\n    alchemical transformations. Alchemical transformations involve gradually changing the Hamiltonian of the system\n    to transform a solute into another or modify its interactions with the solvent, which is a common technique in\n    free energy calculations.\n\n    Attributes:\n        workspace_path (str): The path to the workspace directory where the project's files are stored.\n        mdp_path (str): The path to the directory containing the MDP (Molecular Dynamics Parameters) files.\n        itp_files (dict): A dictionary mapping the names of ITP (Include Topology) files to their paths.\n        mdp_files (dict): A dictionary mapping the names of MDP files to their paths.\n        simulation_settings (dict): A dictionary containing simulation settings such as the number of threads and temperature.\n        system_name (str): The name of the system being simulated.\n        nomad_workflow (str): The name of the workflow file for integration with the NOMAD framework.\n        nomad_top_level_workflow (str): The name of the top-level workflow file for NOMAD.\n        state_names (dict): A dictionary mapping state names to their string representations.\n\n    The class provides methods for preparing the system, running production simulations, computing free energies,\n    and generating and uploading workflows to NOMAD, facilitating an automated and scalable approach to molecular\n    simulations.\n    \"\"\"\n\n    workspace_path: str = (\n        f\"{MartiniFlowProject.workspaces_path}/{conf['relative_paths']['workspaces']}\"\n    )\n    mdp_path = (\n        f\"{MartiniFlowProject.input_files_path}/{conf['relative_paths']['mdp_files']}\"\n    )\n    itp_files = {k: v.get(str) for k, v in conf[\"itp_files\"].items()}\n    mdp_files = {k: v.get(str) for k, v in conf[\"mdp_files\"].items()}\n    simulation_settings = {\n        \"n_threads\": conf[\"settings\"][\"n_threads\"].get(int),\n        \"temperature\": conf[\"settings\"][\"temperature\"].get(float),\n    }\n    system_name = conf[\"output_names\"][\"system\"].get(str)\n    nomad_workflow: str = conf[\"output_names\"][\"nomad_workflow\"].get(str)\n    nomad_top_level_workflow: str = conf[\"output_names\"][\n        \"nomad_top_level_workflow\"\n    ].get(str)\n    state_names = {k: v.get(str) for k, v in conf[\"output_names\"][\"states\"].items()}\n\n    @classmethod\n    def get_system_run_name(cls, lambda_state: str) -&gt; str:\n        return SoluteInSolventAlchemicalFlow.get_state_name(\n            state_name=f\"production-{lambda_state}\"\n        )\n</code></pre>"},{"location":"workflows/solute_in_solvent_alchemical/#martignac.workflows.solute_in_solvent_alchemical.compute_free_energy","title":"<code>compute_free_energy(*jobs)</code>","text":"<p>Computes the free energy difference for alchemical transformations using the MBAR method.</p> <p>This function aggregates the simulation data from multiple jobs, each representing a different lambda state in the alchemical transformation process. It uses the alchemlyb library's MBAR estimator to calculate the free energy difference between the initial and final states of the transformation. The results, including the mean free energy difference and its standard deviation, are stored in the job document for each job.</p> <p>The function assumes that the necessary simulation data (XVG files) are already generated and stored by the production phase of the workflow. It leverages the extract_u_nk function from alchemlyb to parse these files and extract the reduced potential energies, which are then combined and passed to the MBAR estimator.</p> <p>Parameters:</p> Name Type Description Default <code>*jobs</code> <code>Job</code> <p>A variable number of job objects, each representing a distinct lambda state in the alchemical          transformation process. These jobs should have already completed the production phase, with XVG          files available for analysis.</p> <code>()</code> Note <p>This function is part of the SoluteInSolventAlchemicalFlow project and is designed to be used within a signac-flow workflow. It relies on specific project and job structure defined in the MartiniFlowProject class and its derivatives.</p> Source code in <code>martignac/workflows/solute_in_solvent_alchemical.py</code> <pre><code>@SoluteInSolventAlchemicalFlow.pre(all_lambda_states_sampled, tag=\"lambda_sampled\")\n@SoluteInSolventAlchemicalFlow.post(free_energy_already_calculated, tag=\"mbar\")\n@SoluteInSolventAlchemicalFlow.operation_hooks.on_success(store_task_for_many_jobs)\n@SoluteInSolventAlchemicalFlow.operation(\n    aggregator=aggregator(\n        aggregator_function=solvent_and_solute_aggregator, sort_by=\"lambda_state\"\n    )\n)\ndef compute_free_energy(*jobs):\n    \"\"\"\n    Computes the free energy difference for alchemical transformations using the MBAR method.\n\n    This function aggregates the simulation data from multiple jobs, each representing a different lambda state in\n    the alchemical transformation process. It uses the alchemlyb library's MBAR estimator to calculate the free energy\n    difference between the initial and final states of the transformation. The results, including the mean free energy\n    difference and its standard deviation, are stored in the job document for each job.\n\n    The function assumes that the necessary simulation data (XVG files) are already generated and stored by the\n    production phase of the workflow. It leverages the extract_u_nk function from alchemlyb to parse these files and\n    extract the reduced potential energies, which are then combined and passed to the MBAR estimator.\n\n    Args:\n        *jobs (Job): A variable number of job objects, each representing a distinct lambda state in the alchemical\n                     transformation process. These jobs should have already completed the production phase, with XVG\n                     files available for analysis.\n\n    Note:\n        This function is part of the SoluteInSolventAlchemicalFlow project and is designed to be used within a\n        signac-flow workflow. It relies on specific project and job structure defined in the MartiniFlowProject class\n        and its derivatives.\n    \"\"\"\n    logger.info(\"calculating free energies using pyMBAR\")\n    xvg_files = [job.fn(job.doc[project_name][\"alchemical_xvg\"]) for job in jobs]\n    u_nk_list = [\n        extract_u_nk(\n            f, T=SoluteInSolventAlchemicalFlow.simulation_settings.get(\"temperature\")\n        )\n        for f in xvg_files\n    ]\n    u_nk_combined = pd.concat(u_nk_list)\n    mbar = MBAR().fit(u_nk_combined)\n    free_energy = float(mbar.delta_f_.iloc[0, -1])\n    d_free_energy = float(mbar.d_delta_f_.iloc[0, -1])\n    solvent_name, solute_name = job_system_keys(jobs[0])\n    logger.info(\n        f\"free energy {solvent_name}_{solute_name}: {free_energy:+6.2f} +/- {d_free_energy:5.2f} kT\"\n    )\n    for job in jobs:\n        job.doc = update_nested_dict(\n            job.doc,\n            {\n                project_name: {\n                    \"free_energy\": {\"mean\": free_energy, \"std\": d_free_energy}\n                }\n            },\n        )\n</code></pre>"},{"location":"workflows/solute_in_solvent_alchemical/#martignac.workflows.solute_in_solvent_alchemical.prepare_system","title":"<code>prepare_system(*jobs)</code>","text":"<p>Prepares the system for alchemical transformation simulations by importing necessary data from related projects.</p> <p>This function is a critical part of the workflow in the SoluteInSolventAlchemicalFlow project. It ensures that all necessary input files and configurations are correctly set up for each job involved in the alchemical transformation process. The function performs several key operations:</p> <ol> <li>Identifies the job with the lowest lambda state to serve as the primary job for data import.</li> <li>Imports solute-related input files from the SoluteGenFlow project into the primary job.</li> <li>Imports solvent-related input files from the SolventGenFlow project into the primary job.</li> <li>Imports solvation-related input files from the SoluteInSolventGenFlow project into the primary job.</li> <li>Replicates the imported data across all other jobs involved in the transformation process.</li> <li>Updates the job document to mark the system as prepared for each job.</li> </ol> <p>The function leverages the <code>import_job_from_other_flow</code> utility to facilitate the import of data between different projects, ensuring that all necessary files are available for the simulation to proceed.</p> <p>Parameters:</p> Name Type Description Default <code>*jobs</code> <code>Job</code> <p>A variable number of job objects, each representing a distinct simulation job within the          alchemical transformation workflow.</p> <code>()</code> Source code in <code>martignac/workflows/solute_in_solvent_alchemical.py</code> <pre><code>@SoluteInSolventAlchemicalFlow.pre(fetched_from_nomad)\n@SoluteInSolventAlchemicalFlow.post(all_jobs_prepared, tag=\"system_prepared\")\n@SoluteInSolventAlchemicalFlow.operation_hooks.on_success(store_workflow_for_many_jobs)\n@SoluteInSolventAlchemicalFlow.operation(\n    aggregator=aggregator(aggregator_function=solvent_and_solute_aggregator)\n)\ndef prepare_system(*jobs):\n    \"\"\"\n    Prepares the system for alchemical transformation simulations by importing necessary data from related projects.\n\n    This function is a critical part of the workflow in the SoluteInSolventAlchemicalFlow project. It ensures that\n    all necessary input files and configurations are correctly set up for each job involved in the alchemical\n    transformation process. The function performs several key operations:\n\n    1. Identifies the job with the lowest lambda state to serve as the primary job for data import.\n    2. Imports solute-related input files from the SoluteGenFlow project into the primary job.\n    3. Imports solvent-related input files from the SolventGenFlow project into the primary job.\n    4. Imports solvation-related input files from the SoluteInSolventGenFlow project into the primary job.\n    5. Replicates the imported data across all other jobs involved in the transformation process.\n    6. Updates the job document to mark the system as prepared for each job.\n\n    The function leverages the `import_job_from_other_flow` utility to facilitate the import of data between\n    different projects, ensuring that all necessary files are available for the simulation to proceed.\n\n    Args:\n        *jobs (Job): A variable number of job objects, each representing a distinct simulation job within the\n                     alchemical transformation workflow.\n\n    \"\"\"\n    job = lowest_lambda_job(jobs)\n    logger.info(f\"Preparing system for {job.id} @ AlchemicalTransformationFlow\")\n    solute_job: Job = get_solute_job(job)\n    solute_keys = [\"solute_itp\"]\n    import_job_from_other_flow(job, solute_gen_project, solute_job, solute_keys)\n    solvent_job: Job = get_solvent_job(job)\n    import_job_from_other_flow(job, solvent_gen_project, solvent_job, [])\n    solvation_job: Job = get_solvation_job(job)\n    solvation_keys = [\"solute_solvent_gro\", \"solute_solvent_top\"]\n    project.operation_to_workflow[func_name()] = solute_solvation_project.class_name()\n    import_job_from_other_flow(\n        job, solute_solvation_project, solvation_job, solvation_keys\n    )\n    num_lambda_points = get_num_lambda_points(jobs)\n\n    for other_job in [j for j in jobs if j != job]:\n        logger.info(\n            f\"Importing data to job {other_job.id} @ AlchemicalTransformationFlow\"\n        )\n        import_job_from_other_flow(\n            other_job, solute_gen_project, solute_job, solute_keys, run_child_job=False\n        )\n        import_job_from_other_flow(\n            other_job, solvent_gen_project, solvent_job, [], run_child_job=False\n        )\n        import_job_from_other_flow(\n            other_job,\n            solute_solvation_project,\n            solvation_job,\n            solvation_keys,\n            run_child_job=False,\n        )\n\n    for job in jobs:\n        job.doc = update_nested_dict(job.doc, {project_name: {\"system_prepared\": True}})\n        job.doc[project_name][\"num_lambda_points\"] = num_lambda_points\n</code></pre>"},{"location":"workflows/solute_in_solvent_alchemical/#martignac.workflows.solute_in_solvent_alchemical.production","title":"<code>production(job)</code>","text":"<p>Executes the production phase of the molecular dynamics simulation for a given job.</p> <p>This function configures and runs the production phase of the alchemical transformation simulation. It involves setting up the Molecular Dynamics Parameters (MDP) file specific to the lambda state of the job, customizing it for the solute involved, and executing the GROMACS simulation. The function generates and stores the paths to the output XVG and log files in the job document for later analysis.</p> <p>The MDP file is first templated with the lambda state and solute name, then used to run the simulation with the specified number of threads. This phase is critical for generating the data necessary for free energy calculation.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object representing a single simulation job within the alchemical transformation workflow.        It contains the state point information, including the lambda state and solute name, and provides        context for the simulation, including paths to input and output files.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command executed for the production phase, primarily for logging or debugging purposes. This includes  the path to the modified MDP file, the output XVG file for the lambda state, and the log file.</p> Source code in <code>martignac/workflows/solute_in_solvent_alchemical.py</code> <pre><code>@SoluteInSolventAlchemicalFlow.pre(system_prepared, tag=\"system_prepared\")\n@SoluteInSolventAlchemicalFlow.post(lambda_sampled, tag=\"lambda_sampled\")\n@SoluteInSolventAlchemicalFlow.operation_hooks.on_success(\n    store_gromacs_log_to_doc_with_state_point\n)\n@SoluteInSolventAlchemicalFlow.operation(cmd=True, with_job=True)\ndef production(job):\n    \"\"\"\n    Executes the production phase of the molecular dynamics simulation for a given job.\n\n    This function configures and runs the production phase of the alchemical transformation simulation. It involves\n    setting up the Molecular Dynamics Parameters (MDP) file specific to the lambda state of the job, customizing it\n    for the solute involved, and executing the GROMACS simulation. The function generates and stores the paths to\n    the output XVG and log files in the job document for later analysis.\n\n    The MDP file is first templated with the lambda state and solute name, then used to run the simulation with the\n    specified number of threads. This phase is critical for generating the data necessary for free energy calculation.\n\n    Args:\n        job (Job): The job object representing a single simulation job within the alchemical transformation workflow.\n                   It contains the state point information, including the lambda state and solute name, and provides\n                   context for the simulation, including paths to input and output files.\n\n    Returns:\n        str: The command executed for the production phase, primarily for logging or debugging purposes. This includes\n             the path to the modified MDP file, the output XVG file for the lambda state, and the log file.\n    \"\"\"\n    solute_has_charged_beads = job.doc[solute_gen_project.class_name()].get(\n        \"solute_has_charged_beads\"\n    )\n    num_lambda_points = job.doc[project_name][\"num_lambda_points\"]\n    vdw_lambdas, coul_lambdas = generate_lambdas(\n        num_lambda_points, turn_off_coulomb=not solute_has_charged_beads\n    )\n    vdw_lambda_str = \" \".join(map(str, vdw_lambdas))\n    coul_lambda_str = \" \".join(map(str, coul_lambdas))\n    lambda_state = str(job.sp.lambda_state)\n    lambda_mdp = (\n        f\"{SoluteInSolventAlchemicalFlow.get_system_run_name(job.sp.lambda_state)}.mdp\"\n    )\n    sub_template_mdp(\n        SoluteInSolventAlchemicalFlow.mdp_files.get(\"production\"),\n        \"sedstate\",\n        lambda_state,\n        lambda_mdp,\n    )\n    sub_template_mdp(lambda_mdp, \"sedmolecule\", job.sp[\"solute_name\"], lambda_mdp)\n    sub_template_mdp(lambda_mdp, \"sedvdwlambdas\", vdw_lambda_str, lambda_mdp)\n    sub_template_mdp(lambda_mdp, \"sedcoullambdas\", coul_lambda_str, lambda_mdp)\n    job.doc[project_name][\n        \"alchemical_xvg\"\n    ] = f\"{SoluteInSolventAlchemicalFlow.get_system_run_name(lambda_state)}.xvg\"\n    job.doc[project_name][\n        \"alchemical_log\"\n    ] = f\"{SoluteInSolventAlchemicalFlow.get_system_run_name(lambda_state)}.log\"\n    return gromacs_simulation_command(\n        mdp=lambda_mdp,\n        top=job.doc[solute_solvation_project.class_name()].get(\"solute_solvent_top\"),\n        gro=job.doc[solute_solvation_project.class_name()].get(\"solute_solvent_gro\"),\n        name=SoluteInSolventAlchemicalFlow.get_system_run_name(lambda_state),\n        n_threads=SoluteInSolventAlchemicalFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_in_solvent_generation/","title":"Solute-in-solvent generation","text":""},{"location":"workflows/solute_in_solvent_generation/#martignac.workflows.solute_in_solvent_generation.SoluteInSolventGenFlow","title":"<code>SoluteInSolventGenFlow</code>","text":"<p>               Bases: <code>MartiniFlowProject</code></p> <p>Represents the workflow for generating a solute in solvent system for molecular dynamics simulations.</p> <p>This class extends the MartiniFlowProject, incorporating specific configurations and operations for solute and solvent generation, solvation, minimization, equilibration, and preparation for NOMAD upload. It defines the workflow's file paths, input files, simulation settings, and state names based on the project configuration.</p> <p>Attributes:</p> Name Type Description <code>workspace_path</code> <code>str</code> <p>Path to the workspace directory for this workflow.</p> <code>itp_files</code> <code>dict</code> <p>Dictionary mapping from itp file identifiers to their paths.</p> <code>mdp_path</code> <code>str</code> <p>Path to the directory containing MDP files for GROMACS simulations.</p> <code>mdp_files</code> <code>dict</code> <p>Dictionary mapping from MDP file identifiers to their paths.</p> <code>simulation_settings</code> <code>dict</code> <p>Dictionary containing simulation settings, e.g., number of threads.</p> <code>system_name</code> <code>str</code> <p>Name of the system being generated.</p> <code>nomad_workflow</code> <code>str</code> <p>Name of the workflow file for NOMAD.</p> <code>nomad_top_level_workflow</code> <code>str</code> <p>Name of the top-level workflow file for NOMAD.</p> <code>state_names</code> <code>dict</code> <p>Dictionary mapping state identifiers to their names.</p> <p>The class also includes methods for each step of the workflow, including generating the solute and solvent, solvating the solute with the solvent, minimizing the energy of the system, equilibrating the system, and preparing and uploading the workflow to NOMAD.</p> Source code in <code>martignac/workflows/solute_in_solvent_generation.py</code> <pre><code>class SoluteInSolventGenFlow(MartiniFlowProject):\n    \"\"\"\n    Represents the workflow for generating a solute in solvent system for molecular dynamics simulations.\n\n    This class extends the MartiniFlowProject, incorporating specific configurations and operations\n    for solute and solvent generation, solvation, minimization, equilibration, and preparation for\n    NOMAD upload. It defines the workflow's file paths, input files, simulation settings, and state\n    names based on the project configuration.\n\n    Attributes:\n        workspace_path (str): Path to the workspace directory for this workflow.\n        itp_files (dict): Dictionary mapping from itp file identifiers to their paths.\n        mdp_path (str): Path to the directory containing MDP files for GROMACS simulations.\n        mdp_files (dict): Dictionary mapping from MDP file identifiers to their paths.\n        simulation_settings (dict): Dictionary containing simulation settings, e.g., number of threads.\n        system_name (str): Name of the system being generated.\n        nomad_workflow (str): Name of the workflow file for NOMAD.\n        nomad_top_level_workflow (str): Name of the top-level workflow file for NOMAD.\n        state_names (dict): Dictionary mapping state identifiers to their names.\n\n    The class also includes methods for each step of the workflow, including generating the solute and\n    solvent, solvating the solute with the solvent, minimizing the energy of the system, equilibrating\n    the system, and preparing and uploading the workflow to NOMAD.\n    \"\"\"\n\n    workspace_path: str = (\n        f\"{MartiniFlowProject.workspaces_path}/{conf['relative_paths']['workspaces']}\"\n    )\n    itp_files = {k: v.get(str) for k, v in conf[\"itp_files\"].items()}\n    mdp_path = (\n        f\"{MartiniFlowProject.input_files_path}/{conf['relative_paths']['mdp_files']}\"\n    )\n    mdp_files = {k: v.get(str) for k, v in conf[\"mdp_files\"].items()}\n    simulation_settings = {\"n_threads\": conf[\"settings\"][\"n_threads\"].get(int)}\n    system_name = conf[\"output_names\"][\"system\"].get(str)\n    nomad_workflow: str = conf[\"output_names\"][\"nomad_workflow\"].get(str)\n    nomad_top_level_workflow: str = conf[\"output_names\"][\n        \"nomad_top_level_workflow\"\n    ].get(str)\n    state_names = {k: v.get(str) for k, v in conf[\"output_names\"][\"states\"].items()}\n</code></pre>"},{"location":"workflows/solute_in_solvent_generation/#martignac.workflows.solute_in_solvent_generation.equilibrate","title":"<code>equilibrate(job)</code>","text":"<p>Equilibrates the minimized molecular system to ensure stability under simulation conditions.</p> <p>This operation performs the equilibration phase of the molecular dynamics simulation process, using GROMACS. It aims to bring the system to a stable state where temperature, pressure, and densities are balanced and representative of the intended simulation environment. This step is crucial for achieving realistic simulation results and for preparing the system for the production run.</p> <p>The function updates the job document with the path to the equilibrated coordinate file, marking the equilibration step as complete. It constructs and returns the GROMACS command for equilibration, configured with the appropriate molecular dynamics parameters (MDP) file, topology file, and the minimized coordinate file.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the path to the equilibrated system files.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command to execute the equilibration process using GROMACS, with parameters configured for the  system specified in the job document.</p> Source code in <code>martignac/workflows/solute_in_solvent_generation.py</code> <pre><code>@SoluteInSolventGenFlow.pre(system_minimized, tag=\"system_minimized\")\n@SoluteInSolventGenFlow.post(system_equilibrated, tag=\"system_equilibrated\")\n@SoluteInSolventGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SoluteInSolventGenFlow.operation(cmd=True, with_job=True)\ndef equilibrate(job):\n    \"\"\"\n    Equilibrates the minimized molecular system to ensure stability under simulation conditions.\n\n    This operation performs the equilibration phase of the molecular dynamics simulation process, using GROMACS.\n    It aims to bring the system to a stable state where temperature, pressure, and densities are balanced and\n    representative of the intended simulation environment. This step is crucial for achieving realistic simulation\n    results and for preparing the system for the production run.\n\n    The function updates the job document with the path to the equilibrated coordinate file, marking the\n    equilibration step as complete. It constructs and returns the GROMACS command for equilibration, configured\n    with the appropriate molecular dynamics parameters (MDP) file, topology file, and the minimized coordinate file.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the path to the equilibrated system files.\n\n    Returns:\n        str: The command to execute the equilibration process using GROMACS, with parameters configured for the\n             system specified in the job document.\n    \"\"\"\n    job.doc[project_name][\"solute_solvent_gro\"] = SoluteInSolventGenFlow.get_state_name(\n        \"equilibrate\", \"gro\"\n    )\n    return gromacs_simulation_command(\n        mdp=SoluteInSolventGenFlow.mdp_files.get(\"equilibrate\"),\n        top=SoluteInSolventGenFlow.get_state_name(extension=\"top\"),\n        gro=SoluteInSolventGenFlow.get_state_name(\"minimize\", \"gro\"),\n        name=SoluteInSolventGenFlow.get_state_name(\"equilibrate\"),\n        n_threads=SoluteInSolventGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_in_solvent_generation/#martignac.workflows.solute_in_solvent_generation.generate_solute","title":"<code>generate_solute(job)</code>","text":"<p>Generates the solute for the molecular dynamics simulation.</p> <p>This operation is a critical step in the solute in solvent generation workflow. It imports the solute generation results from a previous workflow, specifically the solute's GRO, TOP, and ITP files, into the current job's document. This process ensures that the solute configuration is ready for subsequent steps, such as solvation and minimization.</p> <p>The function leverages the <code>import_job_from_other_flow</code> utility to copy the necessary files from the solute generation project to the current project, updating the job document with the paths to these files. It also sets the operation's name in the project's operation to workflow mapping, facilitating tracking and management of the workflow's progress.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the solute generation results.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the paths to the solute's   GRO, TOP, and ITP files, marking the solute generation step as complete.</p> Source code in <code>martignac/workflows/solute_in_solvent_generation.py</code> <pre><code>@SoluteInSolventGenFlow.pre(fetched_from_nomad)\n@SoluteInSolventGenFlow.post(solute_generated, tag=\"solute_generated\")\n@SoluteInSolventGenFlow.operation_hooks.on_success(store_workflow)\n@SoluteInSolventGenFlow.operation\ndef generate_solute(job: Job):\n    \"\"\"\n    Generates the solute for the molecular dynamics simulation.\n\n    This operation is a critical step in the solute in solvent generation workflow. It imports the solute\n    generation results from a previous workflow, specifically the solute's GRO, TOP, and ITP files, into the\n    current job's document. This process ensures that the solute configuration is ready for subsequent steps,\n    such as solvation and minimization.\n\n    The function leverages the `import_job_from_other_flow` utility to copy the necessary files from the solute\n    generation project to the current project, updating the job document with the paths to these files. It also\n    sets the operation's name in the project's operation to workflow mapping, facilitating tracking and management\n    of the workflow's progress.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the solute generation results.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the paths to the solute's\n              GRO, TOP, and ITP files, marking the solute generation step as complete.\n    \"\"\"\n    solute_job: Job = get_solute_job(job)\n    keys_for_files_to_copy = [\"solute_gro\", \"solute_top\", \"solute_itp\"]\n    project.operation_to_workflow[func_name()] = solute_gen_name\n    import_job_from_other_flow(\n        job, solute_gen_project, solute_job, keys_for_files_to_copy\n    )\n</code></pre>"},{"location":"workflows/solute_in_solvent_generation/#martignac.workflows.solute_in_solvent_generation.generate_solvent","title":"<code>generate_solvent(job)</code>","text":"<p>Imports solvent generation results into the current job's document.</p> <p>This function is a key component of the solute in solvent generation workflow. It is responsible for importing the solvent's GRO and TOP files from a solvent generation project into the current job's document. This ensures that the solvent configuration is ready for the subsequent solvation and minimization steps.</p> <p>The function utilizes the <code>import_job_from_other_flow</code> utility to facilitate the copying of the necessary files from the solvent generation project to the current project. It updates the job document with the paths to these files and sets the operation's name in the project's operation to workflow mapping, aiding in the tracking and management of the workflow's progress.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the solvent generation results.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the paths to the solvent's   GRO and TOP files, marking the solvent generation step as complete.</p> Source code in <code>martignac/workflows/solute_in_solvent_generation.py</code> <pre><code>@SoluteInSolventGenFlow.pre(fetched_from_nomad)\n@SoluteInSolventGenFlow.post(solvent_generated, tag=\"solvent_generated\")\n@SoluteInSolventGenFlow.operation_hooks.on_success(store_workflow)\n@SoluteInSolventGenFlow.operation\ndef generate_solvent(job):\n    \"\"\"\n    Imports solvent generation results into the current job's document.\n\n    This function is a key component of the solute in solvent generation workflow. It is responsible for\n    importing the solvent's GRO and TOP files from a solvent generation project into the current job's\n    document. This ensures that the solvent configuration is ready for the subsequent solvation and\n    minimization steps.\n\n    The function utilizes the `import_job_from_other_flow` utility to facilitate the copying of the\n    necessary files from the solvent generation project to the current project. It updates the job\n    document with the paths to these files and sets the operation's name in the project's operation\n    to workflow mapping, aiding in the tracking and management of the workflow's progress.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the solvent generation results.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the paths to the solvent's\n              GRO and TOP files, marking the solvent generation step as complete.\n    \"\"\"\n    solvent_job: Job = get_solvent_job(job)\n    keys_for_files_to_copy = [\"solvent_gro\", \"solvent_top\"]\n    project.operation_to_workflow[func_name()] = solvent_gen_name\n    import_job_from_other_flow(\n        job, solvent_gen_project, solvent_job, keys_for_files_to_copy\n    )\n    solvent_job: Job = get_solvent_job(job)\n    keys_for_files_to_copy = [\"solvent_gro\", \"solvent_top\"]\n    project.operation_to_workflow[func_name()] = solvent_gen_name\n    import_job_from_other_flow(\n        job, solvent_gen_project, solvent_job, keys_for_files_to_copy\n    )\n</code></pre>"},{"location":"workflows/solute_in_solvent_generation/#martignac.workflows.solute_in_solvent_generation.minimize","title":"<code>minimize(job)</code>","text":"<p>Minimizes the energy of the solvated system to prepare it for molecular dynamics simulation.</p> <p>This operation is essential for stabilizing the molecular system before proceeding to the equilibration and production phases of the simulation. It combines the topology files of the solute and solvent, and then uses GROMACS to minimize the energy of the combined system. The process ensures that any steric clashes or unrealistic bond lengths/angles are corrected before the system is subjected to dynamic simulation conditions.</p> <p>The function updates the job document with the path to the new combined topology file and executes the GROMACS energy minimization command. The output files, including the minimized coordinate file, are essential for the next steps in the simulation workflow.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the paths to the minimized system files.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command to execute the energy minimization process using GROMACS, with parameters configured  for the combined solute and solvent system specified in the job document.</p> Source code in <code>martignac/workflows/solute_in_solvent_generation.py</code> <pre><code>@SoluteInSolventGenFlow.pre(system_generated, tag=\"system_generated\")\n@SoluteInSolventGenFlow.post(system_minimized, tag=\"system_minimized\")\n@SoluteInSolventGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SoluteInSolventGenFlow.operation(cmd=True, with_job=True)\ndef minimize(job):\n    \"\"\"\n    Minimizes the energy of the solvated system to prepare it for molecular dynamics simulation.\n\n    This operation is essential for stabilizing the molecular system before proceeding to the equilibration\n    and production phases of the simulation. It combines the topology files of the solute and solvent, and\n    then uses GROMACS to minimize the energy of the combined system. The process ensures that any steric clashes\n    or unrealistic bond lengths/angles are corrected before the system is subjected to dynamic simulation conditions.\n\n    The function updates the job document with the path to the new combined topology file and executes the\n    GROMACS energy minimization command. The output files, including the minimized coordinate file, are essential\n    for the next steps in the simulation workflow.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the paths to the minimized system files.\n\n    Returns:\n        str: The command to execute the energy minimization process using GROMACS, with parameters configured\n             for the combined solute and solvent system specified in the job document.\n    \"\"\"\n    solute_top = Topology.parse_top_file(job.doc[solute_gen_name][\"solute_top\"])\n    solvent_top = Topology.parse_top_file(job.doc[solvent_gen_name][\"solvent_top\"])\n    solute_solvent_top = Topology.parse_top_file(\n        SoluteInSolventGenFlow.get_state_name(extension=\"top\")\n    )\n    new_top = append_all_includes_to_top(solute_solvent_top, [solvent_top, solute_top])\n    new_top.system = f\"{job.sp['solute_name']} in {job.sp['solvent_name']}\"\n    logger.info(f\"setting topology system name to {new_top.system}\")\n    new_top.output_top(SoluteInSolventGenFlow.get_state_name(extension=\"top\"))\n    job.doc[project_name][\"solute_solvent_top\"] = SoluteInSolventGenFlow.get_state_name(\n        extension=\"top\"\n    )\n    return gromacs_simulation_command(\n        mdp=SoluteInSolventGenFlow.mdp_files.get(\"minimize\"),\n        top=SoluteInSolventGenFlow.get_state_name(extension=\"top\"),\n        gro=SoluteInSolventGenFlow.get_state_name(\"generate\", \"gro\"),\n        name=SoluteInSolventGenFlow.get_state_name(\"minimize\"),\n        n_threads=SoluteInSolventGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solute_in_solvent_generation/#martignac.workflows.solute_in_solvent_generation.solvate","title":"<code>solvate(job)</code>","text":"<p>Solvates the solute with the solvent in preparation for molecular dynamics simulation.</p> <p>This operation combines the solute and solvent geometries into a single system, creating a solvated system ready for energy minimization and further simulation steps. It uses the GROMACS tool to solvate the solute with the solvent, generating a new topology file and coordinate file for the combined system.</p> <p>The function updates the job document with the paths to the generated files, marking the solvation step as complete. This is a crucial step in the workflow, as it prepares the molecular system for the simulation environment.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation. It contains the state point        and document for the job, which will be updated with the paths to the generated files for        the solvated system.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The command to execute the solvation process using GROMACS, with parameters configured for the  solute and solvent files specified in the job document.</p> Source code in <code>martignac/workflows/solute_in_solvent_generation.py</code> <pre><code>@SoluteInSolventGenFlow.pre(solute_generated, tag=\"solute_generated\")\n@SoluteInSolventGenFlow.pre(solvent_generated, tag=\"solvent_generated\")\n@SoluteInSolventGenFlow.post(system_generated, tag=\"system_generated\")\n@SoluteInSolventGenFlow.operation_hooks.on_success(store_task)\n@SoluteInSolventGenFlow.operation(cmd=True, with_job=True)\ndef solvate(job):\n    \"\"\"\n    Solvates the solute with the solvent in preparation for molecular dynamics simulation.\n\n    This operation combines the solute and solvent geometries into a single system, creating a solvated\n    system ready for energy minimization and further simulation steps. It uses the GROMACS tool to solvate\n    the solute with the solvent, generating a new topology file and coordinate file for the combined system.\n\n    The function updates the job document with the paths to the generated files, marking the solvation step\n    as complete. This is a crucial step in the workflow, as it prepares the molecular system for the\n    simulation environment.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation. It contains the state point\n                   and document for the job, which will be updated with the paths to the generated files for\n                   the solvated system.\n\n    Returns:\n        str: The command to execute the solvation process using GROMACS, with parameters configured for the\n             solute and solvent files specified in the job document.\n    \"\"\"\n    return solvate_solute_command(\n        gro_solute=job.doc[solute_gen_name][\"solute_gro\"],\n        gro_solvent=job.doc[solvent_gen_name][\"solvent_gro\"],\n        top_solute=job.doc[solute_gen_name][\"solute_top\"],\n        top_output=SoluteInSolventGenFlow.get_state_name(extension=\"top\"),\n        output_name=SoluteInSolventGenFlow.get_state_name(\"generate\"),\n    )\n</code></pre>"},{"location":"workflows/solvent_generation/","title":"Solvent generation","text":""},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.SolventGenFlow","title":"<code>SolventGenFlow</code>","text":"<p>               Bases: <code>MartiniFlowProject</code></p> <p>A workflow class for generating and preparing solvent systems for molecular dynamics simulations.</p> <p>This class extends <code>MartiniFlowProject</code> to manage the workflow specific to solvent system generation, including the creation of solvent molecules, building solvent boxes, and preparing these systems for simulations using GROMACS. It encompasses operations such as generating the initial molecular structure (GRO file), topology (TOP file), and parameter (ITP file) files for the solvent, followed by energy minimization, equilibration, and production simulations.</p> <p>Attributes:</p> Name Type Description <code>workspace_path</code> <code>str</code> <p>Path to the workspace directory where simulation files are stored.</p> <code>mdp_path</code> <code>str</code> <p>Path to the directory containing MDP files for GROMACS simulations.</p> <code>itp_files</code> <code>dict</code> <p>Dictionary mapping solvent names to their respective ITP file paths.</p> <code>mdp_files</code> <code>dict</code> <p>Dictionary mapping simulation types (e.g., 'minimize', 'equilibrate', 'production') to their MDP file paths.</p> <code>simulation_settings</code> <code>dict</code> <p>Settings for the simulation, such as the number of threads and box length.</p> <code>system_name</code> <code>str</code> <p>The name of the system being simulated.</p> <code>nomad_workflow</code> <code>str</code> <p>The name of the NOMAD workflow associated with this project.</p> <code>state_names</code> <code>dict</code> <p>Dictionary mapping state names to their string representations for tracking the simulation progress.</p> <p>The class provides methods for each step of the solvent preparation process, including generating solvent molecules, building solvent boxes, converting box formats, minimizing energy, equilibrating the system, running production simulations, and integrating with the NOMAD database for workflow management.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>class SolventGenFlow(MartiniFlowProject):\n    \"\"\"\n    A workflow class for generating and preparing solvent systems for molecular dynamics simulations.\n\n    This class extends `MartiniFlowProject` to manage the workflow specific to solvent system generation, including\n    the creation of solvent molecules, building solvent boxes, and preparing these systems for simulations using\n    GROMACS. It encompasses operations such as generating the initial molecular structure (GRO file), topology (TOP file),\n    and parameter (ITP file) files for the solvent, followed by energy minimization, equilibration, and production\n    simulations.\n\n    Attributes:\n        workspace_path (str): Path to the workspace directory where simulation files are stored.\n        mdp_path (str): Path to the directory containing MDP files for GROMACS simulations.\n        itp_files (dict): Dictionary mapping solvent names to their respective ITP file paths.\n        mdp_files (dict): Dictionary mapping simulation types (e.g., 'minimize', 'equilibrate', 'production') to their MDP file paths.\n        simulation_settings (dict): Settings for the simulation, such as the number of threads and box length.\n        system_name (str): The name of the system being simulated.\n        nomad_workflow (str): The name of the NOMAD workflow associated with this project.\n        state_names (dict): Dictionary mapping state names to their string representations for tracking the simulation progress.\n\n    The class provides methods for each step of the solvent preparation process, including generating solvent molecules,\n    building solvent boxes, converting box formats, minimizing energy, equilibrating the system, running production\n    simulations, and integrating with the NOMAD database for workflow management.\n    \"\"\"\n\n    workspace_path: str = (\n        f\"{MartiniFlowProject.workspaces_path}/{conf['relative_paths']['workspaces']}\"\n    )\n    mdp_path = (\n        f\"{MartiniFlowProject.input_files_path}/{conf['relative_paths']['mdp_files']}\"\n    )\n    itp_files = {k: v.get(str) for k, v in conf[\"itp_files\"].items()}\n    mdp_files = {k: v.get(str) for k, v in conf[\"mdp_files\"].items()}\n    simulation_settings = {\n        \"n_threads\": conf[\"settings\"][\"n_threads\"].get(int),\n        \"box_length\": conf[\"settings\"][\"box_length\"].get(float),\n    }\n    system_name = conf[\"output_names\"][\"system\"].get(str)\n    nomad_workflow: str = conf[\"output_names\"][\"nomad_workflow\"].get(str)\n    state_names = {k: v.get(str) for k, v in conf[\"output_names\"][\"states\"].items()}\n</code></pre>"},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.build_solvent_box","title":"<code>build_solvent_box(_)</code>","text":"<p>Builds a solvent box using the generated molecular structure of the solvent.</p> <p>This operation is a key step in the solvent generation workflow, where it utilizes the previously generated GRO file of the solvent molecule to create a solvent box suitable for molecular dynamics simulations. The solvent box is generated using the Packmol tool, which arranges multiple copies of the solvent molecule within a defined box size to achieve a desired density.</p> <p>The function does not take any arguments directly; instead, it operates on the state of the workflow, specifically looking for the presence of a generated GRO file for the solvent molecule. Upon successful completion, it generates a PDB file representing the solvent box, marking the 'generated_box_pdb' condition as complete.</p> <p>This step is crucial for preparing the solvent system for subsequent energy minimization and equilibration processes, ensuring that the system is ready for molecular dynamics simulations.</p> Note <p>This function is designed to be executed within the SolventGenFlow workflow and relies on the workflow's state management to control its execution and dependencies.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>@SolventGenFlow.pre(generated_mol_gro, tag=\"generated_mol_gro\")\n@SolventGenFlow.post(generated_box_pdb, tag=\"generated_box_pdb\")\n@SolventGenFlow.operation_hooks.on_success(store_task)\n@SolventGenFlow.operation(cmd=True, with_job=True)\ndef build_solvent_box(_):\n    \"\"\"\n    Builds a solvent box using the generated molecular structure of the solvent.\n\n    This operation is a key step in the solvent generation workflow, where it utilizes the previously generated\n    GRO file of the solvent molecule to create a solvent box suitable for molecular dynamics simulations. The\n    solvent box is generated using the Packmol tool, which arranges multiple copies of the solvent molecule\n    within a defined box size to achieve a desired density.\n\n    The function does not take any arguments directly; instead, it operates on the state of the workflow,\n    specifically looking for the presence of a generated GRO file for the solvent molecule. Upon successful\n    completion, it generates a PDB file representing the solvent box, marking the 'generated_box_pdb' condition\n    as complete.\n\n    This step is crucial for preparing the solvent system for subsequent energy minimization and equilibration\n    processes, ensuring that the system is ready for molecular dynamics simulations.\n\n    Note:\n        This function is designed to be executed within the SolventGenFlow workflow and relies on the workflow's\n        state management to control its execution and dependencies.\n    \"\"\"\n    return generate_solvent_with_packmol(\n        gro_solvent_mol=SolventGenFlow.get_state_name(\"mol\", \"gro\"),\n        box_length=SolventGenFlow.simulation_settings.get(\"box_length\"),\n        output_pdb=SolventGenFlow.get_state_name(\"box\", \"pdb\"),\n    )\n</code></pre>"},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.convert_box_to_gro","title":"<code>convert_box_to_gro(_)</code>","text":"<p>Converts the solvent box from PDB to GRO format and adjusts the box dimensions.</p> <p>This function is part of the solvent generation workflow in molecular dynamics simulations. It takes the solvent box in PDB format, generated by the <code>build_solvent_box</code> function, and converts it to GRO format, which is required for further simulation steps in GROMACS. Additionally, it adjusts the box dimensions based on the specified box length in the simulation settings, ensuring the correct size and orientation for the simulation.</p> <p>The conversion and adjustment of the box dimensions are crucial for accurate molecular dynamics simulations, as they directly affect the system's physical properties and behavior during the simulation.</p> Note <p>This function does not take any arguments directly; instead, it operates on the state of the workflow, specifically looking for the presence of a generated PDB file for the solvent box. It updates the workflow's state by marking the 'generated_box_gro' condition as complete upon successful conversion.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>@SolventGenFlow.pre(generated_box_pdb, tag=\"generated_box_pdb\")\n@SolventGenFlow.post(generated_box_gro, tag=\"generated_box_gro\")\n@SolventGenFlow.operation_hooks.on_success(store_task)\n@SolventGenFlow.operation(with_job=True)\ndef convert_box_to_gro(_):\n    \"\"\"\n    Converts the solvent box from PDB to GRO format and adjusts the box dimensions.\n\n    This function is part of the solvent generation workflow in molecular dynamics simulations. It takes the solvent\n    box in PDB format, generated by the `build_solvent_box` function, and converts it to GRO format, which is required\n    for further simulation steps in GROMACS. Additionally, it adjusts the box dimensions based on the specified box\n    length in the simulation settings, ensuring the correct size and orientation for the simulation.\n\n    The conversion and adjustment of the box dimensions are crucial for accurate molecular dynamics simulations,\n    as they directly affect the system's physical properties and behavior during the simulation.\n\n    Note:\n        This function does not take any arguments directly; instead, it operates on the state of the workflow,\n        specifically looking for the presence of a generated PDB file for the solvent box. It updates the workflow's\n        state by marking the 'generated_box_gro' condition as complete upon successful conversion.\n    \"\"\"\n    box_length = SolventGenFlow.simulation_settings.get(\"box_length\")\n    box_vector = np.array(\n        [box_length * 10.0, box_length * 10.0, box_length * 10.0, 90.0, 90.0, 90.0]\n    )\n    convert_pdb_to_gro(\n        SolventGenFlow.get_state_name(\"box\", \"pdb\"),\n        SolventGenFlow.get_state_name(\"box\", \"gro\"),\n        box_vector,\n    )\n</code></pre>"},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.equilibrate","title":"<code>equilibrate(_)</code>","text":"<p>Performs the equilibration phase of the molecular dynamics simulation.</p> <p>This function is responsible for running the equilibration simulation step, which is crucial for stabilizing the system at the desired temperature and pressure before the production run. It uses the GROMACS simulation command configured with the 'equilibrate' MDP file, which contains the parameters for the equilibration process.</p> <p>The equilibration step ensures that the system's temperature, pressure, and density are stabilized, preparing it for the accurate and reliable collection of production data in the subsequent simulation phase.</p> Note <p>This function does not take any arguments directly; instead, it operates on the state of the workflow, specifically looking for the presence of a minimized GRO file for the solvent box. It updates the workflow's state by marking the 'system_equilibrated' condition as complete upon successful equilibration.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but executes the equilibration simulation command and updates   the workflow's state accordingly.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>@SolventGenFlow.pre(system_minimized, tag=\"system_minimized\")\n@SolventGenFlow.post(system_equilibrated, tag=\"system_equilibrated\")\n@SolventGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SolventGenFlow.operation(cmd=True, with_job=True)\ndef equilibrate(_):\n    \"\"\"\n    Performs the equilibration phase of the molecular dynamics simulation.\n\n    This function is responsible for running the equilibration simulation step, which is crucial for stabilizing the\n    system at the desired temperature and pressure before the production run. It uses the GROMACS simulation command\n    configured with the 'equilibrate' MDP file, which contains the parameters for the equilibration process.\n\n    The equilibration step ensures that the system's temperature, pressure, and density are stabilized, preparing it\n    for the accurate and reliable collection of production data in the subsequent simulation phase.\n\n    Note:\n        This function does not take any arguments directly; instead, it operates on the state of the workflow,\n        specifically looking for the presence of a minimized GRO file for the solvent box. It updates the workflow's\n        state by marking the 'system_equilibrated' condition as complete upon successful equilibration.\n\n    Returns:\n        None: This function does not return a value but executes the equilibration simulation command and updates\n              the workflow's state accordingly.\n    \"\"\"\n    return gromacs_simulation_command(\n        mdp=SolventGenFlow.mdp_files.get(\"equilibrate\"),\n        top=SolventGenFlow.get_state_name(\"box\", \"top\"),\n        gro=SolventGenFlow.get_state_name(\"minimize\", \"gro\"),\n        name=SolventGenFlow.get_state_name(\"equilibrate\"),\n        n_threads=SolventGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.generate_solvent_molecule","title":"<code>generate_solvent_molecule(job)</code>","text":"<p>Generates the initial molecular structure (GRO file) and topology (TOP file) for a specified solvent molecule.</p> <p>This function is a critical step in the solvent generation workflow, where it takes the name of the solvent from the job's state point and utilizes it to find the corresponding molecular data. It then generates the GRO and TOP files necessary for molecular dynamics simulations using GROMACS. These files represent the initial molecular structure and topology of the solvent molecule, respectively.</p> <p>The generation of these files marks the completion of the initial setup for the solvent molecule, allowing for further steps in the workflow, such as building the solvent box and performing energy minimization.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation, containing the solvent name        and other relevant information in its state point.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>This function does not return a value but updates the job document with the paths to the generated   GRO and TOP files, marking the 'generated_mol_gro' condition as complete.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>@SolventGenFlow.pre(fetched_from_nomad)\n@SolventGenFlow.post(generated_mol_gro, tag=\"generated_mol_gro\")\n@SolventGenFlow.operation_hooks.on_success(store_task)\n@SolventGenFlow.operation(with_job=True)\ndef generate_solvent_molecule(job) -&gt; None:\n    \"\"\"\n    Generates the initial molecular structure (GRO file) and topology (TOP file) for a specified solvent molecule.\n\n    This function is a critical step in the solvent generation workflow, where it takes the name of the solvent\n    from the job's state point and utilizes it to find the corresponding molecular data. It then generates the\n    GRO and TOP files necessary for molecular dynamics simulations using GROMACS. These files represent the\n    initial molecular structure and topology of the solvent molecule, respectively.\n\n    The generation of these files marks the completion of the initial setup for the solvent molecule, allowing\n    for further steps in the workflow, such as building the solvent box and performing energy minimization.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation, containing the solvent name\n                   and other relevant information in its state point.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the paths to the generated\n              GRO and TOP files, marking the 'generated_mol_gro' condition as complete.\n    \"\"\"\n    molecule = find_molecule_from_name(\n        list(SolventGenFlow.itp_files.values()), job.sp.solvent_name\n    )\n    generate_gro_file_for_molecule(\n        molecule, SolventGenFlow.get_state_name(\"mol\", \"gro\")\n    )\n    generate_top_file_for_molecule(\n        molecule,\n        list(SolventGenFlow.itp_files.values()),\n        SolventGenFlow.get_state_name(\"mol\", \"top\"),\n    )\n    return None\n</code></pre>"},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.minimize","title":"<code>minimize(job)</code>","text":"<p>Performs energy minimization on the solvent system.</p> <p>This function is a crucial step in the solvent generation workflow, aimed at minimizing the potential energy of the solvent system to ensure stability before proceeding to equilibration and production simulations. It generates the topology file for the solvent box with the correct number of molecules, updates the job document with the solvent topology and name, and then executes the GROMACS energy minimization command using the specified MDP file.</p> <p>The energy minimization process is essential for removing any physically unrealistic conformations and reducing the system's energy, which could otherwise lead to simulation artifacts or instabilities.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation, containing the solvent name        and other relevant information in its state point.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the paths to the generated   topology file and executes the energy minimization command.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>@SolventGenFlow.pre(generated_box_gro, tag=\"generated_box_gro\")\n@SolventGenFlow.post(system_minimized, tag=\"system_minimized\")\n@SolventGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SolventGenFlow.operation(cmd=True, with_job=True)\ndef minimize(job):\n    \"\"\"\n    Performs energy minimization on the solvent system.\n\n    This function is a crucial step in the solvent generation workflow, aimed at minimizing the potential energy of the\n    solvent system to ensure stability before proceeding to equilibration and production simulations. It generates the\n    topology file for the solvent box with the correct number of molecules, updates the job document with the solvent\n    topology and name, and then executes the GROMACS energy minimization command using the specified MDP file.\n\n    The energy minimization process is essential for removing any physically unrealistic conformations and reducing the\n    system's energy, which could otherwise lead to simulation artifacts or instabilities.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation, containing the solvent name\n                   and other relevant information in its state point.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the paths to the generated\n              topology file and executes the energy minimization command.\n    \"\"\"\n    molecule = find_molecule_from_name(\n        list(SolventGenFlow.itp_files.values()), job.sp.solvent_name\n    )\n    generate_top_file_for_molecule(\n        molecule,\n        list(SolventGenFlow.itp_files.values()),\n        SolventGenFlow.get_state_name(\"box\", \"top\"),\n        num_molecules=get_number_of_molecules_from_gro(\n            SolventGenFlow.get_state_name(\"box\", \"gro\")\n        ),\n    )\n    job.doc[project_name][\"solvent_top\"] = SolventGenFlow.get_state_name(\"box\", \"top\")\n    job.doc[project_name][\"solvent_name\"] = job.sp.solvent_name\n    return gromacs_simulation_command(\n        mdp=SolventGenFlow.mdp_files.get(\"minimize\"),\n        top=SolventGenFlow.get_state_name(\"box\", \"top\"),\n        gro=SolventGenFlow.get_state_name(\"box\", \"gro\"),\n        name=SolventGenFlow.get_state_name(\"minimize\"),\n        n_threads=SolventGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"},{"location":"workflows/solvent_generation/#martignac.workflows.solvent_generation.production","title":"<code>production(job)</code>","text":"<p>Executes the production phase of the molecular dynamics simulation.</p> <p>This function is the final step in the solvent generation workflow, where it performs the production simulation using GROMACS. The production simulation is crucial for generating the actual data for analysis, representing the behavior of the solvent system under specified conditions over time.</p> <p>The function configures and executes the GROMACS simulation command with the 'production' MDP file, which contains the parameters for the production phase, such as simulation time and temperature control settings. It updates the job document with the path to the final GRO file generated by this simulation, marking the 'system_sampled' condition as complete, indicating that the production phase has been successfully executed and data collection is finished.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job object associated with the current workflow operation, containing the solvent name        and other relevant information in its state point.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value but updates the job document with the path to the production   GRO file and executes the production simulation command.</p> Source code in <code>martignac/workflows/solvent_generation.py</code> <pre><code>@SolventGenFlow.pre(system_equilibrated, tag=\"system_equilibrated\")\n@SolventGenFlow.post(system_sampled, tag=\"system_sampled\")\n@SolventGenFlow.operation_hooks.on_success(store_gromacs_log_to_doc)\n@SolventGenFlow.operation(cmd=True, with_job=True)\ndef production(job):\n    \"\"\"\n    Executes the production phase of the molecular dynamics simulation.\n\n    This function is the final step in the solvent generation workflow, where it performs the production simulation\n    using GROMACS. The production simulation is crucial for generating the actual data for analysis, representing\n    the behavior of the solvent system under specified conditions over time.\n\n    The function configures and executes the GROMACS simulation command with the 'production' MDP file, which contains\n    the parameters for the production phase, such as simulation time and temperature control settings. It updates the\n    job document with the path to the final GRO file generated by this simulation, marking the 'system_sampled' condition\n    as complete, indicating that the production phase has been successfully executed and data collection is finished.\n\n    Args:\n        job (Job): The job object associated with the current workflow operation, containing the solvent name\n                   and other relevant information in its state point.\n\n    Returns:\n        None: This function does not return a value but updates the job document with the path to the production\n              GRO file and executes the production simulation command.\n    \"\"\"\n    job.doc[project_name][\"solvent_gro\"] = SolventGenFlow.get_state_name(\n        \"production\", \"gro\"\n    )\n    return gromacs_simulation_command(\n        mdp=SolventGenFlow.mdp_files.get(\"production\"),\n        top=SolventGenFlow.get_state_name(\"box\", \"top\"),\n        gro=SolventGenFlow.get_state_name(\"equilibrate\", \"gro\"),\n        name=SolventGenFlow.get_state_name(\"production\"),\n        n_threads=SolventGenFlow.simulation_settings.get(\"n_threads\"),\n    )\n</code></pre>"}]}